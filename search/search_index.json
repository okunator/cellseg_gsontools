{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#introduction","title":"Introduction","text":"<p>Cellseg_gsontools is a Python toolset designed to analyze and summarize large cell and tissue segmentation maps created from Whole Slide Images (WSI). The library is built on top of <code>geopandas</code> and <code>libpysal</code>. In other words, the library can process geospatial data with GeoJSON-interface.</p> <p> </p> <p>NOTE: The library is synergetic with the cellseg_models.pytorch segmentation library which enables you to segment your WSI into <code>GeoJSON</code> format.</p>"},{"location":"getting_started/installation/","title":"Installation","text":"<pre><code>pip install cellseg-gsontools\n</code></pre>"},{"location":"getting_started/quick_start/","title":"Quick start","text":"In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import cervix_cells, cervix_tissue\n\ncells = cervix_cells()\ntissue = cervix_tissue()\n\ncells.head(4)\n</pre> from cellseg_gsontools.data import cervix_cells, cervix_tissue  cells = cervix_cells() tissue = cervix_tissue()  cells.head(4) Out[1]: type geometry class_name uid 1 Feature POLYGON ((-10.988 48446.005, -10.988 48453.996... inflammatory 2 Feature POLYGON ((-20.988 48477.996, -19.990 48479.993... connective 3 Feature POLYGON ((-14.988 48767.995, -11.993 48770.990... inflammatory 4 Feature POLYGON ((-3.988 49537.995, -2.995 49538.988, ... connective In\u00a0[2]: Copied! <pre>cells.plot(column=\"class_name\", figsize=(10, 5))\n</pre> cells.plot(column=\"class_name\", figsize=(10, 5)) Out[2]: <pre>&lt;Axes: &gt;</pre> In\u00a0[3]: Copied! <pre>tissue.plot(column=\"class_name\", figsize=(10, 5))\n</pre> tissue.plot(column=\"class_name\", figsize=(10, 5)) Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre># Get only the stromal tissue from `tissue` gdf\nstroma = tissue.loc[tissue[\"class_name\"] == \"areastroma\"]\n\n# sjoin\ncells_in_stroma = cells.sjoin(stroma, how=\"inner\", predicate=\"intersects\")\ncells_in_stroma.plot(column=\"class_name_left\", figsize=(10, 5))\n</pre> # Get only the stromal tissue from `tissue` gdf stroma = tissue.loc[tissue[\"class_name\"] == \"areastroma\"]  # sjoin cells_in_stroma = cells.sjoin(stroma, how=\"inner\", predicate=\"intersects\") cells_in_stroma.plot(column=\"class_name_left\", figsize=(10, 5)) Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre># sindex. Very fast!\ntissue_inds, cell_inds = cells.sindex.query(stroma.geometry, predicate=\"intersects\")\ncells_in_stroma = cells.iloc[cell_inds]\ncells_in_stroma.plot(column=\"class_name\", figsize=(10, 5))\n</pre> # sindex. Very fast! tissue_inds, cell_inds = cells.sindex.query(stroma.geometry, predicate=\"intersects\") cells_in_stroma = cells.iloc[cell_inds] cells_in_stroma.plot(column=\"class_name\", figsize=(10, 5)) Out[5]: <pre>&lt;Axes: &gt;</pre> In\u00a0[6]: Copied! <pre>from cellseg_gsontools.geometry import shape_metric\n\ncells_in_stroma = shape_metric(\n    cells_in_stroma,\n    metrics=[\"area\", \"sphericity\", \"eccentricity\"],\n    parallel=True\n)\ncells_in_stroma.head(4)\n</pre> from cellseg_gsontools.geometry import shape_metric  cells_in_stroma = shape_metric(     cells_in_stroma,     metrics=[\"area\", \"sphericity\", \"eccentricity\"],     parallel=True ) cells_in_stroma.head(4) Out[6]: type geometry class_name area sphericity eccentricity uid 3181 Feature POLYGON ((2050.012 50909.995, 2054.007 50913.9... inflammatory 366.583000 0.666200 0.564428 2021 Feature POLYGON ((1905.012 51053.996, 1906.826 51056.8... glandular_epithel 924.939588 0.530253 0.817158 2030 Feature POLYGON ((1928.012 51090.995, 1932.005 51094.9... glandular_epithel 281.475643 0.626814 0.527087 2036 Feature POLYGON ((1927.012 51147.003, 1928.012 51151.9... glandular_epithel 460.664656 0.617916 0.661679 In\u00a0[10]: Copied! <pre>import matplotlib.pyplot as plt\n\nfig, ax = plt.subplots(3, 1, figsize=(10, 15))\nax = ax.flatten()\n\nax[0] = cells_in_stroma.plot(\n    ax=ax[0],\n    column=\"area\",\n    cmap=\"viridis\",\n    legend=True,\n)\nax[0].set_title(\"Area\")\nax[1] = cells_in_stroma.plot(\n    ax=ax[1],\n    column=\"sphericity\",\n    cmap=\"viridis\",\n    legend=True,\n)\nax[1].set_title(\"Sphericity\")\nax[2] = cells_in_stroma.plot(\n    ax=ax[2],\n    column=\"eccentricity\",\n    cmap=\"viridis\",\n    legend=True,\n)\nax[2].set_title(\"Eccentricity\")\n</pre> import matplotlib.pyplot as plt  fig, ax = plt.subplots(3, 1, figsize=(10, 15)) ax = ax.flatten()  ax[0] = cells_in_stroma.plot(     ax=ax[0],     column=\"area\",     cmap=\"viridis\",     legend=True, ) ax[0].set_title(\"Area\") ax[1] = cells_in_stroma.plot(     ax=ax[1],     column=\"sphericity\",     cmap=\"viridis\",     legend=True, ) ax[1].set_title(\"Sphericity\") ax[2] = cells_in_stroma.plot(     ax=ax[2],     column=\"eccentricity\",     cmap=\"viridis\",     legend=True, ) ax[2].set_title(\"Eccentricity\") Out[10]: <pre>Text(0.5, 1.0, 'Eccentricity')</pre> In\u00a0[12]: Copied! <pre>from cellseg_gsontools.graphs import fit_graph\nfrom cellseg_gsontools.links import weights2gdf\n\nstromal_connectivity = fit_graph(\n    cells_in_stroma,\n    type=\"distband\",\n    thresh=100,\n)\nweights = weights2gdf(cells_in_stroma, stromal_connectivity)\nweights.head(4)\n</pre> from cellseg_gsontools.graphs import fit_graph from cellseg_gsontools.links import weights2gdf  stromal_connectivity = fit_graph(     cells_in_stroma,     type=\"distband\",     thresh=100, ) weights = weights2gdf(cells_in_stroma, stromal_connectivity) weights.head(4) Out[12]: index focal neighbor weight focal_centroid neighbor_centroid focal_class_name neighbor_class_name class_name geometry 0 0 2021 2030 1.0 POINT (1927.025763595986 51043.32882097136) POINT (1938.091708479527 51086.61324699228) glandular_epithel glandular_epithel glandular_epithel-glandular_epithel LINESTRING (1927.026 51043.329, 1938.092 51086... 1 2 2030 2036 1.0 POINT (1938.091708479527 51086.61324699228) POINT (1941.0429358989277 51145.53971058136) glandular_epithel glandular_epithel glandular_epithel-glandular_epithel LINESTRING (1938.092 51086.613, 1941.043 51145... 2 4 6600 6614 1.0 POINT (6981.369919939368 47996.21331351611) POINT (6955.696549069773 48039.52205471928) connective connective connective-connective LINESTRING (6981.370 47996.213, 6955.697 48039... 3 5 6600 6617 1.0 POINT (6981.369919939368 47996.21331351611) POINT (6907.960024465983 48045.98316704895) connective connective connective-connective LINESTRING (6981.370 47996.213, 6907.960 48045... In\u00a0[16]: Copied! <pre>weights.value_counts(\"class_name\", normalize=True)\n</pre> weights.value_counts(\"class_name\", normalize=True) Out[16]: <pre>class_name\nconnective-inflammatory                0.381386\nconnective-connective                  0.331238\ninflammatory-inflammatory              0.249722\nglandular_epithel-glandular_epithel    0.019352\nconnective-glandular_epithel           0.011105\nglandular_epithel-inflammatory         0.005143\nconnective-neoplastic                  0.001220\ninflammatory-neoplastic                0.000618\nneoplastic-neoplastic                  0.000108\nconnective-dead                        0.000015\nconnective-squamous_epithel            0.000015\ndead-inflammatory                      0.000015\ndead-neoplastic                        0.000015\nglandular_epithel-neoplastic           0.000015\ninflammatory-squamous_epithel          0.000015\nneoplastic-squamous_epithel            0.000015\nName: proportion, dtype: float64</pre> In\u00a0[28]: Copied! <pre>from cellseg_gsontools.grid import hexgrid_overlay\n\ngrid = hexgrid_overlay(stroma)\nax = tissue.plot(column=\"class_name\", figsize=(10, 5))\ngrid.boundary.plot(ax=ax, color=\"white\")\n</pre> from cellseg_gsontools.grid import hexgrid_overlay  grid = hexgrid_overlay(stroma) ax = tissue.plot(column=\"class_name\", figsize=(10, 5)) grid.boundary.plot(ax=ax, color=\"white\") Out[28]: <pre>&lt;Axes: &gt;</pre> In\u00a0[31]: Copied! <pre>from cellseg_gsontools.grid import grid_classify\n\n# Immune cell cnt heuristic to classify the grid cells into two classes\ndef get_immune_cell_prop(gdf, **kwargs) -&gt; int:\n    try:\n        cnt = gdf.class_name.value_counts(normalize=True)[\"inflammatory\"]\n    except KeyError:\n        cnt = 0\n\n    return cnt\n\ngrid = grid_classify(\n    grid=grid,\n    objs=cells_in_stroma,\n    metric_func=get_immune_cell_prop,\n    predicate=\"intersects\",\n    new_col_names=\"immune_percentage\"\n)\n\ngrid.head(4)\n</pre> from cellseg_gsontools.grid import grid_classify  # Immune cell cnt heuristic to classify the grid cells into two classes def get_immune_cell_prop(gdf, **kwargs) -&gt; int:     try:         cnt = gdf.class_name.value_counts(normalize=True)[\"inflammatory\"]     except KeyError:         cnt = 0      return cnt  grid = grid_classify(     grid=grid,     objs=cells_in_stroma,     metric_func=get_immune_cell_prop,     predicate=\"intersects\",     new_col_names=\"immune_percentage\" )  grid.head(4) Out[31]: geometry immune_percentage 8982f6d61d7ffff POLYGON ((9170.47315 50052.75362, 9195.41909 5... 0.375000 8982f6d6117ffff POLYGON ((8371.83439 50391.14515, 8396.78532 5... 0.740741 8982f699343ffff POLYGON ((5547.10778 49343.98203, 5572.07323 4... 0.389610 8982f6d608fffff POLYGON ((10842.80505 49967.64578, 10867.74140... 0.200000 In\u00a0[40]: Copied! <pre>ax = tissue.plot(column=\"class_name\", figsize=(10, 5), cmap=\"tab20_r\")\nax = cells.plot(ax=ax, column=\"class_name\", figsize=(10, 5), cmap=\"tab20\")\n\ngrid.geometry = grid.boundary\ngrid.plot(\n    ax=ax,\n    column=\"immune_percentage\",\n    figsize=(10, 5),\n    alpha=0.5,\n    cmap=\"turbo\"\n)\n</pre> ax = tissue.plot(column=\"class_name\", figsize=(10, 5), cmap=\"tab20_r\") ax = cells.plot(ax=ax, column=\"class_name\", figsize=(10, 5), cmap=\"tab20\")  grid.geometry = grid.boundary grid.plot(     ax=ax,     column=\"immune_percentage\",     figsize=(10, 5),     alpha=0.5,     cmap=\"turbo\" ) Out[40]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"getting_started/quick_start/#quick-start","title":"Quick start\u00b6","text":""},{"location":"getting_started/quick_start/#data","title":"Data\u00b6","text":"<p>Get some data to play with.</p> <p>NOTE that the cell type labels are under the <code>class_name</code> column. Whenever you use <code>cellseg_gsontools</code>, you need to have a column named <code>class_name</code> containing the class labels.</p>"},{"location":"getting_started/quick_start/#subset-cells-within-a-specific-tissue","title":"Subset Cells Within a Specific Tissue\u00b6","text":"<p>Two ways to subset cells within a specific tissue: <code>sjoin</code> or <code>sindex</code>. The <code>sjoin</code> operation can be super slow when the dataframes are very large.</p>"},{"location":"getting_started/quick_start/#compute-morphological-features","title":"Compute Morphological Features\u00b6","text":""},{"location":"getting_started/quick_start/#compute-spatial-weights","title":"Compute Spatial Weights\u00b6","text":"<p>Spatial weights are connectivity graphs between cells.</p>"},{"location":"getting_started/quick_start/#compute-spatial-indices-grids","title":"Compute Spatial Indices (Grids)\u00b6","text":""},{"location":"getting_started/quick_start/#compute-grid-features","title":"Compute Grid Features\u00b6","text":""},{"location":"reference/cell_neighborhoods/local_character_ref/","title":"local_character","text":""},{"location":"reference/cell_neighborhoods/local_character_ref/#cellseg_gsontools.character.local_character","title":"<code>cellseg_gsontools.character.local_character(gdf, spatial_weights, val_col, id_col=None, reductions=('sum'), weight_by_area=False, parallel=True, num_processes=-1, rm_nhood_cols=True, col_prefix=None, create_copy=True)</code>","text":"<p>Compute the local sum/mean/median/min/max/std of a specified metric for each neighborhood of geometry objects in a gdf.</p> Note <p>Option to weight the nhood values by their area before reductions.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The input GeoDataFrame.</p> required <code>spatial_weights</code> <code>W</code> <p>Libpysal spatial weights object.</p> required <code>val_col</code> <code>Union[str, Tuple[str, ...]]</code> <p>The name of the column in the gdf for which the reduction is computed. If a tuple, the reduction is computed for each column.</p> required <code>id_col</code> <code>str</code> <p>The unique id column in the gdf. If None, this uses <code>set_uid</code> to set it. Defaults to None.</p> <code>None</code> <code>reductions</code> <code>Tuple[str, ...]</code> <p>A list of reduction methods for the neighborhood. One of \"sum\", \"mean\", \"median\", \"min\", \"max\", \"std\". Defaults to (\"sum\", ).</p> <code>('sum')</code> <code>weight_by_area</code> <code>bool</code> <p>Flag whether to weight the neighborhood values by the area of the object. Defaults to False.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Flag whether to use parallel apply operations when computing the character. Defaults to True.</p> <code>True</code> <code>num_processes</code> <code>int, default=-1</code> <p>The number of processes to use when parallel=True. If -1, this will use all available cores.</p> <code>-1</code> <code>rm_nhood_cols</code> <code>bool</code> <p>Flag, whether to remove the extra neighborhood columns from the result gdf. Defaults to True.</p> <code>True</code> <code>col_prefix</code> <code>str</code> <p>Prefix for the new column names.</p> <code>None</code> <code>create_copy</code> <code>bool</code> <p>Flag whether to create a copy of the input gdf and return that. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The input geodataframe with computed character column added.</p> <p>Examples:</p> <p>Compute the mean of eccentricity values for each cell neighborhood</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.character import local_character\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; w = fit_graph(gdf, type=\"distband\", thres=75.0)\n&gt;&gt;&gt; local_character(\n...     gdf,\n...     spatial_weights=w,\n...     val_col=[\"eccentricity\", \"area\"],\n...     reduction=[\"mean\", \"median\"],\n...     weight_by_area=True,\n... )\n</code></pre> Source code in <code>cellseg_gsontools/character.py</code> <pre><code>def local_character(\n    gdf: gpd.GeoDataFrame,\n    spatial_weights: W,\n    val_col: Union[str, Tuple[str, ...]],\n    id_col: str = None,\n    reductions: Tuple[str, ...] = (\"sum\",),\n    weight_by_area: bool = False,\n    parallel: bool = True,\n    num_processes: int = -1,\n    rm_nhood_cols: bool = True,\n    col_prefix: str = None,\n    create_copy: bool = True,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Compute the local sum/mean/median/min/max/std of a specified metric for each\n    neighborhood of geometry objects in a gdf.\n\n    Note:\n        Option to weight the nhood values by their area before reductions.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The input GeoDataFrame.\n        spatial_weights (libysal.weights.W):\n            Libpysal spatial weights object.\n        val_col (Union[str, Tuple[str, ...]]):\n            The name of the column in the gdf for which the reduction is computed.\n            If a tuple, the reduction is computed for each column.\n        id_col (str):\n            The unique id column in the gdf. If None, this uses `set_uid` to set it.\n            Defaults to None.\n        reductions (Tuple[str, ...]):\n            A list of reduction methods for the neighborhood. One of\n            \"sum\", \"mean\", \"median\", \"min\", \"max\", \"std\". Defaults to (\"sum\", ).\n        weight_by_area (bool):\n            Flag whether to weight the neighborhood values by the area of the object.\n            Defaults to False.\n        parallel (bool):\n            Flag whether to use parallel apply operations when computing the character.\n            Defaults to True.\n        num_processes (int, default=-1):\n            The number of processes to use when parallel=True. If -1,\n            this will use all available cores.\n        rm_nhood_cols (bool):\n            Flag, whether to remove the extra neighborhood columns from the result gdf.\n            Defaults to True.\n        col_prefix (str):\n            Prefix for the new column names.\n        create_copy (bool):\n            Flag whether to create a copy of the input gdf and return that.\n            Defaults to True.\n\n    Returns:\n        gpd.GeoDataFrame:\n            The input geodataframe with computed character column added.\n\n    Examples:\n        Compute the mean of eccentricity values for each cell neighborhood\n        &gt;&gt;&gt; from cellseg_gsontools.character import local_character\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; w = fit_graph(gdf, type=\"distband\", thres=75.0)\n        &gt;&gt;&gt; local_character(\n        ...     gdf,\n        ...     spatial_weights=w,\n        ...     val_col=[\"eccentricity\", \"area\"],\n        ...     reduction=[\"mean\", \"median\"],\n        ...     weight_by_area=True,\n        ... )\n    \"\"\"\n    allowed = (\"sum\", \"mean\", \"median\", \"min\", \"max\", \"std\")\n    if not all(r in allowed for r in reductions):\n        raise ValueError(\n            f\"Illegal reduction in `reductions`. Got: {reductions}. \"\n            f\"Allowed reductions: {allowed}.\"\n        )\n\n    if create_copy:\n        gdf = gdf.copy()\n\n    # set uid\n    if id_col is None:\n        id_col = \"uid\"\n        gdf = set_uid(gdf)\n\n    # Get the immediate node neighborhood\n    func = partial(neighborhood, spatial_weights=spatial_weights)\n    gdf[\"nhood\"] = gdf_apply(\n        gdf,\n        func,\n        columns=[id_col],\n        axis=1,\n        parallel=parallel,\n        num_processes=num_processes,\n    )\n\n    # get areas\n    area_col = None\n    if weight_by_area:\n        area_col = \"nhood_areas\"\n        func = partial(nhood_vals, values=gdf.geometry.area)\n        gdf[area_col] = gdf_apply(\n            gdf,\n            func,\n            columns=[\"nhood\"],\n            axis=1,\n            parallel=parallel,\n            num_processes=num_processes,\n        )\n\n    if isinstance(val_col, str):\n        val_col = (val_col,)\n\n    # get character values\n    # Compute the neighborhood characters\n    col_prefix = \"\" if col_prefix is None else col_prefix\n    for col in val_col:\n        values = gdf[col]\n        char_col = f\"{col}_nhood_vals\"\n        func = partial(nhood_vals, values=values)\n        gdf[char_col] = gdf_apply(\n            gdf,\n            func,\n            columns=[\"nhood\"],\n            axis=1,\n            parallel=parallel,\n            num_processes=num_processes,\n        )\n\n        # loop over the reduction methods\n        for r in reductions:\n            columns = [char_col]\n            new_col = f\"{col_prefix}{col}_nhood_{r}\"\n            if area_col in gdf.columns:\n                columns.append(area_col)\n                new_col = f\"{col_prefix}{col}_nhood_{r}_area_weighted\"\n\n            func = partial(reduce, how=r)\n            gdf[new_col] = gdf_apply(\n                gdf,\n                func,\n                columns=columns,\n                axis=1,\n                parallel=parallel,\n                num_processes=num_processes,\n            )\n\n        if rm_nhood_cols:\n            gdf = gdf.drop(labels=[char_col], axis=1)\n\n    if rm_nhood_cols:\n        labs = [\"nhood\"]\n        if weight_by_area:\n            labs.append(area_col)\n        gdf = gdf.drop(labels=labs, axis=1)\n\n    return gdf\n</code></pre>"},{"location":"reference/cell_neighborhoods/local_distances_ref/","title":"local_distances","text":""},{"location":"reference/cell_neighborhoods/local_distances_ref/#cellseg_gsontools.character.local_distances","title":"<code>cellseg_gsontools.character.local_distances(gdf, spatial_weights, id_col=None, reductions=('mean'), weight_by_area=False, invert=False, parallel=True, num_processes=-1, rm_nhood_cols=True, col_prefix=None, create_copy=True)</code>","text":"<p>Compute the local sum/mean/median/min/max/std distance of the neighborhood distances for each geometry object in a gdf.</p> Note <p>Option to weight the nhood values by their area before reductions.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The input GeoDataFrame.</p> required <code>spatial_weights</code> <code>W</code> <p>Libpysal spatial weights object.</p> required <code>id_col</code> <code>str</code> <p>The unique id column in the gdf. If None, this uses <code>set_uid</code> to set it. Defaults to None.</p> <code>None</code> <code>reductions</code> <code>Tuple[str, ...]</code> <p>A list of reduction methods for the neighborhood. One of \"sum\", \"mean\", \"median\", \"min\", \"max\", \"std\". Defaults to (\"sum\", ).</p> <code>('mean')</code> <code>weight_by_area</code> <code>bool</code> <p>Flag whether to weight the neighborhood values by the area of the object. Defaults to False.</p> <code>False</code> <code>invert</code> <code>bool</code> <p>Flag whether to invert the distances. Defaults to False.</p> <code>False</code> <code>parallel</code> <code>bool</code> <p>Flag whether to use parallel apply operations when computing the character. Defaults to True.</p> <code>True</code> <code>num_processes</code> <code>int, default=-1</code> <p>The number of processes to use when parallel=True. If -1, this will use all available cores.</p> <code>-1</code> <code>rm_nhood_cols</code> <code>bool</code> <p>Flag, whether to remove the extra neighborhood columns from the result gdf. Defaults to True.</p> <code>True</code> <code>col_prefix</code> <code>str</code> <p>Prefix for the new column names.</p> <code>None</code> <code>create_copy</code> <code>bool</code> <p>Flag whether to create a copy of the input gdf and return that. Defaults to True.</p> <code>True</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The input geodataframe with computed distances column added.</p> <p>Examples:</p> <p>Compute the mean of eccentricity values for each neighborhood</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.character import local_distances\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; w = fit_graph(gdf, type=\"distband\", thres=75.0)\n&gt;&gt;&gt; local_distances(gdf, spatial_weights=w, reduction=[\"mean\"], weight_by_area=True)\n</code></pre> Source code in <code>cellseg_gsontools/character.py</code> <pre><code>def local_distances(\n    gdf: gpd.GeoDataFrame,\n    spatial_weights: W,\n    id_col: str = None,\n    reductions: Tuple[str, ...] = (\"mean\",),\n    weight_by_area: bool = False,\n    invert: bool = False,\n    parallel: bool = True,\n    num_processes: int = -1,\n    rm_nhood_cols: bool = True,\n    col_prefix: str = None,\n    create_copy: bool = True,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Compute the local sum/mean/median/min/max/std distance of the neighborhood\n    distances for each geometry object in a gdf.\n\n    Note:\n        Option to weight the nhood values by their area before reductions.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The input GeoDataFrame.\n        spatial_weights (libysal.weights.W):\n            Libpysal spatial weights object.\n        id_col (str):\n            The unique id column in the gdf. If None, this uses `set_uid` to set it.\n            Defaults to None.\n        reductions (Tuple[str, ...]):\n            A list of reduction methods for the neighborhood. One of \"sum\", \"mean\",\n            \"median\", \"min\", \"max\", \"std\". Defaults to (\"sum\", ).\n        weight_by_area (bool):\n            Flag whether to weight the neighborhood values by the area of the object.\n            Defaults to False.\n        invert (bool):\n            Flag whether to invert the distances. Defaults to False.\n        parallel (bool):\n            Flag whether to use parallel apply operations when computing the character.\n            Defaults to True.\n        num_processes (int, default=-1):\n            The number of processes to use when parallel=True. If -1,\n            this will use all available cores.\n        rm_nhood_cols (bool):\n            Flag, whether to remove the extra neighborhood columns from the result gdf.\n            Defaults to True.\n        col_prefix (str):\n            Prefix for the new column names.\n        create_copy (bool):\n            Flag whether to create a copy of the input gdf and return that.\n            Defaults to True.\n\n    Returns:\n        gpd.GeoDataFrame:\n            The input geodataframe with computed distances column added.\n\n    Examples:\n        Compute the mean of eccentricity values for each neighborhood\n        &gt;&gt;&gt; from cellseg_gsontools.character import local_distances\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; w = fit_graph(gdf, type=\"distband\", thres=75.0)\n        &gt;&gt;&gt; local_distances(gdf, spatial_weights=w, reduction=[\"mean\"], weight_by_area=True)\n    \"\"\"\n    allowed = (\"sum\", \"mean\", \"median\", \"min\", \"max\", \"std\")\n    if not all(r in allowed for r in reductions):\n        raise ValueError(\n            f\"Illegal reduction in `reductions`. Got: {reductions}. \"\n            f\"Allowed reductions: {allowed}.\"\n        )\n\n    if create_copy:\n        gdf = gdf.copy()\n\n    # set uid\n    if id_col is None:\n        id_col = \"uid\"\n        gdf = set_uid(gdf)\n\n    # get the immediate node neighborhood\n    func = partial(neighborhood, spatial_weights=spatial_weights)\n    gdf[\"nhood\"] = gdf_apply(\n        gdf,\n        func,\n        columns=[id_col],\n        axis=1,\n        parallel=parallel,\n        num_processes=num_processes,\n    )\n\n    # get areas\n    area_col = None\n    if weight_by_area:\n        func = partial(nhood_vals, values=gdf.geometry.area)\n        gdf[area_col] = gdf_apply(\n            gdf,\n            func,\n            columns=[\"nhood\"],\n            axis=1,\n            parallel=parallel,\n            num_processes=num_processes,\n        )\n\n    # get distances\n    func = partial(nhood_dists, centroids=gdf.centroid, invert=invert)\n    gdf[\"nhood_dists\"] = gdf_apply(\n        gdf,\n        func,\n        columns=[\"nhood\"],\n        axis=1,\n        parallel=parallel,\n        num_processes=num_processes,\n    )\n\n    col_prefix = \"\" if col_prefix is None else col_prefix\n\n    # loop over the reduction methods\n    for r in reductions:\n        columns = [\"nhood_dists\"]\n        new_col = f\"{col_prefix}nhood_dists_{r}\"\n        if area_col in gdf.columns:\n            columns.append(area_col)\n            new_col = f\"{col_prefix}nhood_dists_{r}_area_weighted\"\n\n        func = partial(reduce, how=r)\n        gdf[new_col] = gdf_apply(\n            gdf,\n            func,\n            columns=columns,\n            axis=1,\n            parallel=parallel,\n            num_processes=num_processes,\n        )\n\n    if rm_nhood_cols:\n        labs = [\"nhood\", \"nhood_dists\"]\n        if weight_by_area:\n            labs.append(area_col)\n        gdf = gdf.drop(labels=labs, axis=1)\n\n    return gdf\n</code></pre>"},{"location":"reference/cell_neighborhoods/local_diversity_ref/","title":"local_diversity","text":""},{"location":"reference/cell_neighborhoods/local_diversity_ref/#cellseg_gsontools.diversity.local_diversity","title":"<code>cellseg_gsontools.diversity.local_diversity(gdf, spatial_weights, val_col, id_col=None, metrics=('simpson_index'), scheme='FisherJenks', parallel=True, num_processes=-1, rm_nhood_cols=True, col_prefix=None, create_copy=True)</code>","text":"<p>Compute the local diversity/heterogenity metric for cell neighborhood.</p> Note <p>Allowed diversity metrics:</p> <ul> <li><code>simpson_index</code> - for both categorical and real valued neighborhoods</li> <li><code>shannon_index</code> - for both categorical and real valued neighborhoods</li> <li><code>gini_index</code> - for only real valued neighborhoods</li> <li><code>theil_index</code> - for only real valued neighborhoods</li> </ul> Note <p>If <code>val_col</code> is not categorical, the values are binned using <code>mapclassify</code>. The bins are then used to compute the diversity metrics. If <code>val_col</code> is categorical, the values are used directly.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The input GeoDataFrame.</p> required <code>spatial_weights</code> <code>W</code> <p>Libpysal spatial weights object.</p> required <code>val_col</code> <code>Union[str, Tuple[str, ...]]</code> <p>The name of the column in the gdf for which the diversity is computed. You can also pass in a list of columns, in which case the diversity is computed for each column.</p> required <code>id_col</code> <code>str</code> <p>The unique id column in the gdf. If None, this uses <code>set_uid</code> to set it. Defaults to None.</p> <code>None</code> <code>metrics</code> <code>Tuple[str, ...]</code> <p>A Tuple/List of diversity metrics. Allowed metrics: \"shannon_index\", \"simpson_index\", \"gini_index\", \"theil_index\". Defaults to None.</p> <code>('simpson_index')</code> <code>scheme</code> <code>str</code> <p><code>mapclassify</code> classification scheme. Defaults to \"FisherJenks\".</p> <code>'FisherJenks'</code> <code>parallel</code> <code>bool</code> <p>Flag whether to use parallel apply operations when computing the diversities. Defaults to True.</p> <code>True</code> <code>num_processes</code> <code>int, default=-1</code> <p>The number of processes to use when parallel=True. If -1, this will use all available cores.</p> <code>-1</code> <code>rm_nhood_cols</code> <code>bool</code> <p>Flag, whether to remove the extra neighborhood columns from the result gdf. Defaults to True.</p> <code>True</code> <code>col_prefix</code> <code>str</code> <p>Prefix for the new column names. Defaults to None.</p> <code>None</code> <code>create_copy</code> <code>bool</code> <p>Flag whether to create a copy of the input gdf or not. Defaults to True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an illegal metric is given.</p> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The input geodataframe with computed diversity metric columns added.</p> <p>Examples:</p> <p>Compute the simpson diversity of eccentricity values for each cell neighborhood</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.diversity import local_diversity\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; w = fit_graph(gdf, type=\"distband\", thres=75.0)\n&gt;&gt;&gt; local_diversity(\n...     gdf,\n...     spatial_weights=w_dist,\n...     val_col=\"eccentricity\",\n...     metrics=[\"simpson_index\"],\n... )\n</code></pre> Source code in <code>cellseg_gsontools/diversity.py</code> <pre><code>def local_diversity(\n    gdf: gpd.GeoDataFrame,\n    spatial_weights: W,\n    val_col: Union[str, Tuple[str, ...]],\n    id_col: str = None,\n    metrics: Tuple[str, ...] = (\"simpson_index\",),\n    scheme: str = \"FisherJenks\",\n    parallel: bool = True,\n    num_processes: int = -1,\n    rm_nhood_cols: bool = True,\n    col_prefix: str = None,\n    create_copy: bool = True,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Compute the local diversity/heterogenity metric for cell neighborhood.\n\n    Note:\n        Allowed diversity metrics:\n\n        - `simpson_index` - for both categorical and real valued neighborhoods\n        - `shannon_index` - for both categorical and real valued neighborhoods\n        - `gini_index` - for only real valued neighborhoods\n        - `theil_index` - for only real valued neighborhoods\n\n    Note:\n        If `val_col` is not categorical, the values are binned using `mapclassify`.\n        The bins are then used to compute the diversity metrics. If `val_col` is\n        categorical, the values are used directly.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The input GeoDataFrame.\n        spatial_weights (libysal.weights.W):\n            Libpysal spatial weights object.\n        val_col (Union[str, Tuple[str, ...]]):\n            The name of the column in the gdf for which the diversity is computed.\n            You can also pass in a list of columns, in which case the diversity is\n            computed for each column.\n        id_col (str):\n            The unique id column in the gdf. If None, this uses `set_uid` to set it.\n            Defaults to None.\n        metrics (Tuple[str, ...]):\n            A Tuple/List of diversity metrics. Allowed metrics: \"shannon_index\",\n            \"simpson_index\", \"gini_index\", \"theil_index\". Defaults to None.\n        scheme (str):\n            `mapclassify` classification scheme. Defaults to \"FisherJenks\".\n        parallel (bool):\n            Flag whether to use parallel apply operations when computing the diversities.\n            Defaults to True.\n        num_processes (int, default=-1):\n            The number of processes to use when parallel=True. If -1,\n            this will use all available cores.\n        rm_nhood_cols (bool):\n            Flag, whether to remove the extra neighborhood columns from the result gdf.\n            Defaults to True.\n        col_prefix (str):\n            Prefix for the new column names. Defaults to None.\n        create_copy (bool):\n            Flag whether to create a copy of the input gdf or not. Defaults to True.\n\n    Raises:\n        ValueError:\n            If an illegal metric is given.\n\n    Returns:\n        gpd.GeoDataFrame:\n            The input geodataframe with computed diversity metric columns added.\n\n    Examples:\n        Compute the simpson diversity of eccentricity values for each cell neighborhood\n        &gt;&gt;&gt; from cellseg_gsontools.diversity import local_diversity\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; w = fit_graph(gdf, type=\"distband\", thres=75.0)\n        &gt;&gt;&gt; local_diversity(\n        ...     gdf,\n        ...     spatial_weights=w_dist,\n        ...     val_col=\"eccentricity\",\n        ...     metrics=[\"simpson_index\"],\n        ... )\n    \"\"\"\n    allowed = list(DIVERSITY_LOOKUP.keys())\n    if not all(m in allowed for m in metrics):\n        raise ValueError(\n            f\"Illegal metric in `metrics`. Got: {metrics}. Allowed metrics: {allowed}.\"\n        )\n\n    if create_copy:\n        gdf = gdf.copy()\n\n    # set uid\n    if id_col is None:\n        id_col = \"uid\"\n        gdf = set_uid(gdf)\n\n    # If shannon or simpson index in metrics, counts are needed\n    ret_counts = False\n    if any([m in metrics for m in (\"simpson_index\", \"shannon_index\")]):\n        ret_counts = True\n\n    # If Gini is in metrics, neighboring values are needed\n    gt = (\"gini_index\", \"theil_index\")\n    ret_vals = False\n    if any([m in metrics for m in gt]):\n        ret_vals = True\n\n    # Get the immediate node neighborhood\n    func = partial(neighborhood, spatial_weights=spatial_weights)\n    gdf[\"nhood\"] = gdf_apply(\n        gdf,\n        func,\n        columns=[id_col],\n        axis=1,\n        parallel=parallel,\n        num_processes=num_processes,\n    )\n\n    if isinstance(val_col, str):\n        val_col = (val_col,)\n\n    for col in val_col:\n        values = gdf[col]\n\n        # Get bins if data not categorical\n        if not is_categorical(values):\n            bins = mapclassify.classify(values, scheme=scheme).bins\n        else:\n            bins = None\n\n        # Get the counts of the binned metric inside the neighborhoods\n        if ret_counts:\n            func = partial(nhood_counts, values=values, bins=bins)\n            gdf[f\"{col}_nhood_counts\"] = gdf_apply(\n                gdf,\n                func,\n                columns=[\"nhood\"],\n                axis=1,\n                parallel=parallel,\n                num_processes=num_processes,\n            )\n\n        if ret_vals:\n            func = partial(nhood_vals, values=values)\n            gdf[f\"{col}_nhood_vals\"] = gdf_apply(\n                gdf,\n                func,\n                columns=[\"nhood\"],\n                axis=1,\n                parallel=parallel,\n                num_processes=num_processes,\n            )\n\n        # Compute the diversity metrics for the neighborhood counts\n        for metric in metrics:\n            colname = f\"{col}_nhood_counts\" if metric not in gt else f\"{col}_nhood_vals\"\n\n            col_prefix = \"\" if col_prefix is None else col_prefix\n            gdf[f\"{col_prefix}{col}_{metric}\"] = gdf_apply(\n                gdf,\n                DIVERSITY_LOOKUP[metric],\n                columns=[colname],\n                parallel=parallel,\n                num_processes=num_processes,\n            )\n\n        if rm_nhood_cols:\n            gdf = gdf.drop(labels=[colname], axis=1)\n\n    if rm_nhood_cols:\n        gdf = gdf.drop(labels=[\"nhood\"], axis=1)\n\n    return gdf\n</code></pre>"},{"location":"reference/cell_neighbors/neighborhood_ref/","title":"neighborhood","text":""},{"location":"reference/cell_neighbors/neighborhood_ref/#cellseg_gsontools.neighbors.neighborhood","title":"<code>cellseg_gsontools.neighbors.neighborhood(node, spatial_weights, include_self=True, ret_n_neighbors=False)</code>","text":"<p>Get immediate neighborhood of a node given the spatial weights obj.</p> Note <p>This function is designed to be used with the <code>gdf_apply</code> function. See the example.</p> Note <p>The neighborhood contains the given node itself by default.</p> <p>Parameters:</p> Name Type Description Default <code>node</code> <code>int or Series</code> <p>Input node uid.</p> required <code>spatial_weights</code> <code>W</code> <p>Libpysal spatial weights object.</p> required <code>include_self</code> <code>bool</code> <p>Flag, whether to include the node itself in the neighborhood. Defaults to True.</p> <code>True</code> <code>ret_n_neighbors</code> <code>bool</code> <p>If True, instead of returning a sequence of the neighbor node uids returns just the number of neighbors. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>Union[List[int], int]</code> <p>List[int] or int: A list of the neighboring node uids. E.g. [1, 4, 19]. or the number of neighbors if <code>ret_n_neighbors=True</code>.</p> <p>Examples:</p> <p>Use <code>gdf_apply</code> to extract the neighboring nodes for each node/cell</p> <pre><code>&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n&gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n&gt;&gt;&gt; from cellseg_gsontools.neighbors import neighborhood\n&gt;&gt;&gt; gc = gland_cells()\n&gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n&gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n&gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n&gt;&gt;&gt; # Get the neihgboring nodes of the graph\n&gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n&gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n&gt;&gt;&gt; gc[\"nhood\"].head(5)\n        uid\n0       [0, 1, 3, 4, 483, 484]\n1     [1, 0, 4, 482, 483, 487]\n2       [2, 3, 5, 6, 484, 493]\n3      [3, 0, 2, 4, 5, 7, 484]\n4    [4, 0, 1, 3, 7, 487, 488]\nName: nhood, dtype: object\n</code></pre> Source code in <code>cellseg_gsontools/neighbors.py</code> <pre><code>def neighborhood(\n    node: Union[int, pd.Series],\n    spatial_weights: W,\n    include_self: bool = True,\n    ret_n_neighbors: bool = False,\n) -&gt; Union[List[int], int]:\n    \"\"\"Get immediate neighborhood of a node given the spatial weights obj.\n\n    Note:\n        This function is designed to be used with the `gdf_apply` function.\n        See the example.\n\n    Note:\n        The neighborhood contains the given node itself by default.\n\n    Parameters:\n        node (int or pd.Series):\n            Input node uid.\n        spatial_weights (libysal.weights.W):\n            Libpysal spatial weights object.\n        include_self (bool):\n            Flag, whether to include the node itself in the neighborhood.\n            Defaults to True.\n        ret_n_neighbors (bool):\n            If True, instead of returning a sequence of the neighbor node uids\n            returns just the number of neighbors. Defaults to False.\n\n    Returns:\n        List[int] or int:\n            A list of the neighboring node uids. E.g. [1, 4, 19].\n            or the number of neighbors if `ret_n_neighbors=True`.\n\n    Examples:\n        Use `gdf_apply` to extract the neighboring nodes for each node/cell\n        &gt;&gt;&gt; from functools import partial\n        &gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n        &gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n        &gt;&gt;&gt; from cellseg_gsontools.neighbors import neighborhood\n        &gt;&gt;&gt; gc = gland_cells()\n        &gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n        &gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n        &gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n        &gt;&gt;&gt; # Get the neihgboring nodes of the graph\n        &gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n        &gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n        &gt;&gt;&gt; gc[\"nhood\"].head(5)\n                uid\n        0       [0, 1, 3, 4, 483, 484]\n        1     [1, 0, 4, 482, 483, 487]\n        2       [2, 3, 5, 6, 484, 493]\n        3      [3, 0, 2, 4, 5, 7, 484]\n        4    [4, 0, 1, 3, 7, 487, 488]\n        Name: nhood, dtype: object\n    \"\"\"\n    if isinstance(node, pd.Series):\n        node = node.iloc[0]  # assume that the series is a row\n\n    nhood = np.nan\n    if ret_n_neighbors:\n        nhood = spatial_weights.cardinalities[node]\n    elif node in spatial_weights.neighbors.keys():\n        # get spatial neighborhood\n        nhood = spatial_weights.neighbors[node]\n        if include_self:\n            nhood = [node] + list(nhood)\n\n    return nhood\n</code></pre>"},{"location":"reference/cell_neighbors/nhood_counts_ref/","title":"nhood_counts","text":""},{"location":"reference/cell_neighbors/nhood_counts_ref/#cellseg_gsontools.neighbors.nhood_counts","title":"<code>cellseg_gsontools.neighbors.nhood_counts(nhood, values, bins, **kwargs)</code>","text":"<p>Get the counts of objects that belong to bins/classes in the neighborhood.</p> Note <p>This function is designed to be used with the <code>gdf_apply</code> function. See the example.</p> <p>Parameters:</p> Name Type Description Default <code>nhood</code> <code>Sequence[int]</code> <p>A list or array of neighboring node uids.</p> required <code>values</code> <code>Series</code> <p>A value column-vector of shape (N, ).</p> required <code>bins</code> <code>Sequence</code> <p>The bins of any value vector. Shape (n_bins, ).</p> required <code>return_vals</code> <code>bool</code> <p>If True, also, the values the values are. Defaults to False.</p> required <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Additional keyword arguments. Not used.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The counts vector of the given values vector. Shape (n_classes, )</p> <p>Examples:</p> <p>Use <code>gdf_apply</code> to compute the neighborhood counts for each areal bin</p> <pre><code>&gt;&gt;&gt; import mapclassify\n&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n&gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n&gt;&gt;&gt; from cellseg_gsontools.neighbors import neighborhood, nhood_vals, nhood_counts\n&gt;&gt;&gt; gc = gland_cells()\n&gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n&gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n&gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n&gt;&gt;&gt; # Get the neihgboring nodes of the graph\n&gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n&gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n&gt;&gt;&gt; # get the area values of the neighbors\n&gt;&gt;&gt; func = partial(nhood_vals, values=gc.area.round(2))\n&gt;&gt;&gt; gc[\"neighbor_areas\"] = gdf_apply(\n...     gc,\n...     func=func,\n...     parallel=True,\n...     columns=[\"nhood\"],\n... )\n&gt;&gt;&gt; bins = mapclassify.Quantiles(gc.area, k=5)\n&gt;&gt;&gt; func = partial(nhood_counts, values=gc.area, bins=bins.bins)\n&gt;&gt;&gt; gc[\"area_bins\"] = gdf_apply(\n...     gc,\n...     func,\n...     columns=[\"nhood\"],\n... )\n&gt;&gt;&gt; gc[\"area_bins\"].head(5)\nuid\n0    [0, 2, 0, 3, 1]\n1    [0, 2, 1, 2, 1]\n2    [0, 0, 0, 3, 3]\n3    [0, 1, 0, 3, 3]\n4    [0, 1, 0, 3, 3]\nName: area_bins, dtype: object\n</code></pre> Source code in <code>cellseg_gsontools/neighbors.py</code> <pre><code>def nhood_counts(\n    nhood: Sequence[int], values: pd.Series, bins: Sequence, **kwargs\n) -&gt; np.ndarray:\n    \"\"\"Get the counts of objects that belong to bins/classes in the neighborhood.\n\n    Note:\n        This function is designed to be used with the `gdf_apply` function.\n        See the example.\n\n    Parameters:\n        nhood (Sequence[int]):\n            A list or array of neighboring node uids.\n        values (pd.Series):\n            A value column-vector of shape (N, ).\n        bins (Sequence):\n            The bins of any value vector. Shape (n_bins, ).\n        return_vals (bool, optional):\n            If True, also, the values the values are. Defaults to False.\n        **kwargs (Dict[str, Any]):\n            Additional keyword arguments. Not used.\n\n    Returns:\n        np.ndarray:\n            The counts vector of the given values vector. Shape (n_classes, )\n\n    Examples:\n        Use `gdf_apply` to compute the neighborhood counts for each areal bin\n        &gt;&gt;&gt; import mapclassify\n        &gt;&gt;&gt; from functools import partial\n        &gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n        &gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n        &gt;&gt;&gt; from cellseg_gsontools.neighbors import neighborhood, nhood_vals, nhood_counts\n        &gt;&gt;&gt; gc = gland_cells()\n        &gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n        &gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n        &gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n        &gt;&gt;&gt; # Get the neihgboring nodes of the graph\n        &gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n        &gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n        &gt;&gt;&gt; # get the area values of the neighbors\n        &gt;&gt;&gt; func = partial(nhood_vals, values=gc.area.round(2))\n        &gt;&gt;&gt; gc[\"neighbor_areas\"] = gdf_apply(\n        ...     gc,\n        ...     func=func,\n        ...     parallel=True,\n        ...     columns=[\"nhood\"],\n        ... )\n        &gt;&gt;&gt; bins = mapclassify.Quantiles(gc.area, k=5)\n        &gt;&gt;&gt; func = partial(nhood_counts, values=gc.area, bins=bins.bins)\n        &gt;&gt;&gt; gc[\"area_bins\"] = gdf_apply(\n        ...     gc,\n        ...     func,\n        ...     columns=[\"nhood\"],\n        ... )\n        &gt;&gt;&gt; gc[\"area_bins\"].head(5)\n        uid\n        0    [0, 2, 0, 3, 1]\n        1    [0, 2, 1, 2, 1]\n        2    [0, 0, 0, 3, 3]\n        3    [0, 1, 0, 3, 3]\n        4    [0, 1, 0, 3, 3]\n        Name: area_bins, dtype: object\n    \"\"\"\n    if isinstance(nhood, pd.Series):\n        nhood = nhood.iloc[0]  # assume that the series is a row\n\n    counts = np.array([0])\n    if nhood not in (None, np.nan) and isinstance(nhood, (Sequence, np.ndarray)):\n        nhood_vals = values.loc[nhood]\n\n        if is_categorical(nhood_vals):\n            counts = nhood_vals.value_counts().values\n        else:\n            sample_bins = mapclassify.UserDefined(nhood_vals, bins)\n            counts = sample_bins.counts\n\n    return counts\n</code></pre>"},{"location":"reference/cell_neighbors/nhood_dists_ref/","title":"nhood_dists","text":""},{"location":"reference/cell_neighbors/nhood_dists_ref/#cellseg_gsontools.neighbors.nhood_dists","title":"<code>cellseg_gsontools.neighbors.nhood_dists(nhood, centroids, ids=None, invert=False)</code>","text":"<p>Compute the neighborhood distances between the center node.</p> Note <p>This function is designed to be used with the <code>gdf_apply</code> function. See the example.</p> Note <p>It is assumed that the center node is the first index in the <code>nhood</code> array. Use <code>include_self=True</code> in <code>neighborhood</code> to include the center.</p> <p>Parameters:</p> Name Type Description Default <code>nhood</code> <code>Sequence[int]</code> <p>An array containing neighbor indices. The first index is assumed to be the center node.</p> required <code>centroids</code> <code>Series</code> <p>A pd.Series array containing the centroid Points of the full gdf.</p> required <code>ids</code> <code>Series</code> <p>A pd.Series array containing the ids of the full gdf.</p> <code>None</code> <code>invert</code> <code>bool</code> <p>Flag, whether to invert the distances. E.g. 1/dists. Defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: An array containing the distances between the center node and its neighborhood.</p> <p>Examples:</p> <p>Use <code>gdf_apply</code> to extract the neighboring node distances for each node/cell</p> <pre><code>&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n&gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n&gt;&gt;&gt; from cellseg_gsontools.neighbors import neighborhood, nhood_dists\n&gt;&gt;&gt; gc = gland_cells()\n&gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n&gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n&gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n&gt;&gt;&gt; # Get the neihgboring nodes of the graph\n&gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n&gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n&gt;&gt;&gt; func = partial(nhood_dists, centroids=gc.centroid)\n&gt;&gt;&gt; gc[\"nhood_dists\"] = gdf_apply(\n...     gc,\n...     func,\n...     columns=[\"nhood\"],\n... )\n&gt;&gt;&gt; gc[\"nhood_dists\"].head(5)\nuid\n0        [0.0, 26.675, 24.786, 30.068, 30.228, 41.284]\n1        [0.0, 26.675, 23.428, 42.962, 39.039, 23.949]\n2        [0.0, 25.577, 39.348, 46.097, 34.309, 29.478]\n3    [0.0, 24.786, 25.577, 39.574, 37.829, 47.16, 3...\n4    [0.0, 30.068, 23.428, 39.574, 29.225, 36.337, ...\nName: nhood_dists, dtype: object\n</code></pre> Source code in <code>cellseg_gsontools/neighbors.py</code> <pre><code>def nhood_dists(\n    nhood: Sequence[int],\n    centroids: pd.Series,\n    ids: pd.Series = None,\n    invert: bool = False,\n) -&gt; np.ndarray:\n    \"\"\"Compute the neighborhood distances between the center node.\n\n    Note:\n        This function is designed to be used with the `gdf_apply` function.\n        See the example.\n\n    Note:\n        It is assumed that the center node is the first index in the `nhood`\n        array. Use `include_self=True` in `neighborhood` to include the center.\n\n    Parameters:\n        nhood (Sequence[int]):\n            An array containing neighbor indices. The first index is assumed to be\n            the center node.\n        centroids (pd.Series):\n            A pd.Series array containing the centroid Points of the full gdf.\n        ids (pd.Series):\n            A pd.Series array containing the ids of the full gdf.\n        invert (bool):\n            Flag, whether to invert the distances. E.g. 1/dists. Defaults to False.\n\n    Returns:\n        np.ndarray:\n            An array containing the distances between the center node and its\n            neighborhood.\n\n    Examples:\n        Use `gdf_apply` to extract the neighboring node distances for each node/cell\n        &gt;&gt;&gt; from functools import partial\n        &gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n        &gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n        &gt;&gt;&gt; from cellseg_gsontools.neighbors import neighborhood, nhood_dists\n        &gt;&gt;&gt; gc = gland_cells()\n        &gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n        &gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n        &gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n        &gt;&gt;&gt; # Get the neihgboring nodes of the graph\n        &gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n        &gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n        &gt;&gt;&gt; func = partial(nhood_dists, centroids=gc.centroid)\n        &gt;&gt;&gt; gc[\"nhood_dists\"] = gdf_apply(\n        ...     gc,\n        ...     func,\n        ...     columns=[\"nhood\"],\n        ... )\n        &gt;&gt;&gt; gc[\"nhood_dists\"].head(5)\n        uid\n        0        [0.0, 26.675, 24.786, 30.068, 30.228, 41.284]\n        1        [0.0, 26.675, 23.428, 42.962, 39.039, 23.949]\n        2        [0.0, 25.577, 39.348, 46.097, 34.309, 29.478]\n        3    [0.0, 24.786, 25.577, 39.574, 37.829, 47.16, 3...\n        4    [0.0, 30.068, 23.428, 39.574, 29.225, 36.337, ...\n        Name: nhood_dists, dtype: object\n    \"\"\"\n    if isinstance(nhood, pd.Series):\n        nhood = nhood.iloc[0]  # assume that the series is a row\n\n    nhood_dists = np.array([0])\n    if nhood not in (None, np.nan) and isinstance(nhood, (Sequence, np.ndarray)):\n        if ids is not None:\n            nhood = ids[ids.isin(nhood)].index\n\n        node = nhood[0]\n        center_node = centroids.loc[node]\n        nhood_nodes = centroids.loc[nhood].to_numpy()\n        nhood_dists = np.array(\n            [np.round(_dist(center_node, c), 3) for c in nhood_nodes]\n        )\n        if invert:\n            nhood_dists = np.round(np.reciprocal(nhood_dists, where=nhood_dists &gt; 0), 3)\n\n    return nhood_dists\n</code></pre>"},{"location":"reference/cell_neighbors/nhood_type_count_ref/","title":"nhood_type_count","text":""},{"location":"reference/cell_neighbors/nhood_type_count_ref/#cellseg_gsontools.neighbors.nhood_type_count","title":"<code>cellseg_gsontools.neighbors.nhood_type_count(cls_neighbors, cls, frac=True, **kwargs)</code>","text":"<p>Get the number of nodes of a specific category in a neighborhood of a node.</p> Note <p>This function is designed to be used with the <code>gdf_apply</code> function. See the example.</p> <p>Parameters:</p> Name Type Description Default <code>cls_neihbors</code> <code>Sequence</code> <p>A array/list (int or str) containing a category for each value in the data.</p> required <code>cls</code> <code>int or str</code> <p>The specific category.</p> required <code>frac</code> <code>bool</code> <p>Flag, whether to return the fraction instead of the count. Defaults to True.</p> <code>True</code> <code>**kwargs</code> <code>Dict[str, Any])]</code> <p>Additional keyword arguments. Not used.</p> <code>{}</code> <p>Returns:     float:         The count or fraction of a node of specific category in a neighborhood.</p> <p>Raises:</p> Type Description <code>TypeError</code> <p>If the <code>cls_neighbors</code> is not categorical.</p> <p>Examples:</p> <p>Use <code>gdf_apply</code> to get the neighborhood fractions of immune cells for each node</p> <pre><code>&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n&gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n&gt;&gt;&gt; from cellseg_gsontools.neighbors import (\n...     neighborhood,\n...     nhood_vals,\n...     hnood_type_count,\n... )\n&gt;&gt;&gt; gc = gland_cells()\n&gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n&gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n&gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n&gt;&gt;&gt; # Get the neihgboring nodes of the graph\n&gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n&gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n&gt;&gt;&gt; # get the classes of the neighbors\n&gt;&gt;&gt; func = partial(nhood_vals, values=gc.class_name)\n&gt;&gt;&gt; gc[\"neighbor_classes\"] = gdf_apply(\n...     gc,\n...     func=func,\n...     parallel=True,\n...     columns=[\"nhood\"],\n... )\n&gt;&gt;&gt; func = partial(nhood_type_count, cls=\"inflammatory\", frac=True)\n&gt;&gt;&gt; gc[\"n_immune_neighbors\"] = gdf_apply(\n...    gc,\n...    func=func,\n...    parallel=True,\n...    columns=[\"neighbor_classes\"],\n&gt;&gt;&gt; )\n&gt;&gt;&gt; gc[gc[\"n_immune_neighbors\"] &gt; 0][\"n_immune_neighbors\"].head(5)\nuid\n39    0.333333\n40    0.111111\n42    0.166667\n44    0.375000\n48    0.166667\nName: n_immune_neighbors, dtype: float64\n</code></pre> Source code in <code>cellseg_gsontools/neighbors.py</code> <pre><code>def nhood_type_count(\n    cls_neighbors: Sequence, cls: Union[int, str], frac: bool = True, **kwargs\n) -&gt; float:\n    \"\"\"Get the number of nodes of a specific category in a neighborhood of a node.\n\n    Note:\n        This function is designed to be used with the `gdf_apply` function.\n        See the example.\n\n    Parameters:\n        cls_neihbors (Sequence):\n            A array/list (int or str) containing a category for each value in the data.\n        cls (int or str):\n            The specific category.\n        frac (bool, optional):\n            Flag, whether to return the fraction instead of the count. Defaults to True.\n        **kwargs (Dict[str, Any])]):\n            Additional keyword arguments. Not used.\n    Returns:\n        float:\n            The count or fraction of a node of specific category in a neighborhood.\n\n    Raises:\n        TypeError:\n            If the `cls_neighbors` is not categorical.\n\n    Examples:\n        Use `gdf_apply` to get the neighborhood fractions of immune cells for each node\n        &gt;&gt;&gt; from functools import partial\n        &gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n        &gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n        &gt;&gt;&gt; from cellseg_gsontools.neighbors import (\n        ...     neighborhood,\n        ...     nhood_vals,\n        ...     hnood_type_count,\n        ... )\n        &gt;&gt;&gt; gc = gland_cells()\n        &gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n        &gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n        &gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n        &gt;&gt;&gt; # Get the neihgboring nodes of the graph\n        &gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n        &gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n        &gt;&gt;&gt; # get the classes of the neighbors\n        &gt;&gt;&gt; func = partial(nhood_vals, values=gc.class_name)\n        &gt;&gt;&gt; gc[\"neighbor_classes\"] = gdf_apply(\n        ...     gc,\n        ...     func=func,\n        ...     parallel=True,\n        ...     columns=[\"nhood\"],\n        ... )\n        &gt;&gt;&gt; func = partial(nhood_type_count, cls=\"inflammatory\", frac=True)\n        &gt;&gt;&gt; gc[\"n_immune_neighbors\"] = gdf_apply(\n        ...    gc,\n        ...    func=func,\n        ...    parallel=True,\n        ...    columns=[\"neighbor_classes\"],\n        &gt;&gt;&gt; )\n        &gt;&gt;&gt; gc[gc[\"n_immune_neighbors\"] &gt; 0][\"n_immune_neighbors\"].head(5)\n        uid\n        39    0.333333\n        40    0.111111\n        42    0.166667\n        44    0.375000\n        48    0.166667\n        Name: n_immune_neighbors, dtype: float64\n    \"\"\"\n    if isinstance(cls_neighbors, pd.Series):\n        cls_neighbors = cls_neighbors.iloc[0]  # assume that the series is a row\n\n    ret = 0\n    if isinstance(cls_neighbors, (Sequence, np.ndarray)):\n        if len(cls_neighbors) &gt; 0:\n            if not isinstance(cls_neighbors[0], (int, str)):\n                raise TypeError(\"cls_neighbors must contain int of str values.\")\n\n        t, c = np.unique(cls_neighbors, return_counts=True)\n\n        ret = 0.0\n        if cls in t:\n            ix = np.where(t == cls)\n            ret = c[ix][0]\n            if frac:\n                ret = ret / np.sum(c)\n\n    return ret\n</code></pre>"},{"location":"reference/cell_neighbors/nhood_vals_ref/","title":"nhood_vals","text":""},{"location":"reference/cell_neighbors/nhood_vals_ref/#cellseg_gsontools.neighbors.nhood_vals","title":"<code>cellseg_gsontools.neighbors.nhood_vals(nhood, values, **kwargs)</code>","text":"<p>Get the values of objects in the neighboring nodes.</p> Note <p>This function is designed to be used with the <code>gdf_apply</code> function. See the example.</p> <p>Parameters:</p> Name Type Description Default <code>nhood</code> <code>Sequence[int]</code> <p>A list or array of neighboring node uids.</p> required <code>values</code> <code>Series</code> <p>A value column-vector of shape (N, ).</p> required <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Additional keyword arguments. Not used.</p> <code>{}</code> <p>Returns:</p> Type Description <code>ndarray</code> <p>np.ndarray: The counts vector of the given values vector. Shape (n_classes, )</p> <p>Examples:</p> <p>Use <code>gdf_apply</code> to get the neighborhood values for each area of a cell</p> <pre><code>&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n&gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n&gt;&gt;&gt; from cellseg_gsontools.neighbors import neighborhood, nhood_vals\n&gt;&gt;&gt; gc = gland_cells()\n&gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n&gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n&gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n&gt;&gt;&gt; # Get the neihgboring nodes of the graph\n&gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n&gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n&gt;&gt;&gt; # get the area values of the neighbors\n&gt;&gt;&gt; func = partial(nhood_vals, values=gc.area.round(2))\n&gt;&gt;&gt; gc[\"neighbor_areas\"] = gdf_apply(\n...     gc,\n...     func=func,\n...     parallel=True,\n...     columns=[\"nhood\"],\n... )\n&gt;&gt;&gt; gc[\"neighbor_areas\"].head(5)\n    uid\n0     [520.24, 565.58, 435.91, 302.26, 241.85, 418.02]\n1     [565.58, 520.24, 302.26, 318.15, 241.85, 485.71]\n2      [721.5, 435.91, 556.05, 466.96, 418.02, 678.35]\n3    [435.91, 520.24, 721.5, 302.26, 556.05, 655.42...\n4    [302.26, 520.24, 565.58, 435.91, 655.42, 485.7...\nName: neighbor_areas, dtype: object\n</code></pre> Source code in <code>cellseg_gsontools/neighbors.py</code> <pre><code>def nhood_vals(nhood: Sequence[int], values: pd.Series, **kwargs) -&gt; np.ndarray:\n    \"\"\"Get the values of objects in the neighboring nodes.\n\n    Note:\n        This function is designed to be used with the `gdf_apply` function.\n        See the example.\n\n    Parameters:\n        nhood (Sequence[int]):\n            A list or array of neighboring node uids.\n        values (pd.Series):\n            A value column-vector of shape (N, ).\n        **kwargs (Dict[str, Any]):\n            Additional keyword arguments. Not used.\n\n    Returns:\n        np.ndarray:\n            The counts vector of the given values vector. Shape (n_classes, )\n\n    Examples:\n        Use `gdf_apply` to get the neighborhood values for each area of a cell\n        &gt;&gt;&gt; from functools import partial\n        &gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; from cellseg_gsontools.utils import set_uid\n        &gt;&gt;&gt; from cellseg_gsontools.apply import gdf_apply\n        &gt;&gt;&gt; from cellseg_gsontools.neighbors import neighborhood, nhood_vals\n        &gt;&gt;&gt; gc = gland_cells()\n        &gt;&gt;&gt; # To fit the delaunay graph, we need to set a unique id for each cell first\n        &gt;&gt;&gt; gc = set_uid(gc, id_col=\"uid\")\n        &gt;&gt;&gt; w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\n        &gt;&gt;&gt; # Get the neihgboring nodes of the graph\n        &gt;&gt;&gt; func = partial(neighborhood, spatial_weights=w)\n        &gt;&gt;&gt; gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n        &gt;&gt;&gt; # get the area values of the neighbors\n        &gt;&gt;&gt; func = partial(nhood_vals, values=gc.area.round(2))\n        &gt;&gt;&gt; gc[\"neighbor_areas\"] = gdf_apply(\n        ...     gc,\n        ...     func=func,\n        ...     parallel=True,\n        ...     columns=[\"nhood\"],\n        ... )\n        &gt;&gt;&gt; gc[\"neighbor_areas\"].head(5)\n            uid\n        0     [520.24, 565.58, 435.91, 302.26, 241.85, 418.02]\n        1     [565.58, 520.24, 302.26, 318.15, 241.85, 485.71]\n        2      [721.5, 435.91, 556.05, 466.96, 418.02, 678.35]\n        3    [435.91, 520.24, 721.5, 302.26, 556.05, 655.42...\n        4    [302.26, 520.24, 565.58, 435.91, 655.42, 485.7...\n        Name: neighbor_areas, dtype: object\n    \"\"\"\n    if isinstance(nhood, pd.Series):\n        nhood = nhood.iloc[0]  # assume that the series is a row\n\n    nhood_vals = np.array([0])\n    if nhood not in (None, np.nan) and isinstance(nhood, (Sequence, np.ndarray)):\n        nhood_vals = values.loc[nhood].to_numpy()\n\n    return nhood_vals\n</code></pre>"},{"location":"reference/clustering/cluster_cells_ref/","title":"cluster_cells","text":""},{"location":"reference/clustering/cluster_cells_ref/#cellseg_gsontools.clustering.cluster_cells","title":"<code>cellseg_gsontools.clustering.cluster_cells(cells, cell_type='inflammatory', graph_type='distband', dist_thresh=100, min_size=10, seed=42, spatial_weights=None)</code>","text":"<p>Cluster the cells of the given type.</p> <p>Uses Local Moran analysis to find the LISA clusters of the cells.</p> Note <p>LISA is short for local indicator of spatial association. You can read more, for example, from: - https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html#lisa-principle. The LISA clusters are calculated using the local Moran analysis. The cluster labels are set to HH, LL, LH, HL.</p> Note <p>In this function, the local statistic used to form the clusters is the fraction of objects of type <code>label</code> in the neighborhood times the absolute number of the objects of type <code>label</code> in the neighborhood. Due to the stochastic nature of the LISA analysis, the clustering results may wary marginally between runs if seed is changed. This is due to the random selection of the permutations in the local Moran analysis.</p> <p>Parameters:</p> Name Type Description Default <code>cells</code> <code>GeoDataFrame</code> <p>The GeoDataFrame with the cells.</p> required <code>cell_type</code> <code>str</code> <p>The class name of the cells to cluster.</p> <code>'inflammatory'</code> <code>graph_type</code> <code>str</code> <p>The type of graph to fit. Options are \"delaunay\", \"knn\" and \"distband\".</p> <code>'distband'</code> <code>dist_thresh</code> <code>int</code> <p>The distance threshold to use for the graph.</p> <code>100</code> <code>min_size</code> <code>int</code> <p>The minimum size of the cluster to assign a label.</p> <code>10</code> <code>seed</code> <code>int</code> <p>The random seed to use in the Moran_Local analysis.</p> <code>42</code> <code>spatial_weights</code> <code>W</code> <p>The spatial weights object to use in the analysis. If None, the spatial weights are calculated.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>clustered_cells</code> <code>GeoDataFrame</code> <p>The GeoDataFrame with the clustered cells.</p> <p>Examples:</p> <p>Cluster the inflammatory cells in a GeoDataFrame.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.clustering import cluster_cells\n&gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf\n&gt;&gt;&gt; cells = read_gdf(\"cells.geojson\")\n&gt;&gt;&gt; clustered_cells = cluster_cells(cells, cell_type=\"inflammatory\", seed=42)\n    class_name    geometry                            lisa_label    label\nuid\n0    inflammatory  POLYGON ((64.00 115.020, 69.010 ...  HH            0\n1    inflammatory  POLYGON ((65.00 15.020, 61.010 ...   HH            0\n2   inflammatory  POLYGON ((66.00 110.020, 69.010 ...   HH            2\n</code></pre> Source code in <code>cellseg_gsontools/clustering.py</code> <pre><code>def cluster_cells(\n    cells: gpd.GeoDataFrame,\n    cell_type: str = \"inflammatory\",\n    graph_type: str = \"distband\",\n    dist_thresh: int = 100,\n    min_size: int = 10,\n    seed: int = 42,\n    spatial_weights: W = None,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Cluster the cells of the given type.\n\n    Uses Local Moran analysis to find the LISA clusters of the cells.\n\n    Note:\n        LISA is short for local indicator of spatial association. You can read more,\n        for example, from:\n        - https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html#lisa-principle.\n        The LISA clusters are calculated using the local Moran analysis. The cluster\n        labels are set to HH, LL, LH, HL.\n\n    Note:\n        In this function, the local statistic used to form the clusters is the fraction\n        of objects of type `label` in the neighborhood times the absolute number of the\n        objects of type `label` in the neighborhood. Due to the stochastic nature of the\n        LISA analysis, the clustering results may wary marginally between runs if seed is\n        changed. This is due to the random selection of the permutations in the\n        local Moran analysis.\n\n    Parameters:\n        cells (gpd.GeoDataFrame):\n            The GeoDataFrame with the cells.\n        cell_type (str):\n            The class name of the cells to cluster.\n        graph_type (str):\n            The type of graph to fit. Options are \"delaunay\", \"knn\" and \"distband\".\n        dist_thresh (int):\n            The distance threshold to use for the graph.\n        min_size (int):\n            The minimum size of the cluster to assign a label.\n        seed (int):\n            The random seed to use in the Moran_Local analysis.\n        spatial_weights (W):\n            The spatial weights object to use in the analysis.\n            If None, the spatial weights are calculated.\n\n    Returns:\n        clustered_cells (gpd.GeoDataFrame):\n            The GeoDataFrame with the clustered cells.\n\n    Examples:\n        Cluster the inflammatory cells in a GeoDataFrame.\n\n        &gt;&gt;&gt; from cellseg_gsontools.clustering import cluster_cells\n        &gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf\n        &gt;&gt;&gt; cells = read_gdf(\"cells.geojson\")\n        &gt;&gt;&gt; clustered_cells = cluster_cells(cells, cell_type=\"inflammatory\", seed=42)\n            class_name    geometry                            lisa_label    label\n        uid\n        0    inflammatory  POLYGON ((64.00 115.020, 69.010 ...  HH            0\n        1    inflammatory  POLYGON ((65.00 15.020, 61.010 ...   HH            0\n        2   inflammatory  POLYGON ((66.00 110.020, 69.010 ...   HH            2\n\n    \"\"\"\n    # Find the LISA clusters\n    lisa_labels, w = find_lisa_clusters(\n        cells,\n        label=cell_type,\n        graph_type=graph_type,\n        dist_thresh=dist_thresh,\n        seed=seed,\n        spatial_weights=spatial_weights,\n    )\n    cells[\"lisa_label\"] = lisa_labels\n\n    # Select the HH clusters\n    clustered_cells = cells.loc[\n        (cells[\"class_name\"] == cell_type) &amp; (cells[\"lisa_label\"] == \"HH\")\n    ]\n    clustered_cells = clustered_cells.assign(label=-1)\n\n    # Get the connected components\n    sub_graphs = get_connected_components(clustered_cells, w)\n    clustered_cells = label_connected_components(\n        clustered_cells, sub_graphs, \"label\", min_size=min_size\n    )\n    clustered_cells.set_crs(4328, inplace=True, allow_override=True)\n\n    # drop too small clusters\n    clustered_cells = clustered_cells.loc[clustered_cells[\"label\"] != -1]\n\n    return clustered_cells\n</code></pre>"},{"location":"reference/clustering/cluster_points_ref/","title":"cluster_points","text":""},{"location":"reference/clustering/cluster_points_ref/#cellseg_gsontools.clustering.cluster_points","title":"<code>cellseg_gsontools.clustering.cluster_points(gdf, eps=350.0, min_samples=30, method='dbscan', n_jobs=-1, **kwargs)</code>","text":"<p>Apply a clustering to centroids in a gdf.</p> <p>This is just a quick wrapper for a few clustering algos adapted to geodataframes.</p> Note <p>Allowed clustering methods are:</p> <ul> <li><code>dbscan</code> (sklearn.cluster.DBSCAN)</li> <li><code>hdbscan</code> (sklearn.cluster.HDBSCAN)</li> <li><code>optics</code> (sklearn.cluster.OPTICS)</li> <li><code>adbscan</code> (esda.adbscan.ADBSCAN)</li> </ul> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>Input geo dataframe with a properly set geometry column.</p> required <code>eps</code> <code>float</code> <p>The maximum distance between two samples for one to be considered as in the neighborhood of the other. This is not a maximum bound on the distances of gdf within a cluster.</p> <code>350.0</code> <code>min_samples</code> <code>int</code> <p>The number of samples (or total weight) in a neighborhood for a point to be considered as a core point. This includes the point itself.</p> <code>30</code> <code>method</code> <code>str</code> <p>The clustering method to be used. Allowed: (\"dbscan\", \"adbscan\", \"optics\").</p> <code>'dbscan'</code> <code>n_jobs</code> <code>int</code> <p>The number of parallel jobs to run. None means 1. -1 means using all processors.</p> <code>-1</code> <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Arbitrary key-word arguments passed to the clustering methods.</p> <code>{}</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If illegal method is given or input <code>gdf</code> is of wrong type.</p> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The input gdf with a new \"labels\" columns of the clusters.</p> <p>Examples:</p> <p>Cluster immune cell centroids in a gdf using dbscan.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.clustering import cluster_points\n&gt;&gt;&gt; gdf = read_gdf(\"cells.json\")\n&gt;&gt;&gt; gdf = cluster_points(\n...     gdf[gdf[\"class_name\"] == \"immune\"],\n...     method=\"dbscan\",\n...     eps=350.0,\n...     min_samples=30,\n... )\n</code></pre> Source code in <code>cellseg_gsontools/clustering.py</code> <pre><code>def cluster_points(\n    gdf: gpd.GeoDataFrame,\n    eps: float = 350.0,\n    min_samples: int = 30,\n    method: str = \"dbscan\",\n    n_jobs: int = -1,\n    **kwargs,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Apply a clustering to centroids in a gdf.\n\n    This is just a quick wrapper for a few clustering algos adapted\n    to geodataframes.\n\n    Note:\n        Allowed clustering methods are:\n\n        - `dbscan` (sklearn.cluster.DBSCAN)\n        - `hdbscan` (sklearn.cluster.HDBSCAN)\n        - `optics` (sklearn.cluster.OPTICS)\n        - `adbscan` (esda.adbscan.ADBSCAN)\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            Input geo dataframe with a properly set geometry column.\n        eps (float):\n            The maximum distance between two samples for one to be considered as in the\n            neighborhood of the other. This is not a maximum bound on the distances of\n            gdf within a cluster.\n        min_samples (int):\n            The number of samples (or total weight) in a neighborhood for a point to be\n            considered as a core point. This includes the point itself.\n        method (str):\n            The clustering method to be used. Allowed: (\"dbscan\", \"adbscan\", \"optics\").\n        n_jobs (int):\n            The number of parallel jobs to run. None means 1. -1 means using all\n            processors.\n        **kwargs (Dict[str, Any]):\n            Arbitrary key-word arguments passed to the clustering methods.\n\n    Raises:\n        ValueError:\n            If illegal method is given or input `gdf` is of wrong type.\n\n    Returns:\n        gpd.GeoDataFrame:\n            The input gdf with a new \"labels\" columns of the clusters.\n\n    Examples:\n        Cluster immune cell centroids in a gdf using dbscan.\n\n        &gt;&gt;&gt; from cellseg_gsontools.clustering import cluster_points\n        &gt;&gt;&gt; gdf = read_gdf(\"cells.json\")\n        &gt;&gt;&gt; gdf = cluster_points(\n        ...     gdf[gdf[\"class_name\"] == \"immune\"],\n        ...     method=\"dbscan\",\n        ...     eps=350.0,\n        ...     min_samples=30,\n        ... )\n    \"\"\"\n    allowed = (\"dbscan\", \"adbscan\", \"optics\", \"hdbscan\")\n    if method not in allowed:\n        raise ValueError(\n            f\"Illegal clustering method was given. Got: {method}, allowed: {allowed}\"\n        )\n\n    if isinstance(gdf, gpd.GeoDataFrame):\n        xy = np.vstack([gdf.centroid.x, gdf.centroid.y]).T\n    else:\n        raise ValueError(\n            \"The input `gdf` needs to be a gpd.GeoDataFrame with geometry col \"\n            f\"Got: {type(gdf)}\"\n        )\n\n    if method == \"adbscan\":\n        try:\n            from esda.adbscan import ADBSCAN\n        except ImportError:\n            raise ImportError(\n                \"The adbscan method requires the esda package to be installed.\"\n                \"Install it with: pip install esda\"\n            )\n        xy = pd.DataFrame({\"X\": xy[:, 0], \"Y\": xy[:, 1]})\n        clusterer = ADBSCAN(eps=eps, min_samples=min_samples, n_jobs=n_jobs, **kwargs)\n    elif method == \"dbscan\":\n        clusterer = DBSCAN(eps=eps, min_samples=min_samples, n_jobs=n_jobs, **kwargs)\n    elif method == \"hdbscan\":\n        clusterer = HDBSCAN(min_samples=min_samples, n_jobs=n_jobs, **kwargs)\n    elif method == \"optics\":\n        clusterer = OPTICS(\n            max_eps=eps, min_samples=min_samples, n_jobs=n_jobs, **kwargs\n        )\n\n    labels = clusterer.fit(xy).labels_\n    gdf[\"labels\"] = labels\n\n    return gdf\n</code></pre>"},{"location":"reference/clustering/find_lisa_clusters_ref/","title":"find_lisa_clusters","text":""},{"location":"reference/clustering/find_lisa_clusters_ref/#cellseg_gsontools.clustering.find_lisa_clusters","title":"<code>cellseg_gsontools.clustering.find_lisa_clusters(gdf, label, graph_type='distband', dist_thresh=100, permutations=100, seed=42, spatial_weights=None)</code>","text":"<p>Calculate LISA clusters of objects with <code>class_name=label</code>.</p> Note <p>LISA is short for local indicator of spatial association. You can read more, for example, from: - https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html#lisa-principle. The LISA clusters are calculated using the local Moran analysis. The cluster labels are set to HH, LL, LH, HL.</p> Note <p>In this function, the local statistic used to form the clusters is the fraction of objects of type <code>label</code> in the neighborhood times the absolute number of the objects of type <code>label</code> in the neighborhood. Due to the stochastic nature of the LISA analysis, the clustering results may wary marginally between runs if seed is changed. This is due to the random selection of the permutations in the local Moran analysis.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The GeoDataFrame with the objects to calculate the LISA clusters of.</p> required <code>label</code> <code>str</code> <p>The class name to calculate the LISA clusters of.</p> required <code>graph_type</code> <code>str</code> <p>The type of graph to fit. Options are \"delaunay\", \"knn\" and \"distband\".</p> <code>'distband'</code> <code>dist_thresh</code> <code>int</code> <p>The distance threshold to use for the graph.</p> <code>100</code> <code>permutations</code> <code>int</code> <p>The number of permutations to use in the Moran_Local analysis.</p> <code>100</code> <code>seed</code> <code>int</code> <p>The random seed to use in the Moran_Local analysis.</p> <code>42</code> <code>spatial_weights</code> <code>W</code> <p>The spatial weights object to use in the analysis. If None, the spatial weights are calculated.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>labels</code> <code>List[int]</code> <p>The cluster labels of the objects.</p> <code>w</code> <code>W</code> <p>The spatial weights object used in the analysis.</p> <p>Examples:</p> <p>Find the LISA clusters of inflammatory cells in a GeoDataFrame.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.clustering import find_lisa_clusters\n&gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf\n&gt;&gt;&gt; cells = read_gdf(\"cells.geojson\")\n&gt;&gt;&gt; labels, w = find_lisa_clusters(cells, label=\"inflammatory\", seed=42)\n</code></pre> Source code in <code>cellseg_gsontools/clustering.py</code> <pre><code>def find_lisa_clusters(\n    gdf: gpd.GeoDataFrame,\n    label: str,\n    graph_type: str = \"distband\",\n    dist_thresh: int = 100,\n    permutations: int = 100,\n    seed: int = 42,\n    spatial_weights: W = None,\n) -&gt; Tuple[List[int], W]:\n    \"\"\"Calculate LISA clusters of objects with `class_name=label`.\n\n    Note:\n        LISA is short for local indicator of spatial association. You can read more,\n        for example, from:\n        - https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html#lisa-principle.\n        The LISA clusters are calculated using the local Moran analysis. The cluster\n        labels are set to HH, LL, LH, HL.\n\n    Note:\n        In this function, the local statistic used to form the clusters is the fraction\n        of objects of type `label` in the neighborhood times the absolute number of the\n        objects of type `label` in the neighborhood. Due to the stochastic nature of the\n        LISA analysis, the clustering results may wary marginally between runs if seed is\n        changed. This is due to the random selection of the permutations in the\n        local Moran analysis.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The GeoDataFrame with the objects to calculate the LISA clusters of.\n        label (str):\n            The class name to calculate the LISA clusters of.\n        graph_type (str):\n            The type of graph to fit. Options are \"delaunay\", \"knn\" and \"distband\".\n        dist_thresh (int):\n            The distance threshold to use for the graph.\n        permutations (int):\n            The number of permutations to use in the Moran_Local analysis.\n        seed (int):\n            The random seed to use in the Moran_Local analysis.\n        spatial_weights (W):\n            The spatial weights object to use in the analysis.\n            If None, the spatial weights are calculated.\n\n    Returns:\n        labels (List[int]):\n            The cluster labels of the objects.\n        w (W):\n            The spatial weights object used in the analysis.\n\n    Examples:\n        Find the LISA clusters of inflammatory cells in a GeoDataFrame.\n        &gt;&gt;&gt; from cellseg_gsontools.clustering import find_lisa_clusters\n        &gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf\n        &gt;&gt;&gt; cells = read_gdf(\"cells.geojson\")\n        &gt;&gt;&gt; labels, w = find_lisa_clusters(cells, label=\"inflammatory\", seed=42)\n    \"\"\"\n    try:\n        import esda\n    except ImportError:\n        raise ImportError(\n            \"This function requires the esda package to be installed.\"\n            \"Install it with: pip install esda\"\n        )\n\n    if spatial_weights is not None:\n        w = spatial_weights\n    else:\n        # Fit the distband\n        w = fit_graph(\n            gdf,\n            type=graph_type,\n            id_col=\"uid\",\n            thresh=dist_thresh,\n        )\n\n        # Row-standardized weights\n        w.transform = \"R\"\n\n    # Get the neihgboring nodes of the graph\n    func = partial(neighborhood, spatial_weights=w)\n    gdf[\"nhood\"] = gdf_apply(gdf, func, columns=[\"uid\"])\n\n    # Get the classes of the neighboring nodes\n    func = partial(nhood_vals, values=gdf[\"class_name\"])\n    gdf[\"nhood_classes\"] = gdf_apply(\n        gdf,\n        func=func,\n        parallel=True,\n        columns=[\"nhood\"],\n    )\n\n    # Get the number of inflammatory gdf in the neighborhood\n    func = partial(nhood_type_count, cls=label, frac=False)\n    gdf[f\"{label}_cnt\"] = gdf_apply(\n        gdf,\n        func=func,\n        parallel=True,\n        columns=[\"nhood_classes\"],\n    )\n\n    # Get the fraction of objs of type `label` gdf in the neighborhood\n    func = partial(nhood_type_count, cls=label, frac=True)\n    gdf[f\"{label}_frac\"] = gdf_apply(\n        gdf,\n        func=func,\n        parallel=True,\n        columns=[\"nhood_classes\"],\n    )\n\n    # This will smooth the extremes (e.g. if there is only one cell of type label in the\n    # neighborhood, the fraction will be 1)\n    gdf[f\"{label}_index\"] = gdf[f\"{label}_frac\"] * gdf[f\"{label}_cnt\"]\n\n    # Standardize the index\n    gdf[f\"{label}_index_normed\"] = gdf[f\"{label}_index\"] - gdf[f\"{label}_index\"].mean()\n\n    # Find lisa clusters\n    gdf[gdf[f\"{label}_index_normed\"] &gt; 0][f\"{label}_cnt\"].value_counts(sort=False)\n\n    gdf[f\"{label}_index_lag\"] = lag_spatial(w, gdf[f\"{label}_index_normed\"].values)\n\n    lisa = esda.Moran_Local(\n        gdf[f\"{label}_index_normed\"],\n        w,\n        island_weight=np.nan,\n        seed=seed,\n        permutations=permutations,\n    )\n\n    # Classify the gdf to HH, LL, LH, HL\n    clusters = moran_hot_cold_spots(lisa)\n\n    cluster_labels = [\"ns\", \"HH\", \"LH\", \"LL\", \"HL\"]\n    labels = [cluster_labels[i] for i in clusters]\n\n    return labels, w\n</code></pre>"},{"location":"reference/clustering/get_connected_components_ref/","title":"Get connected components ref","text":""},{"location":"reference/clustering/get_connected_components_ref/#cellseg_gsontools.clustering.get_connected_components","title":"<code>cellseg_gsontools.clustering.get_connected_components(gdf, w)</code>","text":"<p>Get the connected components of a spatial weights object.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The GeoDataFrame with the objects to get the connected components of.</p> required <code>w</code> <code>W</code> <p>The spatial weights object.</p> required <p>Returns:</p> Name Type Description <code>sub_graphs</code> <code>List[W]</code> <p>The connected components of the graph.</p> <p>Examples:</p> <p>Get the connected components of a GeoDataFrame.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.clustering import get_connected_components\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf, set_uid\n&gt;&gt;&gt; cells = read_gdf(\"cells.geojson\")\n&gt;&gt;&gt; cells = cells[cells[\"class_name\"] == \"inflammatory\"]\n&gt;&gt;&gt; cells = set_uid(cells)\n&gt;&gt;&gt; w = fit_graph(cells, type=\"distband\", id_col=\"uid\", thresh=100)\n&gt;&gt;&gt; sub_graphs = get_connected_components(cells, w)\n</code></pre> Source code in <code>cellseg_gsontools/clustering.py</code> <pre><code>def get_connected_components(gdf: gpd.GeoDataFrame, w: W) -&gt; List[W]:\n    \"\"\"Get the connected components of a spatial weights object.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The GeoDataFrame with the objects to get the connected components of.\n        w (W):\n            The spatial weights object.\n\n    Returns:\n        sub_graphs (List[W]):\n            The connected components of the graph.\n\n    Examples:\n        Get the connected components of a GeoDataFrame.\n        &gt;&gt;&gt; from cellseg_gsontools.clustering import get_connected_components\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf, set_uid\n        &gt;&gt;&gt; cells = read_gdf(\"cells.geojson\")\n        &gt;&gt;&gt; cells = cells[cells[\"class_name\"] == \"inflammatory\"]\n        &gt;&gt;&gt; cells = set_uid(cells)\n        &gt;&gt;&gt; w = fit_graph(cells, type=\"distband\", id_col=\"uid\", thresh=100)\n        &gt;&gt;&gt; sub_graphs = get_connected_components(cells, w)\n    \"\"\"\n    w_sub = w_subset(w, gdf.index.to_list(), silence_warnings=True)\n\n    G = w_sub.to_networkx()\n    sub_graphs = [\n        W(nx.to_dict_of_lists(G.subgraph(c).copy()), silence_warnings=True)\n        for c in nx.connected_components(G)\n    ]\n\n    return sub_graphs\n</code></pre>"},{"location":"reference/clustering/label_connected_components_ref/","title":"label_connected_components","text":""},{"location":"reference/clustering/label_connected_components_ref/#cellseg_gsontools.clustering.label_connected_components","title":"<code>cellseg_gsontools.clustering.label_connected_components(gdf, sub_graphs, label_col, min_size=10)</code>","text":"<p>Assign cluster labels to the objects in the GeoDataFrame.</p> <p>The cluster labels are assigned based on the connected components of the graph.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The GeoDataFrame with the objects to assign cluster labels to.</p> required <code>sub_graphs</code> <code>List[W]</code> <p>The connected components of the graph.</p> required <code>label_col</code> <code>str</code> <p>The column name to assign the cluster labels to.</p> required <code>min_size</code> <code>int</code> <p>The minimum size of the cluster to assign a label.</p> <code>10</code> <p>Returns:</p> Name Type Description <code>gdf</code> <code>GeoDataFrame</code> <p>The GeoDataFrame with the assigned cluster labels.</p> <p>Examples:</p> <p>Assign cluster labels to the objects in a GeoDataFrame.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.clustering import label_connected_components\n&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf, set_uid\n&gt;&gt;&gt; cells = read_gdf(\"cells.geojson\")\n&gt;&gt;&gt; cells = cells[cells[\"class_name\"] == \"inflammatory\"]\n&gt;&gt;&gt; cells = set_uid(cells)\n&gt;&gt;&gt; w = fit_graph(cells, type=\"distband\", id_col=\"uid\", thresh=100)\n&gt;&gt;&gt; sub_graphs = get_connected_components(cells, w)\n&gt;&gt;&gt; labeled_cells = label_connected_components(\n...     cells, sub_graphs, \"label\", min_size=10\n... )\n</code></pre> Source code in <code>cellseg_gsontools/clustering.py</code> <pre><code>def label_connected_components(\n    gdf: gpd.GeoDataFrame, sub_graphs: List[W], label_col: str, min_size: int = 10\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Assign cluster labels to the objects in the GeoDataFrame.\n\n    The cluster labels are assigned based on the connected components of the graph.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The GeoDataFrame with the objects to assign cluster labels to.\n        sub_graphs (List[W]):\n            The connected components of the graph.\n        label_col (str):\n            The column name to assign the cluster labels to.\n        min_size (int):\n            The minimum size of the cluster to assign a label.\n\n    Returns:\n        gdf (gpd.GeoDataFrame):\n            The GeoDataFrame with the assigned cluster labels.\n\n    Examples:\n        Assign cluster labels to the objects in a GeoDataFrame.\n        &gt;&gt;&gt; from cellseg_gsontools.clustering import label_connected_components\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf, set_uid\n        &gt;&gt;&gt; cells = read_gdf(\"cells.geojson\")\n        &gt;&gt;&gt; cells = cells[cells[\"class_name\"] == \"inflammatory\"]\n        &gt;&gt;&gt; cells = set_uid(cells)\n        &gt;&gt;&gt; w = fit_graph(cells, type=\"distband\", id_col=\"uid\", thresh=100)\n        &gt;&gt;&gt; sub_graphs = get_connected_components(cells, w)\n        &gt;&gt;&gt; labeled_cells = label_connected_components(\n        ...     cells, sub_graphs, \"label\", min_size=10\n        ... )\n    \"\"\"\n    i = 0\n    for ww in sub_graphs:\n        idxs = list(ww.neighbors.keys())\n        if len(idxs) &lt; min_size:\n            continue\n\n        gdf.iloc[idxs, gdf.columns.get_loc(label_col)] = i\n        i += 1\n\n    return gdf\n</code></pre>"},{"location":"reference/data/cervix_cells_ref/","title":"cervix_cells","text":""},{"location":"reference/data/cervix_cells_ref/#cellseg_gsontools.data.cervix_cells","title":"<code>cellseg_gsontools.data.cervix_cells()</code>","text":"<p>A GeoDataframe containing cells of the cervical tissue.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.data import cervix_cells\n&gt;&gt;&gt; cervix_cells().head(3)\n        type                                           geometry    class_name\nuid\n1    Feature  POLYGON ((-10.988 48446.005, -10.988 48453.996...  inflammatory\n2    Feature  POLYGON ((-20.988 48477.996, -19.990 48479.993...    connective\n3    Feature  POLYGON ((-14.988 48767.995, -11.993 48770.990...  inflammatory\n</code></pre> Source code in <code>cellseg_gsontools/data/fetch.py</code> <pre><code>def cervix_cells():\n    \"\"\"A GeoDataframe containing cells of the cervical tissue.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools.data import cervix_cells\n        &gt;&gt;&gt; cervix_cells().head(3)\n                type                                           geometry    class_name\n        uid\n        1    Feature  POLYGON ((-10.988 48446.005, -10.988 48453.996...  inflammatory\n        2    Feature  POLYGON ((-20.988 48477.996, -19.990 48479.993...    connective\n        3    Feature  POLYGON ((-14.988 48767.995, -11.993 48770.990...  inflammatory\n    \"\"\"\n    return _load(BASE_PATH / \"cervix_cells.feather\")\n</code></pre>"},{"location":"reference/data/cervix_tissue_ref/","title":"cervix_tissue","text":""},{"location":"reference/data/cervix_tissue_ref/#cellseg_gsontools.data.cervix_tissue","title":"<code>cellseg_gsontools.data.cervix_tissue()</code>","text":"<p>A GeoDataframe containing cervical tissue areas.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.data import cervix_tissue\n&gt;&gt;&gt; cervix_tissue().head(3)\n        type                                           geometry  class_name\nuid\n1    Feature  POLYGON ((1852.953 51003.603, 1853.023 51009.1...  areastroma\n2    Feature  POLYGON ((4122.334 48001.899, 4122.994 48014.8...   areagland\n3    Feature  POLYGON ((3075.002 48189.068, 3075.001 48218.8...   areagland\n</code></pre> Source code in <code>cellseg_gsontools/data/fetch.py</code> <pre><code>def cervix_tissue():\n    \"\"\"A GeoDataframe containing cervical tissue areas.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools.data import cervix_tissue\n        &gt;&gt;&gt; cervix_tissue().head(3)\n                type                                           geometry  class_name\n        uid\n        1    Feature  POLYGON ((1852.953 51003.603, 1853.023 51009.1...  areastroma\n        2    Feature  POLYGON ((4122.334 48001.899, 4122.994 48014.8...   areagland\n        3    Feature  POLYGON ((3075.002 48189.068, 3075.001 48218.8...   areagland\n    \"\"\"\n    return _load(BASE_PATH / \"cervix_tissue.feather\")\n</code></pre>"},{"location":"reference/data/gland_cells_ref/","title":"gland_cells","text":""},{"location":"reference/data/gland_cells_ref/#cellseg_gsontools.data.gland_cells","title":"<code>cellseg_gsontools.data.gland_cells()</code>","text":"<p>A GeoDataframe containing cells of cervical gland tissue.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n&gt;&gt;&gt; gland_cells().plot()\nplt.Axes\n</code></pre> Source code in <code>cellseg_gsontools/data/fetch.py</code> <pre><code>def gland_cells():\n    \"\"\"A GeoDataframe containing cells of cervical gland tissue.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools.data import gland_cells\n        &gt;&gt;&gt; gland_cells().plot()\n        plt.Axes\n    \"\"\"\n    return _load(BASE_PATH / \"gland_cells.feather\")\n</code></pre>"},{"location":"reference/data/gland_tissue_ref/","title":"gland_tissue","text":""},{"location":"reference/data/gland_tissue_ref/#cellseg_gsontools.data.gland_tissue","title":"<code>cellseg_gsontools.data.gland_tissue()</code>","text":"<p>A GeoDataframe containing cervical gland tissue.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.data import gland_tissue\n&gt;&gt;&gt; gland_tissue().plot()\nplt.Axes\n</code></pre> Source code in <code>cellseg_gsontools/data/fetch.py</code> <pre><code>def gland_tissue():\n    \"\"\"A GeoDataframe containing cervical gland tissue.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools.data import gland_tissue\n        &gt;&gt;&gt; gland_tissue().plot()\n        plt.Axes\n    \"\"\"\n    return _load(BASE_PATH / \"gland_areas.feather\")\n</code></pre>"},{"location":"reference/data/tumor_stroma_interface_cells_ref/","title":"tumor_stroma_interface_cells","text":""},{"location":"reference/data/tumor_stroma_interface_cells_ref/#cellseg_gsontools.data.tumor_stroma_intreface_cells","title":"<code>cellseg_gsontools.data.tumor_stroma_intreface_cells()</code>","text":"<p>A GeoDataframe containing cells of a TS-interface.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.data import tumor_stroma_intreface_cells\n&gt;&gt;&gt; tumor_stroma_intreface_cells().plot()\nplt.Axes\n</code></pre> Source code in <code>cellseg_gsontools/data/fetch.py</code> <pre><code>def tumor_stroma_intreface_cells():\n    \"\"\"A GeoDataframe containing cells of a TS-interface.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools.data import tumor_stroma_intreface_cells\n        &gt;&gt;&gt; tumor_stroma_intreface_cells().plot()\n        plt.Axes\n    \"\"\"\n    return _load(BASE_PATH / \"ts_iface_cells.feather\")\n</code></pre>"},{"location":"reference/data/tumor_stroma_interface_tissue_ref/","title":"tumor_stroma_interface_tissue","text":""},{"location":"reference/data/tumor_stroma_interface_tissue_ref/#cellseg_gsontools.data.tumor_stroma_intreface_tissue","title":"<code>cellseg_gsontools.data.tumor_stroma_intreface_tissue()</code>","text":"<p>A GeoDataframe containing tissues of a TS-interface.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.data import tumor_stroma_intreface_tissue\n&gt;&gt;&gt; tumor_stroma_intreface_tissue().plot()\nplt.Axes\n</code></pre> Source code in <code>cellseg_gsontools/data/fetch.py</code> <pre><code>def tumor_stroma_intreface_tissue():\n    \"\"\"A GeoDataframe containing tissues of a TS-interface.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools.data import tumor_stroma_intreface_tissue\n        &gt;&gt;&gt; tumor_stroma_intreface_tissue().plot()\n        plt.Axes\n    \"\"\"\n    return _load(BASE_PATH / \"ts_iface_areas.feather\")\n</code></pre>"},{"location":"reference/diversity/gini_index_ref/","title":"gini_index","text":""},{"location":"reference/diversity/gini_index_ref/#cellseg_gsontools.diversity.gini_index","title":"<code>cellseg_gsontools.diversity.gini_index(x)</code>","text":"<p>Compute the gini coefficient of inequality for species.</p> Note <p>This is based on http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm.</p> <p>Gini-index: $$ G = \\frac{\\sum_{i=1}^n (2i - n - 1)x_i} {n \\sum_{i=1}^n x_i} $$</p> <p>where \\(x_i\\) is the count of species \\(i\\) and \\(n\\) is the total count of species.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Sequence</code> <p>The input value-vector. Shape (n, )</p> required <p>Raises:</p> Type Description <code>ValueError</code> <p>If there are negative input values.</p> <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed Gini coefficient.</p> Source code in <code>cellseg_gsontools/diversity.py</code> <pre><code>def gini_index(x: Sequence) -&gt; float:\n    \"\"\"Compute the gini coefficient of inequality for species.\n\n    Note:\n        This is based on\n        http://www.statsdirect.com/help/default.htm#nonparametric_methods/gini.htm.\n\n    **Gini-index:**\n    $$\n    G = \\\\frac{\\\\sum_{i=1}^n (2i - n - 1)x_i} {n \\\\sum_{i=1}^n x_i}\n    $$\n\n    where $x_i$ is the count of species $i$ and $n$ is the total count of species.\n\n    Parameters:\n        x (Sequence):\n            The input value-vector. Shape (n, )\n\n    Raises:\n        ValueError:\n            If there are negative input values.\n\n    Returns:\n        float:\n            The computed Gini coefficient.\n    \"\"\"\n    if np.min(x) &lt; 0:\n        raise ValueError(\"Input values need to be positive for Gini coeff\")\n\n    n = len(x)\n    s = np.sum(x)\n    nx = n * s + SMALL\n\n    rx = (2.0 * np.arange(1, n + 1) * x[np.argsort(x)]).sum()\n    return (rx - nx - s) / nx\n</code></pre>"},{"location":"reference/diversity/shannon_index_ref/","title":"shannon_index","text":""},{"location":"reference/diversity/shannon_index_ref/#cellseg_gsontools.diversity.shannon_index","title":"<code>cellseg_gsontools.diversity.shannon_index(counts)</code>","text":"<p>Compute the Shannon Weiner index/entropy on a count vector.</p> Note <p>\"The Shannon index is related to the concept of uncertainty. If for example, a community has very low diversity, we can be fairly certain of the identity of an organism we might choose by random (high certainty or low uncertainty). If a community is highly diverse and we choose an organism by random, we have a greater uncertainty of which species we will choose (low certainty or high uncertainty).\" - A. Wilson, N. Gownaris</p> <p>Shannon index: $$ H^{\\prime} = -\\sum_{i=1}^n p_i \\ln(p_i) $$</p> <p>where \\(p_i\\) is the proportion of species \\(i\\) and \\(n\\) is the total count of species.</p> <p>Parameters:</p> Name Type Description Default <code>counts</code> <code>Sequence</code> <p>A count vector/list of shape (C, ).</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed Shannon diversity index.</p> Source code in <code>cellseg_gsontools/diversity.py</code> <pre><code>def shannon_index(counts: Sequence) -&gt; float:\n    \"\"\"Compute the Shannon Weiner index/entropy on a count vector.\n\n    Note:\n        \"*The Shannon index is related to the concept of uncertainty. If for example,\n        a community has very low diversity, we can be fairly certain of the identity of\n        an organism we might choose by random (high certainty or low uncertainty). If a\n        community is highly diverse and we choose an organism by random, we have a\n        greater uncertainty of which species we will choose (low certainty or high\n        uncertainty).*\"\n        - [A. Wilson, N. Gownaris](https://bio.libretexts.org/Courses/Gettysburg_College/01%3A_Ecology_for_All/22%3A_Biodiversity/22.02%3A_Diversity_Indices)\n\n    **Shannon index:**\n    $$\n    H^{\\\\prime} = -\\\\sum_{i=1}^n p_i \\\\ln(p_i)\n    $$\n\n    where $p_i$ is the proportion of species $i$ and $n$ is the total count of species.\n\n    Parameters:\n        counts (Sequence):\n            A count vector/list of shape (C, ).\n\n    Returns:\n        float:\n            The computed Shannon diversity index.\n    \"\"\"\n    N = np.sum(counts) + SMALL\n    probs = [float(n) / N for n in counts]\n\n    entropy = -np.sum([p * np.log(p) for p in probs if p != 0])\n\n    if entropy == 0:\n        return 0.0\n\n    return entropy\n</code></pre>"},{"location":"reference/diversity/simpson_index_ref/","title":"simpson_index","text":""},{"location":"reference/diversity/simpson_index_ref/#cellseg_gsontools.diversity.simpson_index","title":"<code>cellseg_gsontools.diversity.simpson_index(counts)</code>","text":"<p>Compute the Simpson diversity index on a count vector.</p> Note <p>Simpson diversity index is a quantitative measure that reflects how many different types (such as species) there are in a dataset (a community). It is a probability measure, when it is low, the greater the probability that two randomly selected individuals will be the same species. - A. Wilson, N. Gownaris</p> <p>Simpson index: $$ D = 1 - \\sum_{i=1}^n \\left(\\frac{n_i}{N}\\right)^2 $$</p> <p>where \\(n_i\\) is the count of species \\(i\\) and \\(N\\) is the total count of species.</p> <p>Parameters:</p> Name Type Description Default <code>counts</code> <code>Sequence</code> <p>A count vector/list of shape (C, ).</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed Simpson diversity index.</p> Source code in <code>cellseg_gsontools/diversity.py</code> <pre><code>def simpson_index(counts: Sequence) -&gt; float:\n    \"\"\"Compute the Simpson diversity index on a count vector.\n\n    Note:\n        Simpson diversity index is a quantitative measure that reflects how many\n        different types (such as species) there are in a dataset (a community). It\n        is a probability measure, when it is low, the greater the probability that\n        two randomly selected individuals will be the same species.\n        - [A. Wilson, N. Gownaris](https://bio.libretexts.org/Courses/Gettysburg_College/01%3A_Ecology_for_All/22%3A_Biodiversity/22.02%3A_Diversity_Indices)\n\n\n    **Simpson index:**\n    $$\n    D = 1 - \\\\sum_{i=1}^n \\\\left(\\\\frac{n_i}{N}\\\\right)^2\n    $$\n\n    where $n_i$ is the count of species $i$ and $N$ is the total count of species.\n\n    Parameters:\n        counts (Sequence):\n            A count vector/list of shape (C, ).\n\n    Returns:\n        float:\n            The computed Simpson diversity index.\n    \"\"\"\n    N = np.sum(counts) + SMALL\n    return 1 - np.sum([(n / N) ** 2 for n in counts if n != 0])\n</code></pre>"},{"location":"reference/diversity/theil_index_ref/","title":"theil_index","text":""},{"location":"reference/diversity/theil_index_ref/#cellseg_gsontools.diversity.theil_index","title":"<code>cellseg_gsontools.diversity.theil_index(x)</code>","text":"<p>Compute the Theil index of inequality for species.</p> <p>Theil-index: $$ T = \\sum_{i=1}^n \\left(     \\frac{y_i}{\\sum_{i=1}^n y_i} \\ln \\left[         N \\frac{y_i} {\\sum_{i=1}^n y_i}     \\right]\\right) $$</p> <p>where \\(y_i\\) is the count of species \\(i\\) and \\(N\\) is the total count of species.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Sequence</code> <p>The input value-vector. Shape (n, )</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The computed Theil index.</p> Source code in <code>cellseg_gsontools/diversity.py</code> <pre><code>def theil_index(x: Sequence) -&gt; float:\n    \"\"\"Compute the Theil index of inequality for species.\n\n    **Theil-index:**\n    $$\n    T = \\\\sum_{i=1}^n \\\\left(\n        \\\\frac{y_i}{\\\\sum_{i=1}^n y_i} \\\\ln \\\\left[\n            N \\\\frac{y_i} {\\\\sum_{i=1}^n y_i}\n        \\\\right]\\\\right)\n    $$\n\n    where $y_i$ is the count of species $i$ and $N$ is the total count of species.\n\n    Parameters:\n        x (Sequence):\n            The input value-vector. Shape (n, )\n\n    Returns:\n        float:\n            The computed Theil index.\n    \"\"\"\n    n = len(x)\n    x = x + SMALL * (x == 0)  # can't have 0 values\n    xt = np.sum(x, axis=0) + SMALL\n    s = x / (xt * 1.0)\n    lns = np.log(n * s)\n    slns = s * lns\n    t = np.sum(slns)\n\n    return t\n</code></pre>"},{"location":"reference/geometry/circularity_ref/","title":"circularity","text":""},{"location":"reference/geometry/circularity_ref/#cellseg_gsontools.geometry.circularity","title":"<code>cellseg_gsontools.geometry.circularity(polygon, **kwargs)</code>","text":"<p>Compute the circularity of a polygon.</p> Note <p>Circularity (sometimes roundness) is the ratio of the area of an object to the area of a circle with the same convex perimeter. Circularity equals 1 for a circular object and less than 1 for non-circular objects. Note that circularity is insensitive to irregular boundaries. - Wirth</p> <p>Circularity: $$ \\frac{4 \\times \\pi A_{poly}}{P_{convex}^2} $$</p> <p>where \\(A_{poly}\\) is the area of the polygon and \\(P_{convex}\\) is the perimeter of the convex hull.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The circularity value of a polygon between 0-1.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def circularity(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the circularity of a polygon.\n\n    Note:\n        Circularity (sometimes roundness) is the ratio of the area of\n        an object to the area of a circle with the same convex perimeter.\n        Circularity equals 1 for a circular object and less than 1 for\n        non-circular objects. Note that circularity is insensitive to\n        irregular boundaries.\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    **Circularity:**\n    $$\n    \\\\frac{4 \\\\times \\\\pi A_{poly}}{P_{convex}^2}\n    $$\n\n    where $A_{poly}$ is the area of the polygon and $P_{convex}$ is the perimeter of\n    the convex hull.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The circularity value of a polygon between 0-1.\n    \"\"\"\n    convex_perimeter = polygon.convex_hull.length\n    area = polygon.area\n\n    circularity = (4 * np.pi * area) / convex_perimeter**2\n\n    return circularity\n</code></pre>"},{"location":"reference/geometry/compactness_ref/","title":"compactness","text":""},{"location":"reference/geometry/compactness_ref/#cellseg_gsontools.geometry.compactness","title":"<code>cellseg_gsontools.geometry.compactness(polygon, **kwargs)</code>","text":"<p>Compute the compactness of a polygon.</p> Note <p>Compactness is defined as the ratio of the area of an object to the area of a circle with the same perimeter. A circle is the most compact shape. Objects that are elliptical or have complicated, irregular (not smooth) boundaries have larger compactness. - Wirth</p> <p>Compactness: $$ \\frac{4\\pi A_{poly}}{P_{poly}^2} $$</p> <p>where \\(A_{poly}\\) is the area of the polygon and \\(P_{poly}\\) is the perimeter of the polygon.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The compactness value of a polygon between 0-1.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def compactness(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the compactness of a polygon.\n\n    Note:\n        Compactness is defined as the ratio of the area of an object\n        to the area of a circle with the same perimeter. A circle is the\n        most compact shape. Objects that are elliptical or have complicated,\n        irregular (not smooth) boundaries have larger compactness.\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    **Compactness:**\n    $$\n    \\\\frac{4\\\\pi A_{poly}}{P_{poly}^2}\n    $$\n\n    where $A_{poly}$ is the area of the polygon and $P_{poly}$ is the perimeter of\n    the polygon.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The compactness value of a polygon between 0-1.\n    \"\"\"\n    perimeter = polygon.length\n    area = polygon.area\n\n    compactness = (4 * np.pi * area) / perimeter**2\n\n    return compactness\n</code></pre>"},{"location":"reference/geometry/convexity_ref/","title":"convexity","text":""},{"location":"reference/geometry/convexity_ref/#cellseg_gsontools.geometry.convexity","title":"<code>cellseg_gsontools.geometry.convexity(polygon, **kwargs)</code>","text":"<p>Compute the convexity of a polygon.</p> Note <p>Convexity is the relative amount that an object differs from a convex object. Convexity is defined by computing the ratio of the perimeter of an object's convex hull to the perimeter of the object itself. This will take the value of 1 for a convex object, and will be less than 1 if the object is not convex, such as one having an irregular boundary. - Wirth</p> <p>Convexity: $$ \\frac{P_{convex}}{P_{poly}} $$</p> <p>where \\(P_{convex}\\) is the perimeter of the convex hull and \\(P_{poly}\\) is the perimeter of the polygon.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The convexity value of a polygon between 0-1.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def convexity(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the convexity of a polygon.\n\n    Note:\n        Convexity is the relative amount that an object differs from a\n        convex object. Convexity is defined by computing the ratio of\n        the perimeter of an object's convex hull to the perimeter of\n        the object itself. This will take the value of 1 for a convex\n        object, and will be less than 1 if the object is not convex, such\n        as one having an irregular boundary.\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    **Convexity:**\n    $$\n    \\\\frac{P_{convex}}{P_{poly}}\n    $$\n\n    where $P_{convex}$ is the perimeter of the convex hull and $P_{poly}$ is the\n    perimeter of the polygon.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The convexity value of a polygon between 0-1.\n    \"\"\"\n    convex_perimeter = polygon.convex_hull.length\n    perimeter = polygon.length\n\n    convexity = convex_perimeter / perimeter\n\n    return convexity\n</code></pre>"},{"location":"reference/geometry/eccentricity_ref/","title":"eccentricity","text":""},{"location":"reference/geometry/eccentricity_ref/#cellseg_gsontools.geometry.eccentricity","title":"<code>cellseg_gsontools.geometry.eccentricity(polygon, **kwargs)</code>","text":"<p>Compute the eccentricity of a polygon.</p> Note <p>Eccentricity (sometimes ellipticity) measures how far the object is from an ellipse. It is defined as the ratio of the length of the minor axis to the length of the major axis of an object. The closer the object is to an ellipse, the closer the eccentricity is to 1 - Wirth</p> <p>Eccentricity: $$ \\sqrt{1 - \\frac{\\text{minor axis}^2}{\\text{major axis}^2}} $$</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The eccentricity value of a polygon between 0-1.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def eccentricity(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the eccentricity of a polygon.\n\n    Note:\n        Eccentricity (sometimes ellipticity) measures how far the object is\n        from an ellipse. It is defined as the ratio of the length of the minor\n        axis to the length of the major axis of an object. The closer the\n        object is to an ellipse, the closer the eccentricity is to 1\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    **Eccentricity:**\n    $$\n    \\\\sqrt{1 - \\\\frac{\\\\text{minor axis}^2}{\\\\text{major axis}^2}}\n    $$\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The eccentricity value of a polygon between 0-1.\n    \"\"\"\n    mrr = polygon.minimum_rotated_rectangle.exterior.coords\n    major_ax, minor_ax = axis_len(mrr)\n    eccentricity = np.sqrt(1 - (minor_ax**2 / major_ax**2))\n    return eccentricity\n</code></pre>"},{"location":"reference/geometry/elongation_ref/","title":"elongation","text":""},{"location":"reference/geometry/elongation_ref/#cellseg_gsontools.geometry.elongation","title":"<code>cellseg_gsontools.geometry.elongation(polygon, **kwargs)</code>","text":"<p>Compute the elongation of a polygon.</p> Note <p>Elongation is the ratio between the length and width of the object bounding box. If the ratio is equal to 1, the object is roughly square or circularly shaped. As the ratio decreases from 1, the object becomes more elongated. - Wirth</p> <p>Elongation: $$ \\frac{\\text{bbox width}}{\\text{bbox height}} $$</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The elongation value of a polygon between 0-1.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def elongation(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the elongation of a polygon.\n\n    Note:\n        Elongation is the ratio between the length and width of the\n        object bounding box. If the ratio is equal to 1, the object\n        is roughly square or circularly shaped. As the ratio decreases\n        from 1, the object becomes more elongated.\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    **Elongation:**\n    $$\n    \\\\frac{\\\\text{bbox width}}{\\\\text{bbox height}}\n    $$\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The elongation value of a polygon between 0-1.\n    \"\"\"\n    minx, miny, maxx, maxy = polygon.bounds\n\n    width = maxx - minx\n    height = maxy - miny\n\n    if width &lt;= height:\n        elongation = width / height\n    else:\n        elongation = height / width\n\n    return elongation\n</code></pre>"},{"location":"reference/geometry/equivalent_rectangular_index_ref/","title":"equivalent_rectangular_index","text":""},{"location":"reference/geometry/equivalent_rectangular_index_ref/#cellseg_gsontools.geometry.equivalent_rectangular_index","title":"<code>cellseg_gsontools.geometry.equivalent_rectangular_index(polygon)</code>","text":"<p>Compute the equivalent rectangular index.</p> Note <p>Equivalent rectangluar index is the deviation of a polygon from an equivalent rectangle.</p> <p>ERI: $$ \\frac{\\sqrt{A_{poly}}}{A_{MRR}} \\times \\frac{P_{MRR}}{P_{poly}} $$</p> <p>where \\(A_{poly}\\) is the area of the polygon, \\(A_{MRR}\\) is the area of the minimum rotated rectangle, \\(P_{MRR}\\) is the perimeter of the minimum rotated rectangle and \\(P_{poly}\\) is the perimeter of the polygon.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The ERI value of a polygon between 0-1.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def equivalent_rectangular_index(polygon: Polygon) -&gt; float:\n    \"\"\"Compute the equivalent rectangular index.\n\n    Note:\n        Equivalent rectangluar index is the deviation of a polygon from\n        an equivalent rectangle.\n\n    **ERI:**\n    $$\n    \\\\frac{\\\\sqrt{A_{poly}}}{A_{MRR}}\n    \\\\times\n    \\\\frac{P_{MRR}}{P_{poly}}\n    $$\n\n    where $A_{poly}$ is the area of the polygon, $A_{MRR}$ is the area of the\n    minimum rotated rectangle, $P_{MRR}$ is the perimeter of the minimum rotated\n    rectangle and $P_{poly}$ is the perimeter of the polygon.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The ERI value of a polygon between 0-1.\n    \"\"\"\n    mrr = polygon.minimum_rotated_rectangle\n\n    return np.sqrt(polygon.area / mrr.area) / (mrr.length / polygon.length)\n</code></pre>"},{"location":"reference/geometry/fractal_dimension_ref/","title":"fractal_dimension","text":""},{"location":"reference/geometry/fractal_dimension_ref/#cellseg_gsontools.geometry.fractal_dimension","title":"<code>cellseg_gsontools.geometry.fractal_dimension(polygon, **kwargs)</code>","text":"<p>Compute the fractal dimension of a polygon.</p> Note <p>The fractal dimension is the rate at which the perimeter of an object increases as the measurement scale is reduced. The fractal dimension produces a single numeric value that summarizes the irregularity of \"roughness\" of the feature boundary. - Wirth</p> <p>Fractal dimension: $$ 2 \\times \\frac{\\log(\\frac{P_{poly}}{4})}{\\log(A_{poly})} $$</p> <p>where \\(P_{poly}\\) is the perimeter of the polygon and \\(A_{poly}\\) is the area of the polygon.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The fractal dimension value of a polygon.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def fractal_dimension(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the fractal dimension of a polygon.\n\n    Note:\n        The fractal dimension is the rate at which the perimeter of an\n        object increases as the measurement scale is reduced. The fractal\n        dimension produces a single numeric value that summarizes the\n        irregularity of \"roughness\" of the feature boundary.\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n\n    **Fractal dimension:**\n    $$\n    2 \\\\times \\\\frac{\\\\log(\\\\frac{P_{poly}}{4})}{\\\\log(A_{poly})}\n    $$\n\n    where $P_{poly}$ is the perimeter of the polygon and $A_{poly}$ is the area of the\n    polygon.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The fractal dimension value of a polygon.\n    \"\"\"\n    perimeter = polygon.length\n    area = polygon.area\n\n    return (2 * np.log(perimeter / 4)) / np.log(area)\n</code></pre>"},{"location":"reference/geometry/major_axis_angle_ref/","title":"major_axis_angle","text":""},{"location":"reference/geometry/major_axis_angle_ref/#cellseg_gsontools.geometry.major_axis_angle","title":"<code>cellseg_gsontools.geometry.major_axis_angle(polygon)</code>","text":"<p>Compute the major axis angle of a polygon.</p> Note <p>The major axis is the (x,y) endpoints of the longest line that can be drawn through the object. Major axis angle is the angle of the major axis with respect to the x-axis. - Wirth</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The angle of the major axis in degrees.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def major_axis_angle(polygon: Polygon) -&gt; float:\n    \"\"\"Compute the major axis angle of a polygon.\n\n    Note:\n        The major axis is the (x,y) endpoints of the longest line that\n        can be drawn through the object. Major axis angle is the angle of\n        the major axis with respect to the x-axis.\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The angle of the major axis in degrees.\n    \"\"\"\n    mrr = polygon.minimum_rotated_rectangle.exterior.coords\n    return axis_angle(mrr, \"major\")\n</code></pre>"},{"location":"reference/geometry/major_axis_len_ref/","title":"major_axis_len","text":""},{"location":"reference/geometry/major_axis_len_ref/#cellseg_gsontools.geometry.major_axis_len","title":"<code>cellseg_gsontools.geometry.major_axis_len(polygon)</code>","text":"<p>Compute the major axis length of a polygon.</p> Note <p>The major axis is the (x,y) endpoints of the longest line that can be drawn through the object. Major axis length is the pixel distance between the major-axis endpoints - Wirth</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The length of the major axis.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def major_axis_len(polygon: Polygon) -&gt; float:\n    \"\"\"Compute the major axis length of a polygon.\n\n    Note:\n        The major axis is the (x,y) endpoints of the longest line that\n        can be drawn through the object. Major axis length is the pixel\n        distance between the major-axis endpoints\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The length of the major axis.\n    \"\"\"\n    mrr = polygon.minimum_rotated_rectangle.exterior.coords\n    return axis_len(mrr, \"major\")\n</code></pre>"},{"location":"reference/geometry/minor_axis_angle_ref/","title":"minor_axis_angle","text":""},{"location":"reference/geometry/minor_axis_angle_ref/#cellseg_gsontools.geometry.minor_axis_angle","title":"<code>cellseg_gsontools.geometry.minor_axis_angle(polygon)</code>","text":"<p>Compute the minor axis angle of a polygon.</p> Note <p>The minor axis is the (x,y) endpoints of the longest line that can be drawn through the object whilst remaining perpendicular with the major-axis. Minor axis angle is the angle of the minor axis with respect to the x-axis. - Wirth</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The angle of the minor axis in degrees.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def minor_axis_angle(polygon: Polygon) -&gt; float:\n    \"\"\"Compute the minor axis angle of a polygon.\n\n    Note:\n        The minor axis is the (x,y) endpoints of the longest line that\n        can be drawn through the object whilst remaining perpendicular\n        with the major-axis. Minor axis angle is the angle of the minor\n        axis with respect to the x-axis.\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The angle of the minor axis in **degrees**.\n    \"\"\"\n    mrr = polygon.minimum_rotated_rectangle.exterior.coords\n    return axis_angle(mrr, \"minor\")\n</code></pre>"},{"location":"reference/geometry/minor_axis_len_ref/","title":"minor_axis_len","text":""},{"location":"reference/geometry/minor_axis_len_ref/#cellseg_gsontools.geometry.minor_axis_len","title":"<code>cellseg_gsontools.geometry.minor_axis_len(polygon)</code>","text":"<p>Compute the minor axis length of a polygon.</p> Note <p>The minor axis is the (x,y) endpoints of the longest line that can be drawn through the object whilst remaining perpendicular with the major-axis. Minor axis length is the pixel distance between the minor-axis endpoints - Wirth</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The length of the minor axis.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def minor_axis_len(polygon: Polygon) -&gt; float:\n    \"\"\"Compute the minor axis length of a polygon.\n\n    Note:\n        The minor axis is the (x,y) endpoints of the longest line that\n        can be drawn through the object whilst remaining perpendicular\n        with the major-axis. Minor axis length is the pixel distance\n        between the minor-axis endpoints\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The length of the minor axis.\n    \"\"\"\n    mrr = polygon.minimum_rotated_rectangle.exterior.coords\n    return axis_len(mrr, \"minor\")\n</code></pre>"},{"location":"reference/geometry/rectangularity_ref/","title":"rectangularity","text":""},{"location":"reference/geometry/rectangularity_ref/#cellseg_gsontools.geometry.rectangularity","title":"<code>cellseg_gsontools.geometry.rectangularity(polygon, **kwargs)</code>","text":"<p>Compute the rectangularity of a polygon.</p> Note <p>Rectangularity is the ratio of the object to the area of the minimum bounding rectangle. Rectangularity has a value of 1 for perfectly rectangular object.</p> <p>Rectangularity: $$ \\frac{A_{poly}}{A_{MRR}} $$</p> <p>where \\(A_{poly}\\) is the area of the polygon and \\(A_{MRR}\\) is the area of the minimum rotated rectangle.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The rectangularity value of a polygon between 0-1.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def rectangularity(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the rectangularity of a polygon.\n\n    Note:\n        Rectangularity is the ratio of the object to the area of the\n        minimum bounding rectangle. Rectangularity has a value of 1\n        for perfectly rectangular object.\n\n    **Rectangularity:**\n    $$\n    \\\\frac{A_{poly}}{A_{MRR}}\n    $$\n\n    where $A_{poly}$ is the area of the polygon and $A_{MRR}$ is the area of the\n    minimum rotated rectangle.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The rectangularity value of a polygon between 0-1.\n    \"\"\"\n    mrr = polygon.minimum_rotated_rectangle\n\n    return polygon.area / mrr.area\n</code></pre>"},{"location":"reference/geometry/shape_index_ref/","title":"shape_index","text":""},{"location":"reference/geometry/shape_index_ref/#cellseg_gsontools.geometry.shape_index","title":"<code>cellseg_gsontools.geometry.shape_index(polygon, **kwargs)</code>","text":"<p>Compute the shape index of a polygon.</p> Note <p>Basically, the inverse of circularity.</p> <p>Shape Index: $$ \\frac{\\sqrt{\\frac{A_{poly}}{\\pi}}}{\\text{MBR}} $$</p> <p>where \\(A_{poly}\\) is the area of the polygon and \\(\\text{MBR}\\) is the radius of the minimum bounding radius.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The shape index value of a polygon.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def shape_index(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the shape index of a polygon.\n\n    Note:\n        Basically, the inverse of circularity.\n\n    **Shape Index:**\n    $$\n    \\\\frac{\\\\sqrt{\\\\frac{A_{poly}}{\\\\pi}}}{\\\\text{MBR}}\n    $$\n\n    where $A_{poly}$ is the area of the polygon and $\\\\text{MBR}$ is the radius of the\n    minimum bounding radius.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The shape index value of a polygon.\n    \"\"\"\n    r = shapely.minimum_bounding_radius(polygon)\n    area = polygon.area\n\n    return np.sqrt(area / np.pi) / r\n</code></pre>"},{"location":"reference/geometry/shape_metric_ref/","title":"shape_metric","text":""},{"location":"reference/geometry/shape_metric_ref/#cellseg_gsontools.geometry.shape_metric","title":"<code>cellseg_gsontools.geometry.shape_metric(gdf, metrics, parallel=True, num_processes=-1, col_prefix=None, create_copy=True)</code>","text":"<p>Compute a set of shape metrics for every row of the gdf.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The input GeoDataFrame.</p> required <code>metrics</code> <code>Tuple[str, ...]</code> <p>A Tuple/List of shape metrics.</p> required <code>parallel</code> <code>bool</code> <p>Flag whether to use parallel apply operations when computing the diversities.</p> <code>True</code> <code>num_processes</code> <code>int, default=-1</code> <p>The number of processes to use when parallel=True. If -1, this will use all available cores.</p> <code>-1</code> <code>col_prefix</code> <code>str</code> <p>Prefix for the new column names.</p> <code>None</code> <code>create_copy</code> <code>bool</code> <p>Flag whether to create a copy of the input gdf or not.</p> <code>True</code> Note <p>Allowed shape metrics are:</p> <ul> <li><code>area</code></li> <li><code>major_axis_len</code></li> <li><code>minor_axis_len</code></li> <li><code>major_axis_angle</code></li> <li><code>minor_axis_angle</code></li> <li><code>compactness</code></li> <li><code>circularity</code></li> <li><code>convexity</code></li> <li><code>solidity</code></li> <li><code>elongation</code></li> <li><code>eccentricity</code></li> <li><code>fractal_dimension</code></li> <li><code>sphericity</code></li> <li><code>shape_index</code></li> <li><code>rectangularity</code></li> <li><code>squareness</code></li> <li><code>equivalent_rectangular_index</code></li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>If an illegal metric is given.</p> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The input geodataframe with computed shape metric columns added.</p> <p>Examples:</p> <p>Compute the eccentricity and solidity for each polygon in gdf.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.geometry import shape_metric\n&gt;&gt;&gt; shape_metric(gdf, metrics=[\"eccentricity\", \"solidity\"], parallel=True)\n</code></pre> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def shape_metric(\n    gdf: gpd.GeoDataFrame,\n    metrics: Tuple[str, ...],\n    parallel: bool = True,\n    num_processes: int = -1,\n    col_prefix: str = None,\n    create_copy: bool = True,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Compute a set of shape metrics for every row of the gdf.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The input GeoDataFrame.\n        metrics (Tuple[str, ...]):\n            A Tuple/List of shape metrics.\n        parallel (bool):\n            Flag whether to use parallel apply operations when computing the diversities.\n        num_processes (int, default=-1):\n            The number of processes to use when parallel=True. If -1,\n            this will use all available cores.\n        col_prefix (str):\n            Prefix for the new column names.\n        create_copy (bool):\n            Flag whether to create a copy of the input gdf or not.\n\n    Note:\n        Allowed shape metrics are:\n\n        - `area`\n        - `major_axis_len`\n        - `minor_axis_len`\n        - `major_axis_angle`\n        - `minor_axis_angle`\n        - `compactness`\n        - `circularity`\n        - `convexity`\n        - `solidity`\n        - `elongation`\n        - `eccentricity`\n        - `fractal_dimension`\n        - `sphericity`\n        - `shape_index`\n        - `rectangularity`\n        - `squareness`\n        - `equivalent_rectangular_index`\n\n    Raises:\n        ValueError:\n            If an illegal metric is given.\n\n    Returns:\n        gpd.GeoDataFrame:\n            The input geodataframe with computed shape metric columns added.\n\n    Examples:\n        Compute the eccentricity and solidity for each polygon in gdf.\n        &gt;&gt;&gt; from cellseg_gsontools.geometry import shape_metric\n        &gt;&gt;&gt; shape_metric(gdf, metrics=[\"eccentricity\", \"solidity\"], parallel=True)\n    \"\"\"\n    if not isinstance(metrics, (list, tuple)):\n        raise ValueError(f\"`metrics` must be a list or tuple. Got: {type(metrics)}.\")\n\n    allowed = list(SHAPE_LOOKUP.keys())\n    if not all(m in allowed for m in metrics):\n        raise ValueError(\n            f\"Illegal metric in `metrics`. Got: {metrics}. Allowed metrics: {allowed}.\"\n        )\n\n    if create_copy:\n        gdf = gdf.copy()\n\n    if col_prefix is None:\n        col_prefix = \"\"\n    else:\n        col_prefix += \"_\"\n\n    met = list(metrics)\n    if \"area\" in metrics:\n        gdf[f\"{col_prefix}area\"] = gdf.area\n        met.remove(\"area\")\n\n    for metric in met:\n        gdf[metric] = gdf_apply(\n            gdf,\n            SHAPE_LOOKUP[metric],\n            columns=[\"geometry\"],\n            parallel=parallel,\n            num_processes=num_processes,\n        )\n\n    return gdf\n</code></pre>"},{"location":"reference/geometry/solidity_ref/","title":"solidity","text":""},{"location":"reference/geometry/solidity_ref/#cellseg_gsontools.geometry.solidity","title":"<code>cellseg_gsontools.geometry.solidity(polygon, **kwargs)</code>","text":"<p>Compute the solidity of a polygon.</p> Note <p>Solidity measures the density of an object. It is defined as the ratio of the area of an object to the area of a convex hull of the object. A value of 1 signifies a solid object, and a value less than 1 will signify an object having an irregular boundary, or containing holes. - Wirth</p> <p>Solidity: $$ \\frac{A_{poly}}{A_{convex}} $$</p> <p>where \\(A_{poly}\\) is the area of the polygon and \\(A_{convex}\\) is the area of the convex hull.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The solidity value of a polygon between 0-1.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def solidity(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the solidity of a polygon.\n\n    Note:\n        Solidity measures the density of an object. It is defined as the\n        ratio of the area of an object to the area of a convex hull of the\n        object. A value of 1 signifies a solid object, and a value less than\n        1 will signify an object having an irregular boundary, or containing\n        holes.\n        - [Wirth](http://www.cyto.purdue.edu/cdroms/micro2/content/education/wirth10.pdf)\n\n    **Solidity:**\n    $$\n    \\\\frac{A_{poly}}{A_{convex}}\n    $$\n\n    where $A_{poly}$ is the area of the polygon and $A_{convex}$ is the area of the\n    convex hull.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The solidity value of a polygon between 0-1.\n    \"\"\"\n    convex_area = polygon.convex_hull.area\n    area = polygon.area\n\n    return area / convex_area\n</code></pre>"},{"location":"reference/geometry/sphericity_ref/","title":"sphericity","text":""},{"location":"reference/geometry/sphericity_ref/#cellseg_gsontools.geometry.sphericity","title":"<code>cellseg_gsontools.geometry.sphericity(polygon, **kwargs)</code>","text":"<p>Compute the sphericity of a polygon.</p> Note <p>Sphericity measures how close an object is to the shape of a \u201csphere\u201d. It is defined as the ratio of the radius of the minimum inscribing circle to the radius of the minimum bounding circle.</p> <p>Sphericity: $$ \\frac{\\text{MIR}}{\\text{MBR}} $$</p> <p>where \\(\\text{MIR}\\) is the radius of the minimum inscribing circle radius and \\(\\text{MBR}\\) is the radius of the minimum bounding radius.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The sphericity value of a polygon.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def sphericity(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the sphericity of a polygon.\n\n    Note:\n        Sphericity measures how close an object is to the shape of a \u201csphere\u201d.\n        It is defined as the ratio of the radius of the minimum inscribing circle\n        to the radius of the minimum bounding circle.\n\n    **Sphericity:**\n    $$\n    \\\\frac{\\\\text{MIR}}{\\\\text{MBR}}\n    $$\n\n    where $\\\\text{MIR}$ is the radius of the minimum inscribing circle radius and\n    $\\\\text{MBR}$ is the radius of the minimum bounding radius.\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The sphericity value of a polygon.\n    \"\"\"\n    _, _, ri = inscribing_circle(polygon)\n    rc = shapely.minimum_bounding_radius(polygon)\n\n    return ri / rc\n</code></pre>"},{"location":"reference/geometry/squareness_ref/","title":"squareness","text":""},{"location":"reference/geometry/squareness_ref/#cellseg_gsontools.geometry.squareness","title":"<code>cellseg_gsontools.geometry.squareness(polygon, **kwargs)</code>","text":"<p>Compute the squareness of a polygon.</p> Note <p>Squareness is a measure of how close an object is to a square.</p> <p>Squareness: $$ \\left(\\frac{4*\\sqrt{A_{poly}}}{P_{poly}}\\right)^2 $$</p> <p>where \\(A_{poly}\\) is the area of the polygon and \\(P_{poly}\\) is the perimeter of the polygon.</p> Note <p>For irregular shapes, squareness is close to zero and for circular shapes close to 1.3. For squares, equals 1</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Input shapely polygon object.</p> required <p>Returns:</p> Name Type Description <code>float</code> <code>float</code> <p>The squareness value of a polygon.</p> Source code in <code>cellseg_gsontools/geometry/shape_metrics.py</code> <pre><code>def squareness(polygon: Polygon, **kwargs) -&gt; float:\n    \"\"\"Compute the squareness of a polygon.\n\n    Note:\n        Squareness is a measure of how close an object is to a square.\n\n    **Squareness:**\n    $$\n    \\\\left(\\\\frac{4*\\\\sqrt{A_{poly}}}{P_{poly}}\\\\right)^2\n    $$\n\n    where $A_{poly}$ is the area of the polygon and $P_{poly}$ is the perimeter of\n    the polygon.\n\n    Note:\n        For irregular shapes, squareness is close to zero and for circular shapes close\n        to 1.3. For squares, equals 1\n\n    Parameters:\n        polygon (Polygon):\n            Input shapely polygon object.\n\n    Returns:\n        float:\n            The squareness value of a polygon.\n    \"\"\"\n    area = polygon.area\n    perimeter = polygon.length\n\n    return ((np.sqrt(area) * 4) / perimeter) ** 2\n</code></pre>"},{"location":"reference/graph/dist_thresh_weights_sequential_ref/","title":"dist_thresh_weights_sequential","text":""},{"location":"reference/graph/dist_thresh_weights_sequential_ref/#cellseg_gsontools.graphs.dist_thresh_weights_sequential","title":"<code>cellseg_gsontools.graphs.dist_thresh_weights_sequential(gdf, w, thresh, id_col=None, include_self=False)</code>","text":"<p>Threshold edges based on distance to center node.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The input geodataframe.</p> required <code>w</code> <code>W</code> <p>The input spatial weights object.</p> required <code>thresh</code> <code>float</code> <p>The distance threshold.</p> required <code>id_col</code> <code>str</code> <p>The unique id column in the gdf. If None, this uses <code>set_uid</code> to set it.</p> <code>None</code> <code>include_self</code> <code>bool, default=True</code> <p>Whether to include self-loops in the neighbors.</p> <code>False</code> <p>Returns:</p> Type Description <code>W</code> <p>libpysal.weights.W: A libpysal spatial weights object, containing the neighbor graph data.</p> Source code in <code>cellseg_gsontools/graphs.py</code> <pre><code>def dist_thresh_weights_sequential(\n    gdf: gpd.GeoDataFrame,\n    w: W,\n    thresh: float,\n    id_col: Optional[str] = None,\n    include_self: bool = False,\n) -&gt; W:\n    \"\"\"Threshold edges based on distance to center node.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The input geodataframe.\n        w (libpysal.weights.W):\n            The input spatial weights object.\n        thresh (float):\n            The distance threshold.\n        id_col (str, optional):\n            The unique id column in the gdf. If None, this uses `set_uid` to set it.\n        include_self (bool, default=True):\n            Whether to include self-loops in the neighbors.\n\n    Returns:\n        libpysal.weights.W:\n            A libpysal spatial weights object, containing the neighbor graph data.\n    \"\"\"\n    gdf = gdf.copy()\n\n    # drop duplicate rows\n    gdf = gdf.drop_duplicates(subset=[id_col], keep=\"first\")\n    gdf[\"nhood\"] = pd.Series(list(w.neighbors.values()), index=gdf.index)\n\n    new_neighbors = []\n    for _, row in gdf.iterrows():\n        neighbor_rows = gdf[gdf.loc[:, id_col].isin(row.nhood)]\n        nhood_dist = [\n            np.round(row.geometry.centroid.distance(ngh), 2)\n            for ngh in neighbor_rows.geometry.centroid\n        ]\n\n        new_neighbors.append(\n            _drop_neighbors(row.nhood, nhood_dist, thresh, include_self=include_self)\n        )\n\n    gdf[\"new_neighbors\"] = new_neighbors\n    return W(dict(zip(gdf[id_col], gdf[\"new_neighbors\"])), silence_warnings=True)\n</code></pre>"},{"location":"reference/graph/fit_graph_ref/","title":"fit_graph","text":""},{"location":"reference/graph/fit_graph_ref/#cellseg_gsontools.graphs.fit_graph","title":"<code>cellseg_gsontools.graphs.fit_graph(gdf, type, id_col=None, thresh=None, silence_warnings=True, **kwargs)</code>","text":"<p>Fit a <code>libpysal</code> spatial weights graph to a gdf.</p> <p>Optionally, a distance threshold can be set for edges that are too long.</p> <p>This is a wrapper to fit <code>libpysal</code> graph with additional distance threshing.</p> Note <p>Allowed graph fitting methods:</p> <ul> <li><code>delaunay</code></li> <li><code>knn</code></li> <li><code>distband</code></li> <li><code>relative_nhood</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The input geodataframe.</p> required <code>type</code> <code>str</code> <p>The type of the libpysal graph. Allowed: \"delaunay\", \"knn\", \"distband\", \"relative_nhood\"</p> required <code>id_col</code> <code>str</code> <p>The unique id column in the gdf. If None, this uses <code>set_uid</code> to set it.</p> <code>None</code> <code>thresh</code> <code>float</code> <p>A distance threshold for too long edges.</p> <code>None</code> <code>silence_warnings</code> <code>bool</code> <p>Flag to silence the warnings.</p> <code>True</code> <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Arbitrary keyword arguments for the Graph init functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>W</code> <p>libpysal.weights.W or None: A libpysal spatial weights object, containing the neighbor graph data. Returns None if the input gdf is empty.</p> <p>Examples:</p> <p>Fit a DistanceBand to a gdf with a dist threshold of 120.0.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; w = fit_graph(gdf, type=\"distband\", thresh=120)\n</code></pre> <p>Fit a delaunay graph to a gdf without a dist threshold.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n&gt;&gt;&gt; w = fit_graph(gdf, type=\"delaunay\", thresh=None)\n</code></pre> Source code in <code>cellseg_gsontools/graphs.py</code> <pre><code>def fit_graph(\n    gdf: gpd.GeoDataFrame,\n    type: str,\n    id_col: Optional[str] = None,\n    thresh: Optional[float] = None,\n    silence_warnings: bool = True,\n    **kwargs,\n) -&gt; W:\n    \"\"\"Fit a `libpysal` spatial weights graph to a gdf.\n\n    Optionally, a distance threshold can be set for edges that are too long.\n\n    This is a wrapper to fit `libpysal` graph with additional distance threshing.\n\n    Note:\n        Allowed graph fitting methods:\n\n        - `delaunay`\n        - `knn`\n        - `distband`\n        - `relative_nhood`\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The input geodataframe.\n        type (str):\n            The type of the libpysal graph. Allowed: \"delaunay\", \"knn\", \"distband\",\n            \"relative_nhood\"\n        id_col (str):\n            The unique id column in the gdf. If None, this uses `set_uid` to set it.\n        thresh (float):\n            A distance threshold for too long edges.\n        silence_warnings (bool):\n            Flag to silence the warnings.\n        **kwargs (Dict[str, Any]):\n            Arbitrary keyword arguments for the Graph init functions.\n\n    Returns:\n        libpysal.weights.W or None:\n            A libpysal spatial weights object, containing the neighbor graph data.\n            Returns None if the input gdf is empty.\n\n    Examples:\n        Fit a DistanceBand to a gdf with a dist threshold of 120.0.\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; w = fit_graph(gdf, type=\"distband\", thresh=120)\n\n        Fit a delaunay graph to a gdf without a dist threshold.\n        &gt;&gt;&gt; from cellseg_gsontools.graphs import fit_graph\n        &gt;&gt;&gt; w = fit_graph(gdf, type=\"delaunay\", thresh=None)\n    \"\"\"\n    allowed = (\n        \"delaunay\",\n        \"knn\",\n        \"distband\",\n        \"relative_nhood\",\n    )\n    if type not in allowed:\n        raise ValueError(f\"Illegal graph type given. Got: {type}. Allowed: {allowed}.\")\n\n    if gdf is None or gdf.empty:\n        return\n\n    # warn if id_col is not provided\n    if not silence_warnings:\n        _graph_warn(type, id_col)\n\n    # can't fit delaunay or relative nhood graphs with less than 4 points\n    if type in (\"delaunay\", \"relative_nhood\"):\n        if len(gdf) &lt; 4:\n            return\n    if type == \"delaunay\":\n        # NOTE: neighbor keys start from 0\n        w = Delaunay.from_dataframe(\n            gdf.centroid,\n            silence_warnings=True,\n            use_index=True,\n            ids=gdf[id_col],\n            **kwargs,\n        )\n    elif type == \"relative_nhood\":\n        # NOTE: neighbor indices start from 0\n        w = Relative_Neighborhood.from_dataframe(\n            gdf.centroid, silence_warnings=True, **kwargs\n        )\n    elif type == \"knn\":\n        if \"ids\" in list(kwargs.keys()):  # drop ids kwarg since it fails\n            kwargs.pop(\"ids\")\n\n        # NOTE: neighbor indices equal gdf[`\u00ecd_col`]\n        w = KNN.from_dataframe(gdf, silence_warnings=True, ids=id_col, **kwargs)\n    elif type == \"distband\":\n        if thresh is None:\n            raise ValueError(\"DistBand requires `thresh` param. Not provided.\")\n\n        if \"ids\" in list(kwargs.keys()):  # drop ids kwarg since it fails\n            kwargs.pop(\"ids\")\n\n        # NOTE: neighbor indices equal gdf[`\u00ecd_col`]\n        w = DistanceBand.from_dataframe(\n            gdf,\n            threshold=thresh,\n            alpha=-1.0,\n            ids=id_col,\n            silence_warnings=True,\n            **kwargs,\n        )\n\n    # convert graph indices to global ids\n    if type in (\"delaunay\", \"relative_nhood\"):\n        w = _graph_to_index(w, gdf)\n        if id_col is not None:\n            w = _graph_to_global_ids(w, gdf, id_col)\n\n    # # Threshold edges based on distance to center node.\n    if thresh is not None and type != \"distband\":\n        w = dist_thresh_weights_sequential(gdf, w, thresh, id_col=id_col)\n\n    return w\n</code></pre>"},{"location":"reference/graph/get_border_crosser_links_ref/","title":"get_border_crosser_links","text":""},{"location":"reference/graph/get_border_crosser_links_ref/#cellseg_gsontools.graphs.get_border_crosser_links","title":"<code>cellseg_gsontools.graphs.get_border_crosser_links(union_weights, roi_weights, iface_weights, only_border_crossers=True)</code>","text":"<p>Get the links that cross the border between the ROI and interface cells.</p> <p>Parameters:</p> Name Type Description Default <code>union_weights</code> <code>W</code> <p>The union of the ROI and interface weights. NOTE: contains links between ROI &amp; interface cells.</p> required <code>roi_weights</code> <code>W</code> <p>The ROI weights. NOTE: contains only links between ROI cells.</p> required <code>iface_weights</code> <code>W</code> <p>The interface weights. NOTE: contains only links between interface cells.</p> required <code>only_border_crossers</code> <code>bool</code> <p>Whether to return only the links that cross the border between the ROI and interface cells or all neighbors of the node that has a border crossing link. This includes also the liks that do not cross the border. By default True.</p> <code>True</code> <p>Returns:</p> Name Type Description <code>W</code> <code>W</code> <p>The links that cross the border between the ROI and interface cells.</p> Source code in <code>cellseg_gsontools/graphs.py</code> <pre><code>def get_border_crosser_links(\n    union_weights: W,\n    roi_weights: W,\n    iface_weights: W,\n    only_border_crossers: bool = True,\n) -&gt; W:\n    \"\"\"Get the links that cross the border between the ROI and interface cells.\n\n    Parameters:\n        union_weights (W):\n            The union of the ROI and interface weights. NOTE: contains links between ROI\n            &amp; interface cells.\n        roi_weights (W):\n            The ROI weights. NOTE: contains only links between ROI cells.\n        iface_weights (W):\n            The interface weights. NOTE: contains only links between interface cells.\n        only_border_crossers (bool, optional):\n            Whether to return only the links that cross the border between the ROI and\n            interface cells or all neighbors of the node that has a border crossing link.\n            This includes also the liks that do not cross the border. By default True.\n\n    Returns:\n        W:\n            The links that cross the border between the ROI and interface cells.\n    \"\"\"\n    # loop the nodes in the union graph and check if they are border crossing links\n    graph = {}\n    for node, neigh in union_weights.neighbors.items():\n        is_roi_node = node in roi_weights.neighbors.keys()\n        is_iface_node = node in iface_weights.neighbors.keys()\n\n        neighbors = []\n        for n in neigh:\n            is_roi_neigh = n in roi_weights.neighbors.keys()\n            is_iface_neigh = n in iface_weights.neighbors.keys()\n            if (is_roi_node and is_iface_neigh) or (is_iface_node and is_roi_neigh):\n                # return all neighbors if requested\n                if not only_border_crossers:\n                    neighbors.extend(neigh)\n                    break\n                else:\n                    neighbors.append(n)\n\n        graph[node] = neighbors\n\n    return W(graph, silence_warnings=True)\n</code></pre>"},{"location":"reference/grid/fit_spatial_grid_ref/","title":"fit_spatial_grid","text":""},{"location":"reference/grid/fit_spatial_grid_ref/#cellseg_gsontools.grid.fit_spatial_grid","title":"<code>cellseg_gsontools.grid.fit_spatial_grid(gdf, grid_type='square', **kwargs)</code>","text":"<p>Quick wrapper to fit either a hex or square grid to a <code>geopandas.GeoDataFrame</code>.</p> Note <ul> <li>Hexagonal grid requires the <code>h3</code> package to be installed.</li> <li>Hexagonal grid only works for a gdf containing one single polygon.</li> </ul> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>GeoDataFrame to fit grid to.</p> required <code>grid_type</code> <code>str</code> <p>Type of grid to fit, by default \"square\".</p> <code>'square'</code> <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Keyword arguments to pass to grid fitting functions.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: Fitted grid.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If grid_type is not one of \"square\" or \"hex\".</p> <code>ImportError</code> <p>If grid_type is \"hex\" and the <code>h3</code> package is not installed.</p> <p>Examples:</p> <p>Fit a hexagonal grid to a gdf:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import read_gdf\n&gt;&gt;&gt; from cellseg_gsontools.grid import fit_spatial_grid\n&gt;&gt;&gt; # Read in the tissue areas\n&gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n&gt;&gt;&gt; # Fit the grid\n&gt;&gt;&gt; hex_grid = fit_spatial_grid(area_gdf, grid_type=\"hex\", resolution=9)\n&gt;&gt;&gt; hex_grid\ngpd.GeoDataFrame\n</code></pre> <p>Fit a square grid to a gdf:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import read_gdf\n&gt;&gt;&gt; from cellseg_gsontools.grid import fit_spatial_grid\n&gt;&gt;&gt; # Read in the tissue areas\n&gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n&gt;&gt;&gt; # Fit the grid\n&gt;&gt;&gt; sq_grid = fit_spatial_grid(\n...     area_gdf, grid_type=\"square\", patch_size=(256, 256), stride=(256, 256)\n... )\n&gt;&gt;&gt; sq_grid\ngpd.GeoDataFrame\n</code></pre> Source code in <code>cellseg_gsontools/grid.py</code> <pre><code>def fit_spatial_grid(\n    gdf: gpd.GeoDataFrame, grid_type: str = \"square\", **kwargs\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Quick wrapper to fit either a hex or square grid to a `geopandas.GeoDataFrame`.\n\n    Note:\n        - Hexagonal grid requires the `h3` package to be installed.\n        - Hexagonal grid only works for a gdf containing one single polygon.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            GeoDataFrame to fit grid to.\n        grid_type (str):\n            Type of grid to fit, by default \"square\".\n        **kwargs (Dict[str, Any]):\n            Keyword arguments to pass to grid fitting functions.\n\n    Returns:\n        gpd.GeoDataFrame:\n            Fitted grid.\n\n    Raises:\n        ValueError: If grid_type is not one of \"square\" or \"hex\".\n        ImportError: If grid_type is \"hex\" and the `h3` package is not installed.\n\n    Examples:\n        Fit a hexagonal grid to a gdf:\n        &gt;&gt;&gt; from cellseg_gsontools import read_gdf\n        &gt;&gt;&gt; from cellseg_gsontools.grid import fit_spatial_grid\n        &gt;&gt;&gt; # Read in the tissue areas\n        &gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n        &gt;&gt;&gt; # Fit the grid\n        &gt;&gt;&gt; hex_grid = fit_spatial_grid(area_gdf, grid_type=\"hex\", resolution=9)\n        &gt;&gt;&gt; hex_grid\n        gpd.GeoDataFrame\n\n        Fit a square grid to a gdf:\n        &gt;&gt;&gt; from cellseg_gsontools import read_gdf\n        &gt;&gt;&gt; from cellseg_gsontools.grid import fit_spatial_grid\n        &gt;&gt;&gt; # Read in the tissue areas\n        &gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n        &gt;&gt;&gt; # Fit the grid\n        &gt;&gt;&gt; sq_grid = fit_spatial_grid(\n        ...     area_gdf, grid_type=\"square\", patch_size=(256, 256), stride=(256, 256)\n        ... )\n        &gt;&gt;&gt; sq_grid\n        gpd.GeoDataFrame\n    \"\"\"\n    allowed = [\"square\", \"hex\"]\n    if grid_type not in allowed:\n        raise ValueError(f\"grid_type must be one of {allowed}, got {grid_type}\")\n\n    if grid_type == \"square\":\n        grid = grid_overlay(gdf, **kwargs)\n    else:\n        if not _has_h3:\n            raise ImportError(\"h3 package not installed. Install with `pip install h3`\")\n        grid = hexgrid_overlay(gdf, **kwargs)\n\n    return grid\n</code></pre>"},{"location":"reference/grid/grid_classify_ref/","title":"grid_classify","text":""},{"location":"reference/grid/grid_classify_ref/#cellseg_gsontools.grid.grid_classify","title":"<code>cellseg_gsontools.grid.grid_classify(grid, objs, metric_func, predicate, new_col_names, parallel=True, num_processes=-1, pbar=False, **kwargs)</code>","text":"<p>Classify the grid based on objs inside the grid cells.</p> <p>Parameters:</p> Name Type Description Default <code>grid</code> <code>GeoDataFrame</code> <p>The grid of rectangles to classify.</p> required <code>objs</code> <code>GeoDataFrame</code> <p>The objects to use for classification.</p> required <code>metric_func</code> <code>Callable</code> <p>The metric/heuristic function to use for classification.</p> required <code>predicate</code> <code>str</code> <p>The predicate to use for the spatial join. Allowed values are \"intersects\" and \"within\".</p> required <code>new_col_names</code> <code>Union[Tuple[str, ...], str]</code> <p>The name of the new column(s) in the grid gdf.</p> required <code>parallel</code> <code>bool</code> <p>Whether to use parallel processing.</p> <code>True</code> <code>num_processes</code> <code>int</code> <p>The number of processes to use. If -1, uses all available cores. Ignored if parallel=False.</p> <code>-1</code> <code>pbar</code> <code>bool</code> <p>Whether to show a progress bar. Ignored if parallel=False.</p> <code>False</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The grid with the new columns added.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If predicate is not one of \"intersects\" or \"within\".</p> <p>Examples:</p> <p>Get the number of immune cells in each grid cell at the tumor stroma interface:</p> <pre><code>&gt;&gt;&gt; import geopandas as gpd\n&gt;&gt;&gt; from shapely.geometry import Polygon\n&gt;&gt;&gt; from functools import partial\n&gt;&gt;&gt; from cellseg_gsontools import gdf_apply, read_gdf\n&gt;&gt;&gt; from cellseg_gsontools.grid import grid_classify, grid_overlay\n&gt;&gt;&gt; from cellseg_gsontools.context import InterfaceContext\n&gt;&gt;&gt; # Define a heuristic function to get the number of immune cells\n&gt;&gt;&gt; def get_immune_cell_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; int:\n...     try:\n...         cnt = gdf.class_name.value_counts()[\"inflammatory\"]\n...     except KeyError:\n...         cnt = 0\n...     return int(cnt)\n&gt;&gt;&gt; # Read in the tissue areas and cells\n&gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n&gt;&gt;&gt; cell_gdf = gpd.read_file(\"path/to/cell.geojson\")\n&gt;&gt;&gt; # Fit a tumor-stroma interface\n&gt;&gt;&gt; tumor_stroma_iface = InterfaceContext(\n...     area_gdf=area_gdf,\n...     cell_gdf=cell_gdf,\n...     top_labels=\"area_cin\",\n...     bottom_labels=\"areastroma\",\n...     buffer_dist=250,\n...     graph_type=\"distband\",\n...     dist_thresh=75,\n...     patch_size=(128, 128),\n...     stride=(128, 128),\n...     min_area_size=50000,\n... )\n&gt;&gt;&gt; tumor_stroma_iface.fit(verbose=False)\n&gt;&gt;&gt; # Get the grid and the cells at the interface\n&gt;&gt;&gt; iface_grid = grid_overlay(\n...     tumor_stroma_iface.context2gdf(\"interface_area\"),\n...     patch_size=(128, 128),\n...     stride=(128, 128),\n... )\n&gt;&gt;&gt; cells = tumor_stroma_iface.context2gdf(\"interface_cells\")\n&gt;&gt;&gt; # Classify the grid\n&gt;&gt;&gt; iface_grid = grid_classify(\n&gt;&gt;&gt;     grid=iface_grid,\n&gt;&gt;&gt;     objs=cells,\n&gt;&gt;&gt;     metric_func=get_immune_cnt,\n&gt;&gt;&gt;     predicate=\"intersects\",\n&gt;&gt;&gt;     new_col_name=\"immune_cnt\",\n&gt;&gt;&gt;     parallel=True,\n&gt;&gt;&gt;     pbar=True,\n&gt;&gt;&gt;     num_processes=-1\n&gt;&gt;&gt; )\n&gt;&gt;&gt; iface_grid\ngeometry  immune_cnt\n28  POLYGON ((20032.00000 54098.50000, 20160.00000... 15\n29  POLYGON ((20160.00000 54098.50000, 20288.00000... 3\n</code></pre> Source code in <code>cellseg_gsontools/grid.py</code> <pre><code>def grid_classify(\n    grid: gpd.GeoDataFrame,\n    objs: gpd.GeoDataFrame,\n    metric_func: Callable,\n    predicate: str,\n    new_col_names: Union[Tuple[str, ...], str],\n    parallel: bool = True,\n    num_processes: int = -1,\n    pbar: bool = False,\n    **kwargs,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Classify the grid based on objs inside the grid cells.\n\n    Parameters:\n        grid (gpd.GeoDataFrame):\n            The grid of rectangles to classify.\n        objs (gpd.GeoDataFrame):\n            The objects to use for classification.\n        metric_func (Callable):\n            The metric/heuristic function to use for classification.\n        predicate (str):\n            The predicate to use for the spatial join. Allowed values are \"intersects\"\n            and \"within\".\n        new_col_names (Union[Tuple[str, ...], str]):\n            The name of the new column(s) in the grid gdf.\n        parallel (bool):\n            Whether to use parallel processing.\n        num_processes (int):\n            The number of processes to use. If -1, uses all available cores.\n            Ignored if parallel=False.\n        pbar (bool):\n            Whether to show a progress bar. Ignored if parallel=False.\n\n    Returns:\n        gpd.GeoDataFrame:\n            The grid with the new columns added.\n\n    Raises:\n        ValueError: If predicate is not one of \"intersects\" or \"within\".\n\n    Examples:\n        Get the number of immune cells in each grid cell at the tumor stroma interface:\n        &gt;&gt;&gt; import geopandas as gpd\n        &gt;&gt;&gt; from shapely.geometry import Polygon\n        &gt;&gt;&gt; from functools import partial\n        &gt;&gt;&gt; from cellseg_gsontools import gdf_apply, read_gdf\n        &gt;&gt;&gt; from cellseg_gsontools.grid import grid_classify, grid_overlay\n        &gt;&gt;&gt; from cellseg_gsontools.context import InterfaceContext\n        &gt;&gt;&gt; # Define a heuristic function to get the number of immune cells\n        &gt;&gt;&gt; def get_immune_cell_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; int:\n        ...     try:\n        ...         cnt = gdf.class_name.value_counts()[\"inflammatory\"]\n        ...     except KeyError:\n        ...         cnt = 0\n        ...     return int(cnt)\n        &gt;&gt;&gt; # Read in the tissue areas and cells\n        &gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n        &gt;&gt;&gt; cell_gdf = gpd.read_file(\"path/to/cell.geojson\")\n        &gt;&gt;&gt; # Fit a tumor-stroma interface\n        &gt;&gt;&gt; tumor_stroma_iface = InterfaceContext(\n        ...     area_gdf=area_gdf,\n        ...     cell_gdf=cell_gdf,\n        ...     top_labels=\"area_cin\",\n        ...     bottom_labels=\"areastroma\",\n        ...     buffer_dist=250,\n        ...     graph_type=\"distband\",\n        ...     dist_thresh=75,\n        ...     patch_size=(128, 128),\n        ...     stride=(128, 128),\n        ...     min_area_size=50000,\n        ... )\n        &gt;&gt;&gt; tumor_stroma_iface.fit(verbose=False)\n        &gt;&gt;&gt; # Get the grid and the cells at the interface\n        &gt;&gt;&gt; iface_grid = grid_overlay(\n        ...     tumor_stroma_iface.context2gdf(\"interface_area\"),\n        ...     patch_size=(128, 128),\n        ...     stride=(128, 128),\n        ... )\n        &gt;&gt;&gt; cells = tumor_stroma_iface.context2gdf(\"interface_cells\")\n        &gt;&gt;&gt; # Classify the grid\n        &gt;&gt;&gt; iface_grid = grid_classify(\n        &gt;&gt;&gt;     grid=iface_grid,\n        &gt;&gt;&gt;     objs=cells,\n        &gt;&gt;&gt;     metric_func=get_immune_cnt,\n        &gt;&gt;&gt;     predicate=\"intersects\",\n        &gt;&gt;&gt;     new_col_name=\"immune_cnt\",\n        &gt;&gt;&gt;     parallel=True,\n        &gt;&gt;&gt;     pbar=True,\n        &gt;&gt;&gt;     num_processes=-1\n        &gt;&gt;&gt; )\n        &gt;&gt;&gt; iface_grid\n        geometry  immune_cnt\n        28  POLYGON ((20032.00000 54098.50000, 20160.00000... 15\n        29  POLYGON ((20160.00000 54098.50000, 20288.00000... 3\n    \"\"\"\n    allowed = [\"intersects\", \"within\"]\n    if predicate not in allowed:\n        raise ValueError(f\"predicate must be one of {allowed}. Got {predicate}\")\n\n    if isinstance(new_col_names, str):\n        new_col_names = [new_col_names]\n\n    func = partial(\n        get_rect_metric, objs=objs, predicate=predicate, metric_func=metric_func\n    )\n    grid.loc[:, list(new_col_names)] = gdf_apply(\n        grid,\n        func=func,\n        parallel=parallel,\n        pbar=pbar,\n        num_processes=num_processes,\n        columns=[\"geometry\"],\n    )\n\n    return grid\n</code></pre>"},{"location":"reference/grid/grid_overlay_ref/","title":"grid_overlay","text":""},{"location":"reference/grid/grid_overlay_ref/#cellseg_gsontools.grid.grid_overlay","title":"<code>cellseg_gsontools.grid.grid_overlay(gdf, patch_size=(256, 256), stride=(256, 256), pad=20, predicate='intersects')</code>","text":"<p>Overlay a square grid to the given areas of a <code>geopandas.GeoDataFrame</code>.</p> Note <p>Returns None if the gdf is empty.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>GeoDataFrame to fit the grid to. Uses the bounding box of the GeoDataFrame to fit the grid.</p> required <code>patch_size</code> <code>Tuple[int, int]</code> <p>Patch size of the grid.</p> <code>(256, 256)</code> <code>stride</code> <code>Tuple[int, int]</code> <p>Stride of the sliding window in the grid.</p> <code>(256, 256)</code> <code>pad</code> <code>int</code> <p>Pad the bounding box with the given number of pixels, by default None.</p> <code>20</code> <code>predicate</code> <code>str</code> <p>Predicate to use for the spatial join, by default \"intersects\". Allowed values are \"intersects\" and \"within\".</p> <code>'intersects'</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: GeoDataFrame with the grid fitted to the given GeoDataFrame.</p> <p>Raises:</p> Type Description <code>ValueError</code> <p>If predicate is not one of \"intersects\" or \"within\".</p> <p>Examples:</p> <p>Fit a square grid to a gdf:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import read_gdf\n&gt;&gt;&gt; from cellseg_gsontools.grid import grid_overlay\n&gt;&gt;&gt; # Read in the tissue areas\n&gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n&gt;&gt;&gt; # Fit the grid\n&gt;&gt;&gt; sq_grid = grid_overlay(area_gdf, patch_size=(256, 256), stride=(256, 256))\n&gt;&gt;&gt; sq_grid\ngpd.GeoDataFrame\n</code></pre> Source code in <code>cellseg_gsontools/grid.py</code> <pre><code>def grid_overlay(\n    gdf: gpd.GeoDataFrame,\n    patch_size: Tuple[int, int] = (256, 256),\n    stride: Tuple[int, int] = (256, 256),\n    pad: int = 20,\n    predicate: str = \"intersects\",\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Overlay a square grid to the given areas of a `geopandas.GeoDataFrame`.\n\n    Note:\n        Returns None if the gdf is empty.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            GeoDataFrame to fit the grid to. Uses the bounding box of the GeoDataFrame\n            to fit the grid.\n        patch_size (Tuple[int, int]):\n            Patch size of the grid.\n        stride (Tuple[int, int]):\n            Stride of the sliding window in the grid.\n        pad (int):\n            Pad the bounding box with the given number of pixels, by default None.\n        predicate (str):\n            Predicate to use for the spatial join, by default \"intersects\".\n            Allowed values are \"intersects\" and \"within\".\n\n    Returns:\n        gpd.GeoDataFrame:\n            GeoDataFrame with the grid fitted to the given GeoDataFrame.\n\n    Raises:\n        ValueError: If predicate is not one of \"intersects\" or \"within\".\n\n    Examples:\n        Fit a square grid to a gdf:\n        &gt;&gt;&gt; from cellseg_gsontools import read_gdf\n        &gt;&gt;&gt; from cellseg_gsontools.grid import grid_overlay\n        &gt;&gt;&gt; # Read in the tissue areas\n        &gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n        &gt;&gt;&gt; # Fit the grid\n        &gt;&gt;&gt; sq_grid = grid_overlay(area_gdf, patch_size=(256, 256), stride=(256, 256))\n        &gt;&gt;&gt; sq_grid\n        gpd.GeoDataFrame\n    \"\"\"\n    if gdf.empty or gdf is None:\n        return\n\n    allowed = [\"intersects\", \"within\"]\n    if predicate not in allowed:\n        raise ValueError(f\"predicate must be one of {allowed}. Got {predicate}\")\n    grid = get_grid(gdf, patch_size, stride, pad=pad)\n    grid.set_crs(epsg=4328, inplace=True, allow_override=True)\n    _, grid_inds = grid.sindex.query(gdf.geometry, predicate=predicate)\n    grid = grid.iloc[np.unique(grid_inds)]\n    # grid = grid.sjoin(gdf, predicate=predicate)\n\n    return grid.drop_duplicates(\"geometry\")\n</code></pre>"},{"location":"reference/grid/hexgrid_overlay_ref/","title":"hexgrid_overlay","text":""},{"location":"reference/grid/hexgrid_overlay_ref/#cellseg_gsontools.grid.hexgrid_overlay","title":"<code>cellseg_gsontools.grid.hexgrid_overlay(gdf, resolution=9, to_lonlat=True)</code>","text":"<p>Fit a <code>h3</code> hexagonal grid on top of a <code>geopandas.GeoDataFrame</code>.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>GeoDataFrame to fit grid to.</p> required <code>resolution</code> <code>int</code> <p>H3 resolution, by default 9.</p> <code>9</code> <code>to_lonlat</code> <code>bool</code> <p>Whether to convert to lonlat coordinates, by default True.</p> <code>True</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: Fitted h3 hex grid.</p> <p>Examples:</p> <p>Fit a hexagonal grid to a gdf:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import read_gdf\n&gt;&gt;&gt; from cellseg_gsontools.grid import hexgrid_overlay\n&gt;&gt;&gt; # Read in the tissue areas\n&gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n&gt;&gt;&gt; # Fit the grid\n&gt;&gt;&gt; hex_grid = hexgrid_overlay(area_gdf, resolution=9)\n&gt;&gt;&gt; hex_grid\ngpd.GeoDataFrame\n</code></pre> Source code in <code>cellseg_gsontools/grid.py</code> <pre><code>def hexgrid_overlay(\n    gdf: gpd.GeoDataFrame, resolution: int = 9, to_lonlat: bool = True\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Fit a `h3` hexagonal grid on top of a `geopandas.GeoDataFrame`.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            GeoDataFrame to fit grid to.\n        resolution (int):\n            H3 resolution, by default 9.\n        to_lonlat (bool):\n            Whether to convert to lonlat coordinates, by default True.\n\n    Returns:\n        gpd.GeoDataFrame:\n            Fitted h3 hex grid.\n\n    Examples:\n        Fit a hexagonal grid to a gdf:\n        &gt;&gt;&gt; from cellseg_gsontools import read_gdf\n        &gt;&gt;&gt; from cellseg_gsontools.grid import hexgrid_overlay\n        &gt;&gt;&gt; # Read in the tissue areas\n        &gt;&gt;&gt; area_gdf = gpd.read_file(\"path/to/area.geojson\")\n        &gt;&gt;&gt; # Fit the grid\n        &gt;&gt;&gt; hex_grid = hexgrid_overlay(area_gdf, resolution=9)\n        &gt;&gt;&gt; hex_grid\n        gpd.GeoDataFrame\n    \"\"\"\n    if gdf.empty or gdf is None:\n        return\n\n    # drop invalid geometries if there are any after buffer\n    gdf.geometry = gdf.geometry.buffer(0)\n    gdf = gdf[gdf.is_valid]\n\n    orig_crs = gdf.crs\n\n    poly = shapely.force_2d(gdf.unary_union)\n    if isinstance(poly, Polygon):\n        hexagons = poly2hexgrid(poly, resolution=resolution, to_lonlat=to_lonlat)\n    else:\n        output = []\n        for geom in poly.geoms:\n            hexes = poly2hexgrid(geom, resolution=resolution, to_lonlat=to_lonlat)\n            output.append(hexes)\n        hexagons = pd.concat(output)\n\n    return hexagons.set_crs(\n        orig_crs, inplace=True, allow_override=True\n    ).drop_duplicates(\"geometry\")\n</code></pre>"},{"location":"reference/io/gdf_to_file_ref/","title":"gdf_to_file","text":""},{"location":"reference/io/gdf_to_file_ref/#cellseg_gsontools.gdf_to_file","title":"<code>cellseg_gsontools.gdf_to_file(gdf, out_fn, format='.feather')</code>","text":"<p>Write a geojson/feather/parquet file from a gdf.</p> <p>This is wrapper around <code>geopandas.GeoDataFrame</code> I/O methods that adds some extra functionality.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The input gdf.</p> required <code>out_fn</code> <code>Union[str, Path]</code> <p>The output filename.</p> required <code>format</code> <code>str</code> <p>The output format. One of \".feather\", \".parquet\", \".geojson\".</p> <code>'.feather'</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If <code>format</code> is not one of \".feather\", \".geojson\", \".parquet\".</p> <code>ValueError</code> <p>If the input gdf does not have a \"class_name\" column.</p> <p>Examples:</p> <p>Write a geojson file.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import gdf_to_file\n&gt;&gt;&gt; gdf_to_file(gdf, \"out.geojson\")\n</code></pre> Source code in <code>cellseg_gsontools/merging/save_utils.py</code> <pre><code>def gdf_to_file(\n    gdf: gpd.GeoDataFrame,\n    out_fn: Union[str, Path],\n    format: str = \".feather\",\n) -&gt; None:\n    \"\"\"Write a geojson/feather/parquet file from a gdf.\n\n    This is wrapper around `geopandas.GeoDataFrame` I/O methods\n    that adds some extra functionality.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The input gdf.\n        out_fn (Union[str, Path]):\n            The output filename.\n        format (str):\n            The output format. One of \".feather\", \".parquet\", \".geojson\".\n\n    Raises:\n        ValueError: If `format` is not one of \".feather\", \".geojson\", \".parquet\".\n        ValueError: If the input gdf does not have a \"class_name\" column.\n\n    Examples:\n        Write a geojson file.\n        &gt;&gt;&gt; from cellseg_gsontools import gdf_to_file\n        &gt;&gt;&gt; gdf_to_file(gdf, \"out.geojson\")\n    \"\"\"\n    out_fn = Path(out_fn)\n    if format not in (\".feather\", \".parquet\", \".geojson\", None):\n        raise ValueError(\n            f\"Invalid format. Got: {format}. Allowed: .feather, .parquet, .geojson\"\n        )\n\n    if \"class_name\" not in gdf.columns:\n        raise ValueError(\"The input gdf needs to have a 'class_name' column.\")\n\n    # add objectType col (QuPath)\n    if \"objectType\" not in gdf.columns:\n        gdf[\"objectType\"] = \"annotation\"\n\n    # add classification col (QuPath)\n    if \"classification\" not in gdf.columns:\n        gdf[\"classification\"] = gdf_apply(\n            gdf, _add_qupath_classification, axis=1, columns=[\"class_name\"]\n        )\n\n    if format == \".feather\":\n        gdf.to_feather(out_fn.with_suffix(\".feather\"))\n    elif format == \".parquet\":\n        gdf.to_parquet(out_fn.with_suffix(\".parquet\"))\n    elif format == \".geojson\":\n        gdf.to_file(out_fn.with_suffix(\".geojson\"), driver=\"GeoJSON\", index=False)\n</code></pre>"},{"location":"reference/io/read_gdf_ref/","title":"read_gdf","text":""},{"location":"reference/io/read_gdf_ref/#cellseg_gsontools.read_gdf","title":"<code>cellseg_gsontools.read_gdf(fname, silence_warnigns=True)</code>","text":"<p>Read a file into a geodataframe.</p> <p>This is a wrapper around <code>geopandas</code> I/O that adds some extra functionality.</p> Note <p>Allowed formats:</p> <ul> <li><code>.json</code>,</li> <li><code>.geojson</code>,</li> <li><code>.feather</code>,</li> <li><code>.parquet</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>fname</code> <code>Union[Path, str]</code> <p>The filename of the gson file.</p> required <code>silence_warnigns</code> <code>bool</code> <p>Whether to silence warnings, by default True.</p> <code>True</code> <p>Raises:</p> Type Description <code>ValueError</code> <p>If suffix is not one of \".json\", \".geojson\", \".feather\", \".parquet\".</p> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The geodataframe.</p> <p>Examples:</p> <p>Read a geojson file that is QuPath-readable.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf\n&gt;&gt;&gt; gdf = read_gdf(\"path/to/file.json\")\n</code></pre> Source code in <code>cellseg_gsontools/utils.py</code> <pre><code>def read_gdf(\n    fname: Union[Path, str],\n    silence_warnigns: bool = True,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Read a file into a geodataframe.\n\n    This is a wrapper around `geopandas` I/O that adds some extra\n    functionality.\n\n    Note:\n        Allowed formats:\n\n        - `.json`,\n        - `.geojson`,\n        - `.feather`,\n        - `.parquet`\n\n    Parameters:\n        fname (Union[Path, str]):\n            The filename of the gson file.\n        silence_warnigns (bool):\n            Whether to silence warnings, by default True.\n\n    Raises:\n        ValueError:\n            If suffix is not one of \".json\", \".geojson\", \".feather\", \".parquet\".\n\n    Returns:\n        gpd.GeoDataFrame:\n            The geodataframe.\n\n    Examples:\n        Read a geojson file that is QuPath-readable.\n        &gt;&gt;&gt; from cellseg_gsontools.utils import read_gdf\n        &gt;&gt;&gt; gdf = read_gdf(\"path/to/file.json\")\n    \"\"\"\n    fname = Path(fname)\n    format = fname.suffix\n    allowed_formats = (\".json\", \".geojson\", \".feather\", \".parquet\")\n    if format not in allowed_formats:\n        raise ValueError(\n            f\"Illegal `format`. Got: {format}. Allowed: {allowed_formats}.\"\n        )\n\n    if format == \".json\":\n        df = pd.read_json(fname)\n    elif format == \".geojson\":\n        try:\n            df = gpd.read_file(fname)\n        except Exception:\n            df = pd.read_json(fname)\n            df = _set_gdf(df)\n    elif format == \".feather\":\n        df = gpd.read_feather(fname)\n    elif format == \".parquet\":\n        df = gpd.read_parquet(fname)\n\n    if df.empty:\n        if not silence_warnigns:\n            warnings.warn(f\"Empty geojson file: {fname.name}. Returning empty gdf.\")\n        return df\n\n    property_col = \"properties\" if \"properties\" in df.columns else \"classification\"\n\n    if \"class_name\" not in df.columns:\n        try:\n            df[\"class_name\"] = gdf_apply(df, _get_class, columns=[property_col])\n        except Exception:\n            if not silence_warnigns:\n                warnings.warn(\n                    f\"Could not find 'name' key in {property_col} column.\"\n                    \"Can't set the `class_name` column to the output gdf.\"\n                )\n\n    if \"class_probs\" not in df.columns:\n        try:\n            df[\"class_probs\"] = gdf_apply(df, _get_prob, columns=[property_col])\n        except Exception:\n            if not silence_warnigns:\n                warnings.warn(\n                    f\"Could not find 'probabilities' key in {property_col} column. \"\n                    \"Can't set the `class_probs` column to the output gdf.\"\n                )\n\n    df[\"geometry\"] = gdf_apply(df, shapely.geometry.shape, columns=[\"geometry\"])\n    return gpd.GeoDataFrame(df).set_geometry(\"geometry\")\n</code></pre>"},{"location":"reference/lines/equal_interval_points_ref/","title":"equal_interval_points","text":""},{"location":"reference/lines/equal_interval_points_ref/#cellseg_gsontools.lines.equal_interval_points","title":"<code>cellseg_gsontools.lines.equal_interval_points(obj, n=None, delta=None)</code>","text":"<p>Resample the points of a shapely object at equal intervals.</p> <p>Parameters:</p> Name Type Description Default <code>obj</code> <code>Any</code> <p>Any shapely object that has length property.</p> required <code>n</code> <code>int</code> <p>Number of points, defaults to None</p> <code>None</code> <code>delta</code> <code>float</code> <p>Distance between points, defaults to None</p> <code>None</code> <p>Returns:</p> Name Type Description <code>points</code> <code>ndarray</code> <p>Array of points at equal intervals along the input object.</p> Source code in <code>cellseg_gsontools/lines.py</code> <pre><code>def equal_interval_points(obj: Any, n: int = None, delta: float = None):\n    \"\"\"Resample the points of a shapely object at equal intervals.\n\n    Parameters:\n        obj (Any):\n            Any shapely object that has length property.\n        n (int):\n            Number of points, defaults to None\n        delta (float):\n            Distance between points, defaults to None\n\n    Returns:\n        points (numpy.ndarray):\n            Array of points at equal intervals along the input object.\n    \"\"\"\n    length = obj.length\n\n    if n is None:\n        if delta is None:\n            delta = obj.length / 1000\n        n = round(length / delta)\n\n    distances = np.linspace(0, length, n)\n    points = [obj.interpolate(distance) for distance in distances]\n    points = np.array([(p.x, p.y) for p in points])\n\n    return points\n</code></pre>"},{"location":"reference/lines/line_branches_ref/","title":"line_branches","text":""},{"location":"reference/lines/line_branches_ref/#cellseg_gsontools.lines.line_branches","title":"<code>cellseg_gsontools.lines.line_branches(edges)</code>","text":"<p>Get the branch points of a line graph.</p> Note <p>Helps to get rid of the random branches of the voronoi medial lines.</p> <p>Parameters:</p> Name Type Description Default <code>edges</code> <code>ndarray</code> <p>Array of edges of the line graph.</p> required <p>Returns:</p> Type Description <code>ndarray</code> <p>numpy.ndarray: Array of edges of the line graph with the branches removed.</p> Source code in <code>cellseg_gsontools/lines.py</code> <pre><code>def line_branches(edges: np.ndarray) -&gt; np.ndarray:\n    \"\"\"Get the branch points of a line graph.\n\n    Note:\n        Helps to get rid of the random branches of the voronoi medial lines.\n\n    Parameters:\n        edges (numpy.ndarray):\n            Array of edges of the line graph.\n\n    Returns:\n        numpy.ndarray:\n            Array of edges of the line graph with the branches removed.\n    \"\"\"\n    # create a graph from the edges\n    neighbors = defaultdict(list)\n    for line in edges:\n        start_id, end_id = line\n        neighbors[start_id].append(end_id)\n        neighbors[end_id].append(start_id)\n\n    w = W(dict(sorted(neighbors.items())))\n\n    # get the branch points\n    branch_points = [k for k, c in w.cardinalities.items() if c &gt; 2]\n\n    # get the paths from the branch points\n    paths = []\n    stack = [(bp, None, [bp]) for bp in branch_points]\n    while stack:\n        cur, prev, path = stack.pop()\n\n        if len(w.neighbors[cur]) == 1 or (prev and cur in branch_points):\n            paths.append(path)\n            continue\n\n        for neighbor in w.neighbors[cur]:\n            if neighbor != prev:\n                stack.append((neighbor, cur, path + [neighbor]))\n\n    return paths\n</code></pre>"},{"location":"reference/lines/medial_lines_ref/","title":"medial_lines","text":""},{"location":"reference/lines/medial_lines_ref/#cellseg_gsontools.lines.medial_lines","title":"<code>cellseg_gsontools.lines.medial_lines(polygon, n=None, delta=None, rm_branches=False)</code>","text":"<p>Get the medial lines of a polygon using a voronoi diagram.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Polygon to compute the medial lines of.</p> required <code>n</code> <code>int</code> <p>Number of resampled points in the input polygon, defaults to None</p> <code>None</code> <code>delta</code> <code>float</code> <p>Distance between resampled polygon points, defaults to None. Ignored if n is not None.</p> <code>None</code> <code>rm_branches</code> <code>bool</code> <p>Whether to remove the branches of the medial lines, defaults to False.</p> <code>False</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: GeoDataFrame of the medial lines.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; import geopandas as gpd\n&gt;&gt;&gt; import shapely\n&gt;&gt;&gt; from cellseg_gsontools.lines import medial_lines\n&gt;&gt;&gt; from cellseg_gsontools.data import cervix_tissue\n&gt;&gt;&gt; tissues = cervix_tissue()\n&gt;&gt;&gt; tumor = tissues[tissues[\"class_name\"] == \"area_cin\"]\n&gt;&gt;&gt; tumor_poly = tumor.geometry.iloc[0]  # get the first tumor polygon\n&gt;&gt;&gt; polygon = shapely.Polygon(tumor_poly.exterior)\n&gt;&gt;&gt; med_lines = medial_lines(polygon, delta=500, rm_branches=False)\n&gt;&gt;&gt; med_lines.head()\ngeometry\n    0  LINESTRING (10789.887 49746.299, 10910.622 493...\n    1  LINESTRING (10789.887 49746.299, 10926.865 498...\n    2  LINESTRING (10924.971 48929.809, 10829.145 492...\n    3  LINESTRING (10910.622 49332.471, 10829.145 492...\n    4  LINESTRING (10926.865 49843.003, 10794.602 502...\n</code></pre> Source code in <code>cellseg_gsontools/lines.py</code> <pre><code>def medial_lines(\n    polygon: shapely.Polygon,\n    n: int = None,\n    delta: float = None,\n    rm_branches: bool = False,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Get the medial lines of a polygon using a voronoi diagram.\n\n    Parameters:\n        polygon (shapely.Polygon):\n            Polygon to compute the medial lines of.\n        n (int):\n            Number of resampled points in the input polygon, defaults to None\n        delta (float):\n            Distance between resampled polygon points, defaults to None. Ignored\n            if n is not None.\n        rm_branches (bool):\n            Whether to remove the branches of the medial lines, defaults to False.\n\n    Returns:\n        gpd.GeoDataFrame:\n            GeoDataFrame of the medial lines.\n\n    Examples:\n        &gt;&gt;&gt; import geopandas as gpd\n        &gt;&gt;&gt; import shapely\n        &gt;&gt;&gt; from cellseg_gsontools.lines import medial_lines\n        &gt;&gt;&gt; from cellseg_gsontools.data import cervix_tissue\n        &gt;&gt;&gt; tissues = cervix_tissue()\n        &gt;&gt;&gt; tumor = tissues[tissues[\"class_name\"] == \"area_cin\"]\n        &gt;&gt;&gt; tumor_poly = tumor.geometry.iloc[0]  # get the first tumor polygon\n        &gt;&gt;&gt; polygon = shapely.Polygon(tumor_poly.exterior)\n        &gt;&gt;&gt; med_lines = medial_lines(polygon, delta=500, rm_branches=False)\n        &gt;&gt;&gt; med_lines.head()\n        geometry\n            0  LINESTRING (10789.887 49746.299, 10910.622 493...\n            1  LINESTRING (10789.887 49746.299, 10926.865 498...\n            2  LINESTRING (10924.971 48929.809, 10829.145 492...\n            3  LINESTRING (10910.622 49332.471, 10829.145 492...\n            4  LINESTRING (10926.865 49843.003, 10794.602 502...\n    \"\"\"\n    # get the medial lines\n    vertices, edges = voronoi_medial(polygon, n=n, delta=delta)\n\n    # remove lone branches of the medial lines\n    if rm_branches:\n        # get the line paths and branches of the medial lines\n        paths = line_branches(edges)\n        edges = np.vstack(\n            [\n                np.array(list(zip(branch, branch[1:])))\n                for branch in paths\n                if len(branch) &gt; 2\n            ]\n        )\n\n    med_lines = gpd.GeoDataFrame(\n        [shapely.LineString(vertices[line]) for line in edges], columns=[\"geometry\"]\n    )\n    # clip the medial lines to the polygon\n    med_lines = med_lines.loc[med_lines.within(polygon)]\n\n    return med_lines\n</code></pre>"},{"location":"reference/lines/perpendicular_line_ref/","title":"perependicular_line","text":""},{"location":"reference/lines/perpendicular_line_ref/#cellseg_gsontools.lines.perpendicular_line","title":"<code>cellseg_gsontools.lines.perpendicular_line(line, seg_length)</code>","text":"<p>Create a perpendicular line from a line segment.</p> Note <p>Returns an empty line if perpendicular line is not possible from the input.</p> <p>Parameters:</p> Name Type Description Default <code>line</code> <code>LineString</code> <p>Line segment to create a perpendicular line from.</p> required <code>seg_length</code> <code>float</code> <p>Length of the perpendicular line.</p> required <p>Returns:</p> Type Description <code>LineString</code> <p>shapely.LineString: Perpendicular line to the input line of length <code>seg_length</code>.</p> Source code in <code>cellseg_gsontools/lines.py</code> <pre><code>def perpendicular_line(\n    line: shapely.LineString, seg_length: float\n) -&gt; shapely.LineString:\n    \"\"\"Create a perpendicular line from a line segment.\n\n    Note:\n        Returns an empty line if perpendicular line is not possible from the input.\n\n    Parameters:\n        line (shapely.LineString):\n            Line segment to create a perpendicular line from.\n        seg_length (float):\n            Length of the perpendicular line.\n\n    Returns:\n        shapely.LineString:\n            Perpendicular line to the input line of length `seg_length`.\n    \"\"\"\n    left = line.parallel_offset(seg_length / 2, \"left\").centroid\n    right = line.parallel_offset(seg_length / 2, \"right\").centroid\n\n    if left.is_empty or right.is_empty:\n        return shapely.LineString()\n\n    return shapely.LineString([left, right])\n</code></pre>"},{"location":"reference/lines/perpendicular_lines_ref/","title":"perpendicular_lines","text":""},{"location":"reference/lines/perpendicular_lines_ref/#cellseg_gsontools.lines.perpendicular_lines","title":"<code>cellseg_gsontools.lines.perpendicular_lines(lines, polygon=None)</code>","text":"<p>Get perpendicular lines to the input lines starting from the line midpoints.</p> <p>Parameters:</p> Name Type Description Default <code>lines</code> <code>GeoDataFrame</code> <p>GeoDataFrame of the input lines.</p> required <code>polygon</code> <code>Polygon</code> <p>Polygon to clip the perpendicular lines to.</p> <code>None</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: GeoDataFrame of the perpendicular lines.</p> Source code in <code>cellseg_gsontools/lines.py</code> <pre><code>def perpendicular_lines(\n    lines: gpd.GeoDataFrame, polygon: shapely.Polygon = None\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Get perpendicular lines to the input lines starting from the line midpoints.\n\n    Parameters:\n        lines (gpd.GeoDataFrame):\n            GeoDataFrame of the input lines.\n        polygon (shapely.Polygon):\n            Polygon to clip the perpendicular lines to.\n\n    Returns:\n        gpd.GeoDataFrame:\n            GeoDataFrame of the perpendicular lines.\n    \"\"\"\n    # create perpendicular lines to the medial lines\n    if polygon is None:\n        polygon = lines.unary_union.convex_hull\n\n    seg_len = major_axis_len(polygon)\n    func = partial(perpendicular_line, seg_length=seg_len)\n    perp_lines = gdf_apply(lines, func, columns=[\"geometry\"])\n\n    # clip the perpendicular lines to the polygon\n    perp_lines = gpd.GeoDataFrame(perp_lines, columns=[\"geometry\"]).clip(polygon)\n\n    # explode perpendicular lines &amp; take only the ones that intersect w/ medial lines\n    perp_lines = perp_lines.explode(index_parts=False).reset_index(drop=True)\n\n    # drop the perpendicular lines that are too short or too long\n    # since these are likely artefacts\n    perp_lines[\"len\"] = perp_lines.geometry.length\n    low, high = perp_lines.len.quantile([0.05, 0.85])\n    perp_lines = perp_lines.query(f\"{low}&lt;len&lt;{high}\")\n\n    return perp_lines\n</code></pre>"},{"location":"reference/lines/voronoi_medial_ref/","title":"voronoi_medial","text":""},{"location":"reference/lines/voronoi_medial_ref/#cellseg_gsontools.lines.voronoi_medial","title":"<code>cellseg_gsontools.lines.voronoi_medial(polygon, n=None, delta=None)</code>","text":"<p>Compute the medial lines of a polygon using voronoi diagram.</p> <p>Parameters:</p> Name Type Description Default <code>polygon</code> <code>Polygon</code> <p>Polygon to compute the medial lines of.</p> required <code>n</code> <code>int</code> <p>Number of resampled points in the input polygon, defaults to None</p> <code>None</code> <code>delta</code> <code>float</code> <p>Distance between resampled polygon points, defaults to None. Ignored if n is not None.</p> <code>None</code> <p>Returns:</p> Name Type Description <code>vertices</code> <code>ndarray</code> <p>Array of vertices of the voronoi diagram.</p> <code>edges</code> <code>ndarray</code> <p>Array of edges of the voronoi diagram.</p> Source code in <code>cellseg_gsontools/lines.py</code> <pre><code>def voronoi_medial(\n    polygon: shapely.Polygon, n: int = None, delta: float = None\n) -&gt; Tuple[np.ndarray, np.ndarray]:\n    \"\"\"Compute the medial lines of a polygon using voronoi diagram.\n\n    Parameters:\n        polygon (shapely.geometry.Polygon):\n            Polygon to compute the medial lines of.\n        n (int):\n            Number of resampled points in the input polygon, defaults to None\n        delta (float):\n            Distance between resampled polygon points, defaults to None. Ignored\n            if n is not None.\n\n    Returns:\n        vertices (numpy.ndarray):\n            Array of vertices of the voronoi diagram.\n        edges (numpy.ndarray):\n            Array of edges of the voronoi diagram.\n    \"\"\"\n    points = equal_interval_points(polygon.exterior, n=n, delta=delta)\n\n    # # create the voronoi diagram on 2D points\n    voronoi = Voronoi(points)\n\n    # which voronoi vertices are contained inside the polygon\n    contains = vectorized.contains(polygon, *voronoi.vertices.T)\n\n    # ridge vertices of -1 are outside, make sure they are False\n    contains = np.append(contains, False)\n\n    # make sure ridge vertices is numpy array\n    ridge = np.asanyarray(voronoi.ridge_vertices, dtype=np.int64)\n\n    # only take ridges where every vertex is contained\n    edges = ridge[contains[ridge].all(axis=1)]\n\n    # now we need to remove uncontained vertices\n    contained = np.unique(edges)\n    mask = np.zeros(len(voronoi.vertices), dtype=np.int64)\n    mask[contained] = np.arange(len(contained))\n\n    # mask voronoi vertices\n    vertices = voronoi.vertices[contained]\n\n    # re-index edges\n    return vertices, mask[edges]\n</code></pre>"},{"location":"reference/links/get_link_combinations_ref/","title":"get_link_combinations","text":""},{"location":"reference/links/get_link_combinations_ref/#cellseg_gsontools.links.get_link_combinations","title":"<code>cellseg_gsontools.links.get_link_combinations(classes)</code>","text":"<p>Return a list of link combinations between the classes in <code>classes</code>.</p> <p>Parameters:</p> Name Type Description Default <code>classes</code> <code>Tuple[str, ...]</code> <p>A list/tuple containing the classes of your dataset.</p> required Source code in <code>cellseg_gsontools/links.py</code> <pre><code>def get_link_combinations(classes: Tuple[str, ...]) -&gt; List[str]:\n    \"\"\"Return a list of link combinations between the classes in `classes`.\n\n    Parameters:\n        classes (Tuple[str, ...]):\n            A list/tuple containing the classes of your dataset.\n    \"\"\"\n    combos = [\"-\".join(t) for t in list(combinations_with_replacement(classes, 2))]\n\n    return combos\n</code></pre>"},{"location":"reference/links/link_counts_ref/","title":"link_counts","text":""},{"location":"reference/links/link_counts_ref/#cellseg_gsontools.links.link_counts","title":"<code>cellseg_gsontools.links.link_counts(gdf, w, classes)</code>","text":"<p>Get the link-type counts of a geodataframe given a spatial weights object <code>w</code>.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>Input geodataframe. Has to have a <code>class_name</code> column.</p> required <code>w</code> <code>W</code> <p>Libpysal spatial weights object of the gdf.</p> required <code>classes</code> <code>Tuple[str, ...]</code> <p>A list/tuple containing the classes of your dataset.</p> required <p>Returns:</p> Type Description <code>Dict[str, int]</code> <p>Dict[str, int]: A contigency dictionary.</p> <p>Examples:</p> <p>Get the link types of the tumor-stroma interfaces.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.spatial_context import InterfaceContext\n&gt;&gt;&gt; from cellseg_gsontools.links import link_counts\n&gt;&gt;&gt; iface_context = InterfaceContext(\n...     area_gdf=areas,\n...     cell_gdf=cells,\n...     top_labels=\"area_cin\",\n...     bottom_labels=\"areastroma\",\n...     silence_warnings=True,\n...     min_area_size=100000.0,\n... )\n&gt;&gt;&gt; classes = [\n...     \"inflammatory\",\n...     \"connective\",\n...     \"glandular_epithel\",\n...     \"squamous_epithel\",\n...     \"neoplastic\",\n... ]\n&gt;&gt;&gt; iface_context.fit(verbose=False)\n&gt;&gt;&gt; w = iface_context.context2weights(\"border_network\")\n&gt;&gt;&gt; link_counts(cells, w, classes)\n{'inflammatory-inflammatory': 31,\n'inflammatory-connective': 89,\n'inflammatory-glandular_epithel': 0,\n'inflammatory-squamous_epithel': 0,\n'inflammatory-neoplastic': 86,\n'connective-connective': 131,\n'connective-glandular_epithel': 0,\n'connective-squamous_epithel': 0,\n'connective-neoplastic': 284,\n'glandular_epithel-glandular_epithel': 0,\n'glandular_epithel-squamous_epithel': 0,\n'glandular_epithel-neoplastic': 0,\n'squamous_epithel-squamous_epithel': 0,\n'squamous_epithel-neoplastic': 0,\n'neoplastic-neoplastic': 236}\n</code></pre> Source code in <code>cellseg_gsontools/links.py</code> <pre><code>def link_counts(\n    gdf: gpd.GeoDataFrame, w: W, classes: Tuple[str, ...]\n) -&gt; Dict[str, int]:\n    \"\"\"Get the link-type counts of a geodataframe given a spatial weights object `w`.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            Input geodataframe. Has to have a `class_name` column.\n        w (libysal.weights.W):\n            Libpysal spatial weights object of the gdf.\n        classes (Tuple[str, ...]):\n            A list/tuple containing the classes of your dataset.\n\n    Returns:\n        Dict[str, int]:\n            A contigency dictionary.\n\n    Examples:\n        Get the link types of the tumor-stroma interfaces.\n        &gt;&gt;&gt; from cellseg_gsontools.spatial_context import InterfaceContext\n        &gt;&gt;&gt; from cellseg_gsontools.links import link_counts\n        &gt;&gt;&gt; iface_context = InterfaceContext(\n        ...     area_gdf=areas,\n        ...     cell_gdf=cells,\n        ...     top_labels=\"area_cin\",\n        ...     bottom_labels=\"areastroma\",\n        ...     silence_warnings=True,\n        ...     min_area_size=100000.0,\n        ... )\n        &gt;&gt;&gt; classes = [\n        ...     \"inflammatory\",\n        ...     \"connective\",\n        ...     \"glandular_epithel\",\n        ...     \"squamous_epithel\",\n        ...     \"neoplastic\",\n        ... ]\n        &gt;&gt;&gt; iface_context.fit(verbose=False)\n        &gt;&gt;&gt; w = iface_context.context2weights(\"border_network\")\n        &gt;&gt;&gt; link_counts(cells, w, classes)\n        {'inflammatory-inflammatory': 31,\n        'inflammatory-connective': 89,\n        'inflammatory-glandular_epithel': 0,\n        'inflammatory-squamous_epithel': 0,\n        'inflammatory-neoplastic': 86,\n        'connective-connective': 131,\n        'connective-glandular_epithel': 0,\n        'connective-squamous_epithel': 0,\n        'connective-neoplastic': 284,\n        'glandular_epithel-glandular_epithel': 0,\n        'glandular_epithel-squamous_epithel': 0,\n        'glandular_epithel-neoplastic': 0,\n        'squamous_epithel-squamous_epithel': 0,\n        'squamous_epithel-neoplastic': 0,\n        'neoplastic-neoplastic': 236}\n    \"\"\"\n    combos = get_link_combinations(classes)\n    link_cnt = {combo: 0 for combo in combos}\n\n    all_node_pairs = []\n    for node, neighbors in w.neighbors.items():\n        ncls = gdf.loc[node, \"class_name\"]\n        if neighbors:\n            neighbors_cls = gdf.loc[neighbors, \"class_name\"]\n            node_pairs = [set((node, n)) for n in neighbors]\n\n            for ngh_ix, ngh_cls in zip(neighbors, neighbors_cls):\n                node_ids = set((node, ngh_ix))\n                if node_ids not in all_node_pairs:\n                    for combo in combos:\n                        types = set(combo.split(\"-\"))\n                        if ncls in types and ngh_cls in types and ngh_cls != ncls:\n                            link_cnt[combo] += 1\n                        elif ncls in types and ngh_cls in types and ngh_cls == ncls:\n                            if len(types) == 1:\n                                link_cnt[combo] += 1\n\n            all_node_pairs.extend(node_pairs)\n\n    return link_cnt\n</code></pre>"},{"location":"reference/links/weights2gdf_ref/","title":"weights2gdf","text":""},{"location":"reference/links/weights2gdf_ref/#cellseg_gsontools.links.weights2gdf","title":"<code>cellseg_gsontools.links.weights2gdf(gdf, w, parallel=False)</code>","text":"<p>Convert a <code>libpysal</code> weights object to a <code>geopandas.GeoDataFrame</code>.</p> <p>Add class names and node centroids to the dataframe.</p> Note <p>if <code>w.neighbors</code> is empty, this will return None.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>GeoDataFrame of the nodes.</p> required <code>w</code> <code>W</code> <p>PySAL weights object.</p> required <code>parallel</code> <code>bool, default=False</code> <p>Whether to use parallel processing.</p> <code>False</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: GeoDataFrame of the links.</p> <p>Examples:</p> <p>Convert <code>libpysal</code> weights from <code>InterfaceContext</code> to <code>geopandas.GeoDataFrame</code>.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.spatial_context import InterfaceContext\n&gt;&gt;&gt; from cellseg_gsontools.links import weights2gdf\n&gt;&gt;&gt; iface_context = InterfaceContext(\n...     area_gdf=areas,\n...     cell_gdf=cells,\n...     top_labels=\"area_cin\",\n...     bottom_labels=\"areastroma\",\n...     silence_warnings=True,\n...     min_area_size=100000.0,\n... )\n&gt;&gt;&gt; iface_context.fit(verbose=False)\n&gt;&gt;&gt; w = iface_context.context2weights(\"border_network\")\n&gt;&gt;&gt; link_gdf = weights2gdf(cells, w)\n</code></pre> Source code in <code>cellseg_gsontools/links.py</code> <pre><code>def weights2gdf(\n    gdf: gpd.GeoDataFrame, w: W, parallel: bool = False\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Convert a `libpysal` weights object to a `geopandas.GeoDataFrame`.\n\n    Add class names and node centroids to the dataframe.\n\n    Note:\n        if `w.neighbors` is empty, this will return None.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            GeoDataFrame of the nodes.\n        w (W):\n            PySAL weights object.\n        parallel (bool, default=False):\n            Whether to use parallel processing.\n\n    Returns:\n        gpd.GeoDataFrame:\n            GeoDataFrame of the links.\n\n    Examples:\n        Convert `libpysal` weights from `InterfaceContext` to `geopandas.GeoDataFrame`.\n        &gt;&gt;&gt; from cellseg_gsontools.spatial_context import InterfaceContext\n        &gt;&gt;&gt; from cellseg_gsontools.links import weights2gdf\n        &gt;&gt;&gt; iface_context = InterfaceContext(\n        ...     area_gdf=areas,\n        ...     cell_gdf=cells,\n        ...     top_labels=\"area_cin\",\n        ...     bottom_labels=\"areastroma\",\n        ...     silence_warnings=True,\n        ...     min_area_size=100000.0,\n        ... )\n        &gt;&gt;&gt; iface_context.fit(verbose=False)\n        &gt;&gt;&gt; w = iface_context.context2weights(\"border_network\")\n        &gt;&gt;&gt; link_gdf = weights2gdf(cells, w)\n    \"\"\"\n    if not w.neighbors:\n        return\n\n    # get all possible link class combinations\n    classes = sorted(gdf.class_name.unique().tolist())\n    link_combos = get_link_combinations(classes)\n\n    # init link gdf\n    link_gdf = w.to_adjlist(remove_symmetric=True, drop_islands=True).reset_index()\n\n    # add centroids and class names\n    link_gdf.loc[:, \"focal_centroid\"] = gdf.loc[link_gdf.focal].centroid.to_list()\n    link_gdf.loc[:, \"neighbor_centroid\"] = gdf.loc[link_gdf.neighbor].centroid.to_list()\n    link_gdf.loc[:, \"focal_class_name\"] = gdf.loc[link_gdf.focal].class_name.to_list()\n    link_gdf.loc[:, \"neighbor_class_name\"] = gdf.loc[\n        link_gdf.neighbor\n    ].class_name.to_list()\n\n    func = partial(_get_link_class, link_combos=link_combos)\n    link_gdf[\"class_name\"] = gdf_apply(\n        link_gdf,\n        func=func,\n        columns=[\"focal_class_name\", \"neighbor_class_name\"],\n        axis=1,\n        parallel=parallel,\n    )\n\n    link_gdf[\"geometry\"] = gdf_apply(\n        link_gdf,\n        func=_create_link,\n        columns=[\"focal_centroid\", \"neighbor_centroid\"],\n        axis=1,\n        parallel=parallel,\n    )\n    link_gdf = link_gdf.set_geometry(\"geometry\")\n\n    return link_gdf\n</code></pre>"},{"location":"reference/merging/area_merger_ref/","title":"AreaMerger","text":""},{"location":"reference/merging/area_merger_ref/#cellseg_gsontools.merging.AreaMerger","title":"<code>cellseg_gsontools.merging.AreaMerger</code>","text":"<p>             Bases: <code>BaseGSONMerger</code></p> <p>Merge the area/tissue annotation files of the tiles to one file.</p> Note <p>Assumes:</p> <ul> <li>Input files contain area/tissue semantic segmentation annotations.</li> <li>Files have start x and y coords embedded in filename e.g. <code>x-[coord]_y-[coord]</code></li> <li>Tiles are the same size.</li> <li>Allowed input file-formats <code>.json</code>, <code>.geojson</code>, <code>.feather</code>, <code>.parquet</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>Union[Path, str]</code> <p>Path to the directory containing the annotation files of tiles.</p> required <p>Attributes:</p> Name Type Description <code>annots</code> <code>GeoDataFrame</code> <p>A gdf of the resulting annotations. Available after merging.</p> Source code in <code>cellseg_gsontools/merging/area_merger.py</code> <pre><code>class AreaMerger(BaseGSONMerger):\n    \"\"\"Merge the area/tissue annotation files of the tiles to one file.\n\n    Note:\n        Assumes:\n\n        - Input files contain area/tissue semantic segmentation annotations.\n        - Files have start x and y coords embedded in filename e.g. `x-[coord]_y-[coord]`\n        - Tiles are the same size.\n        - Allowed input file-formats `.json`, `.geojson`, `.feather`, `.parquet`\n\n    Parameters:\n        in_dir (Union[Path, str]):\n            Path to the directory containing the annotation files of tiles.\n\n    Attributes:\n        annots (gpd.GeoDataFrame):\n            A gdf of the resulting annotations. Available after merging.\n    \"\"\"\n\n    def __init__(self, in_dir: Union[Path, str]) -&gt; None:\n        super().__init__(in_dir, None)\n\n    def merge_dir(\n        self,\n        out_fn: Optional[Union[Path, str]] = None,\n        format: Optional[str] = None,\n        verbose: bool = True,\n        parallel: bool = False,\n    ) -&gt; None:\n        \"\"\"Merge all the semantic segmentation files in the input directory into one.\n\n        Note:\n            Unlike the CellMerger.merge_dir() -method, this can be parallelized with\n            `parallel=True` -argument.\n\n        Parameters:\n            out_fn (Union[Path, str]):\n                Filename for the output file. If None, the merged gdf is saved to the\n                class attribute `self.annots` only.\n            format (str):\n                The format of the output geojson file. One of: \"feather\", \"parquet\",\n                \"geojson\", None. This is ignored if `out_fn` is None.\n            verbose (bool):\n                Whether to show a progress bar or not.\n            parallel (bool):\n                Whether to use parallel processing or not.\n\n        Examples:\n            Write feather files to a '.geojson' file.\n            &gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n            &gt;&gt;&gt; merger = AreaMerger(\"/path/to/feather_files/\")\n            &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.json\", format=\"geojson\")\n\n            Write input geojson files to feather file.\n            &gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n            &gt;&gt;&gt; merger = AreaMerger(\"/path/to/geojsons/\")\n            &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.feather\", format=\"feather\")\n\n            Write input parquet files to parquet file.\n            &gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n            &gt;&gt;&gt; merger = AreaMerger(\"/path/to/parquet_files/\")\n            &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.parquet\", format=\"parquet\")\n        \"\"\"\n        if out_fn is not None:\n            out_fn = Path(out_fn)\n\n        if format not in (\".feather\", \".parquet\", \".geojson\", None):\n            raise ValueError(\n                f\"Invalid format. Got: {format}. Allowed: .feather, .parquet, .geojson\"\n            )\n\n        # merge the tiles\n        self.annots = self._merge(verbose=verbose, parallel=parallel)\n\n        if verbose:\n            msg = f\"{format}-format\" if out_fn is not None else \"`self.annots`\"\n            print(f\"Saving the merged geojson file: {out_fn} to {msg}\")\n\n        if out_fn is not None:\n            # save the merged geojson\n            gdf_to_file(self.annots, out_fn, format)\n\n    def _read_files_to_gdf(\n        self, files: List[Path], verbose: bool = True\n    ) -&gt; gpd.GeoDataFrame:\n        \"\"\"Read in the input files to a gdf.\"\"\"\n        cols = None\n        rows = []\n        pbar = tqdm(files, total=len(files)) if verbose else files\n        for file in pbar:\n            gdf = read_gdf(file)\n            if gdf is not None and not gdf.empty:\n                cols = gdf.columns\n                for _, row in gdf.iterrows():\n                    rows.append(row)\n\n        return gpd.GeoDataFrame(rows, columns=cols)\n\n    def _merge_adjascent_polygons(\n        self, gdf: gpd.GeoDataFrame, w: W, verbose: bool = True, cl: str = None\n    ) -&gt; gpd.GeoDataFrame:\n        \"\"\"Divide spatial weights into subgraphs &amp; merge the polygons in each.\"\"\"\n        # Get all disconnected subgraphs.\n        G = w.to_networkx()\n        sub_graphs = [\n            W(nx.to_dict_of_lists(G.subgraph(c).copy()))\n            for c in nx.connected_components(G)\n        ]\n\n        # loop over the subgraphs\n        pbar = tqdm(sub_graphs, total=len(sub_graphs)) if verbose else sub_graphs\n        result_polygons = []\n        for sub_w in pbar:\n            if verbose:\n                pbar.set_description(f\"Processing {cl} connected regions:\")\n\n            # init a visited lookup table for nodes\n            visited = {node: False for node in sub_w.neighbors.keys()}\n\n            # loop over the nodes/polygons in the subgraph\n            polygons_to_merge = []\n            for node, neighs in sub_w.neighbors.items():\n                # if an island, buffer the polygon\n                if not neighs:\n                    poly = gdf.loc[node].geometry.buffer(2)\n                    result_polygons.append(\n                        validate_and_simplify(poly, simplify=True, buffer=0.0)\n                    )\n                    continue\n\n                # if not visited, check if it intersects with any of its neighbors\n                # and add it to the list of polygons to merge\n                if not visited[node]:\n                    poly = gdf.loc[node].geometry.buffer(2)\n                    # poly = validate_and_simplify(poly, simplify=True, buffer=0.0)\n                    inter = [poly]\n                    for neigh in neighs:\n                        if not visited[neigh]:\n                            neigh_poly = gdf.loc[neigh].geometry.buffer(2)\n                            neigh_poly = validate_and_simplify(\n                                poly, simplify=True, buffer=0.0\n                            )\n                            if poly.intersects(neigh_poly):\n                                inter.append(neigh_poly)\n                                visited[neigh_poly] = True\n\n                    visited[node] = True\n                    polygons_to_merge.extend(inter)\n\n            # don't merge if there are no polygons to merge\n            if polygons_to_merge:\n                result_polygons.append(unary_union(polygons_to_merge))\n\n        # return the merged polygons as gdf\n        out = gpd.GeoDataFrame({\"geometry\": result_polygons, \"class_name\": cl})\n        return out[~out.is_empty].explode(index_parts=False).reset_index(drop=True)\n\n    def _merge_one(\n        self, in_gdf: gpd.GeoDataFrame, cl: str, verbose: bool = True\n    ) -&gt; gpd.GeoDataFrame:\n        \"\"\"Merge the polygons in one class.\"\"\"\n        in_gdf = set_uid(in_gdf)\n\n        w = fuzzy_contiguity(\n            in_gdf,\n            buffering=True,\n            buffer=2,\n            predicate=\"intersects\",\n            silence_warnings=True,\n        )\n\n        return self._merge_adjascent_polygons(in_gdf, w, verbose=verbose, cl=cl)\n\n    def _merge_one_wrap(self, args: Tuple[Any], verbose: bool = True):\n        return self._merge_one(*args, verbose=verbose)\n\n    def _merge(self, verbose: bool = True, parallel: bool = True) -&gt; gpd.GeoDataFrame:\n        \"\"\"Merge the polygons in by class.\"\"\"\n        gdf = self._read_files_to_gdf(self.files)\n        classes = gdf[\"class_name\"].unique()\n\n        if not parallel:\n            polys = []\n            for cl in classes:\n                in_gdf = gdf[gdf[\"class_name\"] == cl]\n                polys.append(self._merge_one(in_gdf, cl, verbose=verbose))\n        else:\n            merge_func = partial(self._merge_one_wrap, verbose=False)\n\n            polys = run_pool(\n                merge_func,\n                [(gdf[gdf[\"class_name\"] == cl], cl) for cl in classes],\n                n_jobs=len(classes),\n                pbar=verbose,\n                pooltype=\"thread\",\n                maptype=\"uimap\",\n            )\n\n        return set_uid(pd.concat(polys, ignore_index=True))\n</code></pre>"},{"location":"reference/merging/area_merger_ref/#cellseg_gsontools.merging.AreaMerger.merge_dir","title":"<code>merge_dir(out_fn=None, format=None, verbose=True, parallel=False)</code>","text":"<p>Merge all the semantic segmentation files in the input directory into one.</p> Note <p>Unlike the CellMerger.merge_dir() -method, this can be parallelized with <code>parallel=True</code> -argument.</p> <p>Parameters:</p> Name Type Description Default <code>out_fn</code> <code>Union[Path, str]</code> <p>Filename for the output file. If None, the merged gdf is saved to the class attribute <code>self.annots</code> only.</p> <code>None</code> <code>format</code> <code>str</code> <p>The format of the output geojson file. One of: \"feather\", \"parquet\", \"geojson\", None. This is ignored if <code>out_fn</code> is None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to show a progress bar or not.</p> <code>True</code> <code>parallel</code> <code>bool</code> <p>Whether to use parallel processing or not.</p> <code>False</code> <p>Examples:</p> <p>Write feather files to a '.geojson' file.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n&gt;&gt;&gt; merger = AreaMerger(\"/path/to/feather_files/\")\n&gt;&gt;&gt; merger.merge_dir(\"/path/to/output.json\", format=\"geojson\")\n</code></pre> <p>Write input geojson files to feather file.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n&gt;&gt;&gt; merger = AreaMerger(\"/path/to/geojsons/\")\n&gt;&gt;&gt; merger.merge_dir(\"/path/to/output.feather\", format=\"feather\")\n</code></pre> <p>Write input parquet files to parquet file.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n&gt;&gt;&gt; merger = AreaMerger(\"/path/to/parquet_files/\")\n&gt;&gt;&gt; merger.merge_dir(\"/path/to/output.parquet\", format=\"parquet\")\n</code></pre> Source code in <code>cellseg_gsontools/merging/area_merger.py</code> <pre><code>def merge_dir(\n    self,\n    out_fn: Optional[Union[Path, str]] = None,\n    format: Optional[str] = None,\n    verbose: bool = True,\n    parallel: bool = False,\n) -&gt; None:\n    \"\"\"Merge all the semantic segmentation files in the input directory into one.\n\n    Note:\n        Unlike the CellMerger.merge_dir() -method, this can be parallelized with\n        `parallel=True` -argument.\n\n    Parameters:\n        out_fn (Union[Path, str]):\n            Filename for the output file. If None, the merged gdf is saved to the\n            class attribute `self.annots` only.\n        format (str):\n            The format of the output geojson file. One of: \"feather\", \"parquet\",\n            \"geojson\", None. This is ignored if `out_fn` is None.\n        verbose (bool):\n            Whether to show a progress bar or not.\n        parallel (bool):\n            Whether to use parallel processing or not.\n\n    Examples:\n        Write feather files to a '.geojson' file.\n        &gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n        &gt;&gt;&gt; merger = AreaMerger(\"/path/to/feather_files/\")\n        &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.json\", format=\"geojson\")\n\n        Write input geojson files to feather file.\n        &gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n        &gt;&gt;&gt; merger = AreaMerger(\"/path/to/geojsons/\")\n        &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.feather\", format=\"feather\")\n\n        Write input parquet files to parquet file.\n        &gt;&gt;&gt; from cellseg_gsontools.merging import AreaMerger\n        &gt;&gt;&gt; merger = AreaMerger(\"/path/to/parquet_files/\")\n        &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.parquet\", format=\"parquet\")\n    \"\"\"\n    if out_fn is not None:\n        out_fn = Path(out_fn)\n\n    if format not in (\".feather\", \".parquet\", \".geojson\", None):\n        raise ValueError(\n            f\"Invalid format. Got: {format}. Allowed: .feather, .parquet, .geojson\"\n        )\n\n    # merge the tiles\n    self.annots = self._merge(verbose=verbose, parallel=parallel)\n\n    if verbose:\n        msg = f\"{format}-format\" if out_fn is not None else \"`self.annots`\"\n        print(f\"Saving the merged geojson file: {out_fn} to {msg}\")\n\n    if out_fn is not None:\n        # save the merged geojson\n        gdf_to_file(self.annots, out_fn, format)\n</code></pre>"},{"location":"reference/merging/cell_merger_ref/","title":"CellMerger","text":""},{"location":"reference/merging/cell_merger_ref/#cellseg_gsontools.merging.CellMerger","title":"<code>cellseg_gsontools.merging.CellMerger</code>","text":"<p>             Bases: <code>BaseGSONMerger</code></p> <p>Merge adjascent cell annotation files to one file.</p> Note <p>Assumes:</p> <ul> <li>Input files contain nuclei/cell instance segmentation annotations.</li> <li>Files have start x and y coords embedded in filename e.g. <code>x-[coord]_y-[coord]</code></li> <li>Input Tiles are the same size.</li> <li>Allowed input file-formats <code>.json</code>, <code>.geojson</code>, <code>.feather</code>, <code>.parquet</code></li> </ul> <p>Parameters:</p> Name Type Description Default <code>in_dir</code> <code>Union[Path, str]</code> <p>Path to the directory containing the annotation files of tiles.</p> required <code>tile_size</code> <code>Tuple[int, int]</code> <p>Height and width of the tiles in pixels.</p> <code>(1000, 1000)</code> <p>Attributes:</p> Name Type Description <code>border_annots</code> <code>GeoDataFrame</code> <p>A gdf of the merged border annotations. Available after merging.</p> <code>non_border_annots</code> <code>GeoDataFrame</code> <p>A gdf of the merged non-border annotations. Available after merging.</p> <code>annots</code> <code>GeoDataFrame</code> <p>A gdf of the resulting annotations. Available after merging.</p> Source code in <code>cellseg_gsontools/merging/cell_merger.py</code> <pre><code>class CellMerger(BaseGSONMerger):\n    \"\"\"Merge adjascent cell annotation files to one file.\n\n    Note:\n        Assumes:\n\n        - Input files contain nuclei/cell instance segmentation annotations.\n        - Files have start x and y coords embedded in filename e.g. `x-[coord]_y-[coord]`\n        - Input Tiles are the same size.\n        - Allowed input file-formats `.json`, `.geojson`, `.feather`, `.parquet`\n\n    Parameters:\n        in_dir (Union[Path, str]):\n            Path to the directory containing the annotation files of tiles.\n        tile_size (Tuple[int, int]):\n            Height and width of the tiles in pixels.\n\n    Attributes:\n        border_annots (gpd.GeoDataFrame):\n            A gdf of the merged border annotations. Available after merging.\n        non_border_annots (gpd.GeoDataFrame):\n            A gdf of the merged non-border annotations. Available after merging.\n        annots (gpd.GeoDataFrame):\n            A gdf of the resulting annotations. Available after merging.\n    \"\"\"\n\n    def __init__(\n        self, in_dir: Union[Path, str], tile_size: Tuple[int, int] = (1000, 1000)\n    ) -&gt; None:\n        super().__init__(in_dir, tile_size)\n\n        # Lookup to manage the relations between the main and adjacent tiles\n        # main tile is the current tile and adj is the adjacent tile\n        self.neighbor_relations = {\n            \"right\": {\"main\": \"right\", \"adj\": \"left\"},\n            \"left\": {\"main\": \"left\", \"adj\": \"right\"},\n            \"top\": {\"main\": \"top\", \"adj\": \"bottom\"},\n            \"bottom\": {\"main\": \"bottom\", \"adj\": \"top\"},\n        }\n\n        # Lookup for already visited neighbors\n        self.visited = {\n            f.name: {\n                \"left\": None,\n                \"right\": None,\n                \"top\": None,\n                \"bottom\": None,\n                \"non_border\": None,\n                \"top_right\": None,\n                \"top_left\": None,\n                \"bottom_left\": None,\n                \"bottom_right\": None,\n            }\n            for f in self.files\n        }\n\n    def merge_dir(\n        self,\n        out_fn: Optional[Union[Path, str]] = None,\n        format: Optional[str] = None,\n        verbose: bool = True,\n    ) -&gt; None:\n        \"\"\"Merge all the instance segmentation files in the input directory.\n\n        Parameters:\n            out_fn (Union[Path, str]):\n                Filename for the output file. If None, the merged gdf is saved to the\n                class attribute `self.annots` only.\n            format (str):\n                The format of the output geojson file. One of: \".feather\", \".parquet\",\n                \".geojson\", None. This is ignored if `out_fn` is None.\n            verbose (bool):\n                Whether to show a progress bar or not.\n\n        Examples:\n            Write geojson files to a standard '.geojson' file.\n            &gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n            &gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n            &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.json\", format=\"geojson\")\n\n            Write input geojson files to feather file.\n            &gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n            &gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n            &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.feather\", format=\"feather\")\n\n            Write input geojson files to parquet file.\n            &gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n            &gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n            &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.parquet\", format=\"parquet\")\n        \"\"\"\n        if out_fn is not None:\n            out_fn = Path(out_fn)\n\n        if format not in (\".feather\", \".parquet\", \".geojson\", None):\n            raise ValueError(\n                f\"Invalid format. Got: {format}. Allowed: .feather, .parquet, .geojson\"\n            )\n\n        # merge the tiles\n        self.annots = self._merge(verbose=verbose)\n        if verbose:\n            msg = f\"{format}-format\" if out_fn is not None else \"`self.annots`\"\n            print(f\"Saving the merged geojson file: {out_fn} to {msg}\")\n\n        if out_fn is not None:\n            # save the merged geojson\n            gdf_to_file(self.annots, out_fn, format)\n\n    def _get_non_border_polygons(self, gson: GSONTile) -&gt; List[Dict[str, Any]]:\n        \"\"\"Get all the polygons that do not touch any edges of the tile.\n\n        Parameters\n        ----------\n            gson : GSONTile\n                GSONTile obj of a geojson tile.\n\n        Returns\n        -------\n            Tuple[List[Polygon], List[str]]:\n                A list of cell polygon objects and a list of the corresponding classes.\n        \"\"\"\n        nb_annots = gson.non_border_annots\n\n        classes = []\n        new_polys = []\n        if not nb_annots.empty:\n            for poly, c in zip(nb_annots.geometry, nb_annots.class_name):\n                poly = validate_and_simplify(poly, simplify=True, buffer=0.0)\n                new_polys.append(poly)\n                classes.append(c)\n\n        return new_polys, classes\n\n    def _merge_adj_ploygons(\n        self, gson: GSONTile, gson_adj: GSONTile, adj_pos: str\n    ) -&gt; List[Dict[str, Any]]:\n        \"\"\"Merge adjascent polygons in two adjacsent geojsons.\n\n        This concatenates the cells that are split at the image borders.\n\n        Parameters\n        ----------\n            gson : GSONTile\n                GSONTile obj of the geojson of the main tile.\n            gson_adj : GSONTile\n                GSONTile obj of the geojson of the adjascnet tile.\n            adj_pos : str\n                The postition of the adjascent tile relative to the main tile.\n                One of: \"left\", \"right\", \"bottom\", \"bottomleft\", \"bottomright\", \"top\",\n                \"topleft\", \"topright\"\n\n        Returns\n        -------\n            Tuple[List[Polygon], List[str]]:\n                A list of cell polygon objects and a list of the corresponding classes.\n        \"\"\"\n        # Get the polygons that end/start at the image border\n        if adj_pos == \"right\":\n            border_annots_main = gson.right_border_annots\n            border_annots_adj = gson_adj.left_border_annots\n        elif adj_pos == \"left\":\n            border_annots_main = gson.left_border_annots\n            border_annots_adj = gson_adj.right_border_annots\n        elif adj_pos == \"bottom\":\n            border_annots_main = gson.bottom_border_annots\n            border_annots_adj = gson_adj.top_border_annots\n        elif adj_pos == \"top\":\n            border_annots_main = gson.top_border_annots\n            border_annots_adj = gson_adj.bottom_border_annots\n\n        # combine polygons that intersect/touch between two image tiles\n        # (cells that are split in two between two image tiles)\n        new_classes = []\n        new_polys = []\n        if not border_annots_main.empty and not border_annots_adj.empty:\n            for main_poly, c1 in zip(\n                border_annots_main.geometry, border_annots_main.class_name\n            ):\n                main_poly = validate_and_simplify(main_poly, buffer=0.0)\n                for adj_poly, c2 in zip(\n                    border_annots_adj.geometry, border_annots_adj.class_name\n                ):\n                    adj_poly = validate_and_simplify(adj_poly, buffer=0.0)\n\n                    # combine the polygons if they intersect\n                    if main_poly.intersects(adj_poly):\n                        new_poly = unary_union([main_poly, adj_poly])\n\n                        # do some simplifying\n                        new_poly = validate_and_simplify(\n                            new_poly, simplify=True, buffer=0.0\n                        )\n\n                        if isinstance(new_poly, MultiPolygon):\n                            print(\"has multipoly\")\n\n                        # take the class of the larger object\n                        if adj_poly.area &gt;= main_poly.area:\n                            new_class = c2\n                        else:\n                            new_class = c1\n\n                        new_polys.append(new_poly)\n                        new_classes.append(new_class)\n\n        return new_polys, new_classes\n\n    def _merge(self, verbose: bool = True) -&gt; gpd.GeoDataFrame:\n        \"\"\"Merge all annotations in the files to one.\n\n        Handles the split cells at the image borders.\n\n        NOTE: This does not handle corners\n        \"\"\"\n        non_border_annots = []\n        non_border_classes = []\n        border_annots = []\n        border_classes = []\n        pbar = tqdm(self.files) if verbose else self.files\n        for f in pbar:\n            if verbose:\n                pbar.set_description(f\"Processing file: {f.name}\")\n\n            # get adjascent tiles\n            adj = self._get_adjascent_tiles(f.name)\n\n            # Init GSONTile obj\n            gson = GSONTile(f, tile_size=self.tile_size)\n            if gson.gdf is not None and not gson.gdf.empty:\n                # add the non border polygons\n                if self.visited[f.name][\"non_border\"] is None:\n                    non_border_polygons, non_border_cls = self._get_non_border_polygons(\n                        gson\n                    )\n                    non_border_annots.extend(non_border_polygons)\n                    non_border_classes.extend(non_border_cls)\n                    self.visited[f.name][\"non_border\"] = f.name\n\n                # loop the adjascent tiles and add the border polygons\n                for pos, f_adj in adj.items():\n                    if f_adj is not None:\n                        if self.visited[f.name][pos] is None:\n                            gson_adj = GSONTile(f_adj, tile_size=self.tile_size)\n\n                            if gson_adj.gdf is not None and not gson_adj.gdf.empty:\n                                border_polygons, border_cls = self._merge_adj_ploygons(\n                                    gson, gson_adj, pos\n                                )\n                                border_annots.extend(border_polygons)\n                                border_classes.extend(border_cls)\n\n                                # update lookup\n                                main_pos = self.neighbor_relations[pos][\"main\"]\n                                adj_pos = self.neighbor_relations[pos][\"adj\"]\n                                self.visited[f_adj.name][adj_pos] = f.name\n                                self.visited[f.name][main_pos] = f_adj.name\n\n        # save the annotations to class attributes\n        self.non_border_annots = gpd.GeoDataFrame(\n            {\"geometry\": non_border_annots, \"class_name\": non_border_classes}\n        )\n        border_annots = gpd.GeoDataFrame(\n            {\"geometry\": border_annots, \"class_name\": border_classes}\n        )\n        self.border_annots = merge_overlaps(border_annots)  # merge overlapping objects\n        annots = set_uid(\n            pd.concat([self.non_border_annots, self.border_annots]),\n            0,\n            id_col=\"id\",\n            drop=False,\n        )\n        return annots[annots.class_name != \"background\"]\n</code></pre>"},{"location":"reference/merging/cell_merger_ref/#cellseg_gsontools.merging.CellMerger.merge_dir","title":"<code>merge_dir(out_fn=None, format=None, verbose=True)</code>","text":"<p>Merge all the instance segmentation files in the input directory.</p> <p>Parameters:</p> Name Type Description Default <code>out_fn</code> <code>Union[Path, str]</code> <p>Filename for the output file. If None, the merged gdf is saved to the class attribute <code>self.annots</code> only.</p> <code>None</code> <code>format</code> <code>str</code> <p>The format of the output geojson file. One of: \".feather\", \".parquet\", \".geojson\", None. This is ignored if <code>out_fn</code> is None.</p> <code>None</code> <code>verbose</code> <code>bool</code> <p>Whether to show a progress bar or not.</p> <code>True</code> <p>Examples:</p> <p>Write geojson files to a standard '.geojson' file.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n&gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n&gt;&gt;&gt; merger.merge_dir(\"/path/to/output.json\", format=\"geojson\")\n</code></pre> <p>Write input geojson files to feather file.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n&gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n&gt;&gt;&gt; merger.merge_dir(\"/path/to/output.feather\", format=\"feather\")\n</code></pre> <p>Write input geojson files to parquet file.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n&gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n&gt;&gt;&gt; merger.merge_dir(\"/path/to/output.parquet\", format=\"parquet\")\n</code></pre> Source code in <code>cellseg_gsontools/merging/cell_merger.py</code> <pre><code>def merge_dir(\n    self,\n    out_fn: Optional[Union[Path, str]] = None,\n    format: Optional[str] = None,\n    verbose: bool = True,\n) -&gt; None:\n    \"\"\"Merge all the instance segmentation files in the input directory.\n\n    Parameters:\n        out_fn (Union[Path, str]):\n            Filename for the output file. If None, the merged gdf is saved to the\n            class attribute `self.annots` only.\n        format (str):\n            The format of the output geojson file. One of: \".feather\", \".parquet\",\n            \".geojson\", None. This is ignored if `out_fn` is None.\n        verbose (bool):\n            Whether to show a progress bar or not.\n\n    Examples:\n        Write geojson files to a standard '.geojson' file.\n        &gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n        &gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n        &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.json\", format=\"geojson\")\n\n        Write input geojson files to feather file.\n        &gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n        &gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n        &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.feather\", format=\"feather\")\n\n        Write input geojson files to parquet file.\n        &gt;&gt;&gt; from cellseg_gsontools.merging import CellMerger\n        &gt;&gt;&gt; merger = CellMerger(\"/path/to/geojsons/\", tile_size=(1000, 1000))\n        &gt;&gt;&gt; merger.merge_dir(\"/path/to/output.parquet\", format=\"parquet\")\n    \"\"\"\n    if out_fn is not None:\n        out_fn = Path(out_fn)\n\n    if format not in (\".feather\", \".parquet\", \".geojson\", None):\n        raise ValueError(\n            f\"Invalid format. Got: {format}. Allowed: .feather, .parquet, .geojson\"\n        )\n\n    # merge the tiles\n    self.annots = self._merge(verbose=verbose)\n    if verbose:\n        msg = f\"{format}-format\" if out_fn is not None else \"`self.annots`\"\n        print(f\"Saving the merged geojson file: {out_fn} to {msg}\")\n\n    if out_fn is not None:\n        # save the merged geojson\n        gdf_to_file(self.annots, out_fn, format)\n</code></pre>"},{"location":"reference/plotting/plot_all_ref/","title":"plot_all","text":""},{"location":"reference/plotting/plot_all_ref/#cellseg_gsontools.plotting.plot_gdf","title":"<code>cellseg_gsontools.plotting.plot_gdf(gdf, col, ax=None, cmap=None, bin_legends=None, show_legend=True, loc='upper right', figsize=(10, 10), **kwargs)</code>","text":"<p>Plot one gdf wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The gdf to plot.</p> required <code>col</code> <code>str</code> <p>The column to highlight.</p> required <code>ax</code> <code>Axes</code> <p>The axes to plot on, by default None.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>The colormap to use, by default None.</p> <code>None</code> <code>bin_legends</code> <code>List[str]</code> <p>The bins to use, by default None.</p> <code>None</code> <code>show_legend</code> <code>bool</code> <p>Whether to show the legend, by default True.</p> <code>True</code> <code>loc</code> <code>str</code> <p>The location of the legend, by default \"upper right\".</p> <code>'upper right'</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure, by default (10, 10).</p> <code>(10, 10)</code> <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Extra keyword arguments passed to the <code>plot</code> method of the GeoDataFrame.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>plt.Axes: The axes used for plotting.</p> Source code in <code>cellseg_gsontools/plotting/plot.py</code> <pre><code>def plot_gdf(\n    gdf: gpd.GeoDataFrame,\n    col: str,\n    ax: plt.Axes = None,\n    cmap: str = None,\n    bin_legends: List[str] = None,\n    show_legend: bool = True,\n    loc: str = \"upper right\",\n    figsize: tuple = (10, 10),\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"Plot one gdf wrapper.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The gdf to plot.\n        col (str):\n            The column to highlight.\n        ax (plt.Axes):\n            The axes to plot on, by default None.\n        cmap (str):\n            The colormap to use, by default None.\n        bin_legends (List[str]):\n            The bins to use, by default None.\n        show_legend (bool):\n            Whether to show the legend, by default True.\n        loc (str):\n            The location of the legend, by default \"upper right\".\n        figsize (tuple):\n            The size of the figure, by default (10, 10).\n        **kwargs (Dict[str, Any])):\n            Extra keyword arguments passed to the `plot` method of the GeoDataFrame.\n\n    Returns:\n        plt.Axes:\n            The axes used for plotting.\n    \"\"\"\n    ax = gdf.plot(\n        ax=ax,\n        column=col,\n        cmap=cmap,\n        categorical=True,\n        legend=show_legend,\n        legend_kwds={\"loc\": loc},\n        figsize=figsize,\n        **kwargs,\n    )\n    if show_legend:\n        leg = ax.legend_\n        ax.add_artist(leg)\n\n    if cmap is not None and show_legend and bin_legends is not None:\n        mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n        replace_legend_items(ax.get_legend(), mapping)\n\n    return ax\n</code></pre>"},{"location":"reference/plotting/plot_gdf_ref/","title":"plot_gdf","text":""},{"location":"reference/plotting/plot_gdf_ref/#cellseg_gsontools.plotting.plot_gdf","title":"<code>cellseg_gsontools.plotting.plot_gdf(gdf, col, ax=None, cmap=None, bin_legends=None, show_legend=True, loc='upper right', figsize=(10, 10), **kwargs)</code>","text":"<p>Plot one gdf wrapper.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>The gdf to plot.</p> required <code>col</code> <code>str</code> <p>The column to highlight.</p> required <code>ax</code> <code>Axes</code> <p>The axes to plot on, by default None.</p> <code>None</code> <code>cmap</code> <code>str</code> <p>The colormap to use, by default None.</p> <code>None</code> <code>bin_legends</code> <code>List[str]</code> <p>The bins to use, by default None.</p> <code>None</code> <code>show_legend</code> <code>bool</code> <p>Whether to show the legend, by default True.</p> <code>True</code> <code>loc</code> <code>str</code> <p>The location of the legend, by default \"upper right\".</p> <code>'upper right'</code> <code>figsize</code> <code>tuple</code> <p>The size of the figure, by default (10, 10).</p> <code>(10, 10)</code> <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Extra keyword arguments passed to the <code>plot</code> method of the GeoDataFrame.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>plt.Axes: The axes used for plotting.</p> Source code in <code>cellseg_gsontools/plotting/plot.py</code> <pre><code>def plot_gdf(\n    gdf: gpd.GeoDataFrame,\n    col: str,\n    ax: plt.Axes = None,\n    cmap: str = None,\n    bin_legends: List[str] = None,\n    show_legend: bool = True,\n    loc: str = \"upper right\",\n    figsize: tuple = (10, 10),\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"Plot one gdf wrapper.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            The gdf to plot.\n        col (str):\n            The column to highlight.\n        ax (plt.Axes):\n            The axes to plot on, by default None.\n        cmap (str):\n            The colormap to use, by default None.\n        bin_legends (List[str]):\n            The bins to use, by default None.\n        show_legend (bool):\n            Whether to show the legend, by default True.\n        loc (str):\n            The location of the legend, by default \"upper right\".\n        figsize (tuple):\n            The size of the figure, by default (10, 10).\n        **kwargs (Dict[str, Any])):\n            Extra keyword arguments passed to the `plot` method of the GeoDataFrame.\n\n    Returns:\n        plt.Axes:\n            The axes used for plotting.\n    \"\"\"\n    ax = gdf.plot(\n        ax=ax,\n        column=col,\n        cmap=cmap,\n        categorical=True,\n        legend=show_legend,\n        legend_kwds={\"loc\": loc},\n        figsize=figsize,\n        **kwargs,\n    )\n    if show_legend:\n        leg = ax.legend_\n        ax.add_artist(leg)\n\n    if cmap is not None and show_legend and bin_legends is not None:\n        mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n        replace_legend_items(ax.get_legend(), mapping)\n\n    return ax\n</code></pre>"},{"location":"reference/spatial_contexts/iface_context_ref/","title":"InterfaceContext","text":""},{"location":"reference/spatial_contexts/iface_context_ref/#cellseg_gsontools.spatial_context.InterfaceContext","title":"<code>cellseg_gsontools.spatial_context.InterfaceContext</code>","text":"<p>Handle &amp; extract interface regions from the <code>cell_gdf</code> and <code>area_gdf</code>.</p> <p>Interfaces are created by buffering areas of type <code>top_label</code> on top of the areas of type <code>bottom_labels</code> and taking the intersection of the buffered area and the <code>top_label</code> area. The result interface is a band-like area b/w <code>top_label</code> and <code>bottom_label</code> areas. The bredth of the interface is given by the <code>buffer_dist</code> param.</p> Note <p><code>area_gdf</code> and <code>cell_gdf</code> have to contain a column named 'class_name'</p> <p>Parameters:</p> Name Type Description Default <code>area_gdf</code> <code>GeoDataFrame</code> <p>A geo dataframe that contains large tissue area polygons enclosing the smaller cellular objects in <code>cell_gdf</code>.</p> required <code>cell_gdf</code> <code>GeoDataFrame</code> <p>A geo dataframe that contains small cellular objects that are enclosed by larger tissue areas in <code>area_gdf</code>.</p> required <code>top_labels</code> <code>Union[Tuple[str, ...], str]</code> <p>The class name(s) of the areas of interest. E.g. \"tumor\". These areas are buffered on top of the areas that have type in <code>bottom_labels</code>. For example, buffering the tumor area on top of the stroma will get the tumor-stroma interface.</p> required <code>bottom_labels</code> <code>Union[Tuple[str, ...], str]</code> <p>The class name of the area on top of which the buffering is applied. Typically you want to buffer at least on top of the stromal area to get e.g. tumor-stroma interface. Other options are ofc possible.</p> required <code>min_area_size</code> <code>float or str</code> <p>The minimum area of the objects that are kept. All the objects in the <code>area_gdf</code> that are larger are kept than <code>min_area_size</code>. If None, all the areas are kept. Defaults to None.</p> <code>None</code> <code>graph_type</code> <code>str</code> <p>The type of the graph to be fitted to the cells inside interfaces. One of: \"delaunay\", \"distband\", \"relative_nhood\", \"knn\".</p> <code>'distband'</code> <code>dist_thresh</code> <code>float</code> <p>Distance threshold for the length of the network links.</p> <code>50.0</code> <code>grid_type</code> <code>str</code> <p>The type of the grid to be fitted on the roi areas. One of: \"square\", \"hex\".</p> <code>'square'</code> <code>patch_size</code> <code>Tuple[int, int]</code> <p>The size of the grid patches to be fitted on the context. This is used when <code>grid_type='square'</code>.</p> <code>(256, 256)</code> <code>stride</code> <code>Tuple[int, int]</code> <p>The stride of the sliding window for grid patching. This is used when <code>grid_type='square'</code>.</p> <code>(256, 256)</code> <code>pad</code> <code>int</code> <p>The padding to add to the bounding box on the grid. This is used when <code>grid_type='square'</code>.</p> <code>None</code> <code>resolution</code> <code>int</code> <p>The resolution of the h3 hex grid. This is used when <code>grid_type='hex'</code>.</p> <code>9</code> <code>predicate</code> <code>str</code> <p>The predicate to use for the spatial join when extracting the ROI cells. See <code>geopandas.tools.sjoin</code></p> <code>'intersects'</code> <code>silence_warnings</code> <code>bool</code> <p>Flag, whether to silence all the warnings.</p> <code>True</code> <code>parallel</code> <code>bool</code> <p>Flag, whether to parallelize the context fitting. If <code>backend == \"geopandas\"</code>, the parallelization is implemented with <code>pandarallel</code> package. If <code>backend == \"spatialpandas\"</code>, or <code>backend == \"dask-geopandas\"</code> the parallelization is implemented with Dask library.</p> <code>False</code> <code>num_processes</code> <code>int</code> <p>The number of processes to use when parallel=True. If -1, this will use all the available cores.</p> <code>-1</code> <code>backend</code> <code>str</code> <p>The backend to use for the spatial context. One of \"geopandas\", \"spatialpandas\" \"dask-geopandas\". \"spatialpandas\" or \"dask-geopandas\" is recommended for gdfs that may contain huge polygons.</p> <code>'geopandas'</code> <p>Attributes:</p> Name Type Description <code>context</code> <code>Dict[int, Dict[str, Union[GeoDataFrame, W]]]</code> <p>A nested dict that contains dicts for each of the distinct ROIs of type <code>top_labels</code> and the interfaces b/w areas of type <code>bottom_labels</code>. The keys of the outer dict are the indices of these areas. The inner dicts contain the keys:</p> <ul> <li><code>roi_area</code>- <code>gpd.GeoDataFrame</code>: of the roi area. Roi area is the tissue         area(s) of type <code>top_labels</code> that is buffered on top of the area         of type <code>bottom_labels</code> to get the interface.</li> <li><code>roi_cells</code> - <code>gpd.GeoDataFrame</code>: of the cells that are contained         inside the <code>roi_area</code>.</li> <li><code>roi_network</code> - <code>libpysal.weights.W</code>: spatial weights network of         the cells inside the <code>roi_area</code>. This can be used to extract         graph features inside the <code>roi_area</code>.</li> <li><code>roi_grid</code> - <code>gpd.GeoDataFrame</code>: of the grid fitted on the <code>roi_area</code>.         This can be used to extract grid features inside the <code>roi_area</code>.</li> <li><code>interface_area</code> - <code>gpd.GeoDataFrame</code>:the interface area. Interface         area is the area that is the intersection of the buffered         <code>roi_area</code> (<code>top_labels</code>) and the area of type <code>bottom_labels</code>.</li> <li><code>interface_network</code> - <code>libpysal.weights.W</code>: spatial weights network of         the cells inside the <code>interface_area</code>.</li> <li><code>border_network</code> - <code>libpysal.weights.W</code>: spatial weights network of the         cells at the border of the roi and interface areas.</li> <li><code>full_network</code> - <code>libpysal.weights.W</code>: spatial weights network of the         cells inside the union of the roi and interface areas.</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>area_gdf</code> or <code>cell_gdf</code> don't contain 'class_name' column.</p> Source code in <code>cellseg_gsontools/spatial_context/interface.py</code> <pre><code>class InterfaceContext:\n    \"\"\"Handle &amp; extract interface regions from the `cell_gdf` and `area_gdf`.\n\n    Interfaces are created by buffering areas of type `top_label` on top of the\n    areas of type `bottom_labels` and taking the intersection of the buffered area\n    and the `top_label` area. The result interface is a band-like area b/w\n    `top_label` and `bottom_label` areas. The bredth of the interface is given by\n    the `buffer_dist` param.\n\n    Note:\n        `area_gdf` and `cell_gdf` have to contain a column named 'class_name'\n\n    Parameters:\n        area_gdf (gpd.GeoDataFrame):\n            A geo dataframe that contains large tissue area polygons enclosing\n            the smaller cellular objects in `cell_gdf`.\n        cell_gdf (gpd.GeoDataFrame):\n            A geo dataframe that contains small cellular objects that are\n            enclosed by larger tissue areas in `area_gdf`.\n        top_labels (Union[Tuple[str, ...], str]):\n            The class name(s) of the areas of interest. E.g. \"tumor\". These areas\n            are buffered on top of the areas that have type in `bottom_labels`. For\n            example, buffering the tumor area on top of the stroma will get the\n            tumor-stroma interface.\n        bottom_labels (Union[Tuple[str, ...], str]):\n            The class name of the area on top of which the buffering is applied.\n            Typically you want to buffer at least on top of the stromal area to get\n            e.g. tumor-stroma interface. Other options are ofc possible.\n        min_area_size (float or str, optional):\n            The minimum area of the objects that are kept. All the objects in\n            the `area_gdf` that are larger are kept than `min_area_size`. If\n            None, all the areas are kept. Defaults to None.\n        graph_type (str):\n            The type of the graph to be fitted to the cells inside interfaces.\n            One of: \"delaunay\", \"distband\", \"relative_nhood\", \"knn\".\n        dist_thresh (float):\n            Distance threshold for the length of the network links.\n        grid_type (str):\n            The type of the grid to be fitted on the roi areas. One of:\n            \"square\", \"hex\".\n        patch_size (Tuple[int, int]):\n            The size of the grid patches to be fitted on the context. This is\n            used when `grid_type='square'`.\n        stride (Tuple[int, int]):\n            The stride of the sliding window for grid patching. This is used\n            when `grid_type='square'`.\n        pad (int):\n            The padding to add to the bounding box on the grid. This is used\n            when `grid_type='square'`.\n        resolution (int):\n            The resolution of the h3 hex grid. This is used when\n            `grid_type='hex'`.\n        predicate (str):\n            The predicate to use for the spatial join when extracting the ROI\n            cells. See `geopandas.tools.sjoin`\n        silence_warnings (bool):\n            Flag, whether to silence all the warnings.\n        parallel (bool):\n            Flag, whether to parallelize the context fitting. If\n            `backend == \"geopandas\"`, the parallelization is implemented with\n            `pandarallel` package. If `backend == \"spatialpandas\"`, or\n            `backend == \"dask-geopandas\"` the parallelization is implemented\n            with Dask library.\n        num_processes (int):\n            The number of processes to use when parallel=True. If -1, this\n            will use all the available cores.\n        backend (str):\n            The backend to use for the spatial context. One of \"geopandas\",\n            \"spatialpandas\" \"dask-geopandas\". \"spatialpandas\" or\n            \"dask-geopandas\" is recommended for gdfs that may contain huge\n            polygons.\n\n    Attributes:\n        context (Dict[int, Dict[str, Union[gpd.GeoDataFrame, libpysal.weights.W]]]):\n            A nested dict that contains dicts for each of the distinct ROIs\n            of type `top_labels` and the interfaces b/w areas of type `bottom_labels`.\n            The keys of the outer dict are the indices of these areas.\n            The inner dicts contain the keys:\n\n            - `roi_area`- `gpd.GeoDataFrame`: of the roi area. Roi area is the tissue\n                    area(s) of type `top_labels` that is buffered on top of the area\n                    of type `bottom_labels` to get the interface.\n            - `roi_cells` - `gpd.GeoDataFrame`: of the cells that are contained\n                    inside the `roi_area`.\n            - `roi_network` - `libpysal.weights.W`: spatial weights network of\n                    the cells inside the `roi_area`. This can be used to extract\n                    graph features inside the `roi_area`.\n            - `roi_grid` - `gpd.GeoDataFrame`: of the grid fitted on the `roi_area`.\n                    This can be used to extract grid features inside the `roi_area`.\n            - `interface_area` - `gpd.GeoDataFrame`:the interface area. Interface\n                    area is the area that is the intersection of the buffered\n                    `roi_area` (`top_labels`) and the area of type `bottom_labels`.\n            - `interface_network` - `libpysal.weights.W`: spatial weights network of\n                    the cells inside the `interface_area`.\n            - `border_network` - `libpysal.weights.W`: spatial weights network of the\n                    cells at the border of the roi and interface areas.\n            - `full_network` - `libpysal.weights.W`: spatial weights network of the\n                    cells inside the union of the roi and interface areas.\n\n    Raises:\n        ValueError: if `area_gdf` or `cell_gdf` don't contain 'class_name' column.\n    \"\"\"\n\n    def __init__(\n        self,\n        area_gdf: gpd.GeoDataFrame,\n        cell_gdf: gpd.GeoDataFrame,\n        top_labels: Union[Tuple[str, ...], str],\n        bottom_labels: Union[Tuple[str, ...], str],\n        min_area_size: Union[float, str] = None,\n        buffer_dist: int = 200,\n        graph_type: str = \"distband\",\n        dist_thresh: float = 50.0,\n        grid_type: str = \"square\",\n        patch_size: Tuple[int, int] = (256, 256),\n        stride: Tuple[int, int] = (256, 256),\n        pad: int = None,\n        resolution: int = 9,\n        predicate: str = \"intersects\",\n        silence_warnings: bool = True,\n        parallel: bool = False,\n        num_processes: int = -1,\n        backend: str = \"geopandas\",\n    ) -&gt; None:\n        self.backend_name = backend\n        if backend == \"geopandas\":\n            self.backend = _SpatialContextGP()\n        # elif backend == \"spatialpandas\":\n        #     self.backend = _SpatialContextSP()\n        # elif backend == \"dask-geopandas\":\n        #     self.backend = _SpatialContextDGP()\n        else:\n            raise ValueError(\n                f\"Unknown backend: {backend}. \"\n                \"Allowed: 'spatialpandas', 'geopandas', 'dask-geopandas'\"\n            )\n\n        # check if the 'class_name' column is present\n        self.backend.check_columns(area_gdf, cell_gdf)\n\n        # set up the attributes\n        self.buffer_dist = buffer_dist\n        self.min_area_size = min_area_size\n        self.dist_thresh = dist_thresh\n        self.graph_type = graph_type\n        self.patch_size = patch_size\n        self.stride = stride\n        self.pad = pad\n        self.silence_warnings = silence_warnings\n        self.top_labels = top_labels\n        self.bottom_labels = bottom_labels\n        self.predicate = predicate\n        self.parallel = parallel\n        self.num_processes = num_processes\n        self.grid_type = grid_type\n        self.resolution = resolution\n\n        # set to geocentric cartesian crs. (unit is metre not degree as by default)\n        # helps to avoid warning flooding\n        self.cell_gdf = set_uid(cell_gdf, id_col=\"global_id\")\n        self.cell_gdf.set_crs(epsg=4328, inplace=True, allow_override=True)\n\n        # cache the full area gdf for plotting\n        self.area_gdf = area_gdf\n        self.area_gdf.set_crs(epsg=4328, inplace=True, allow_override=True)\n\n        # filter small areas and tissue types for the top and bottom labels\n        self.context_area = self.backend.filter_areas(\n            self.area_gdf, top_labels, min_area_size\n        )\n        self.context_area = set_uid(self.context_area, id_col=\"global_id\")\n\n        self.context_area2 = self.backend.filter_areas(\n            self.area_gdf, bottom_labels, min_area_size\n        )\n        self.context_area2 = set_uid(self.context_area2, id_col=\"global_id\")\n\n        # set up cpu count\n        if parallel:\n            self.cpus = (\n                psutil.cpu_count(logical=False)\n                if self.num_processes == -1 or self.num_processes is None\n                else self.num_processes\n            )\n        else:\n            self.cpus = 1\n\n        # convert the gdfs to the backend format\n        self.context_area = self.backend.convert_area_gdf(self.context_area)\n        self.context_area2 = self.backend.convert_area_gdf(self.context_area2)\n\n        self.cell_gdf = self.backend.convert_cell_gdf(\n            self.cell_gdf, parallel=parallel, n_partitions=self.cpus\n        )\n\n    def __getattr__(self, name):\n        \"\"\"Get attribute.\"\"\"\n        return self.backend.__getattribute__(name)\n\n    def fit(\n        self,\n        verbose: bool = True,\n        fit_graph: bool = True,\n        fit_grid: bool = True,\n    ) -&gt; None:\n        \"\"\"Fit the interface context.\n\n        This sets the `self.context` class attribute.\n\n        Parameters:\n            verbose (bool):\n                Flag, whether to use tqdm pbar when creating the interfaces.\n            fit_graph (bool):\n                Flag, whether to fit the spatial weights networks for the\n                context.\n            fit_grid (bool):\n                Flag, whether to fit the a grid on the contextes.\n\n        Examples:\n            Define an tumor-stroma interface context and plot the cells inside the\n            interface area.\n\n            &gt;&gt;&gt; from cellseg_gsontools.backend import InterfaceContext\n            &gt;&gt;&gt; area_gdf = read_gdf(\"area.json\")\n            &gt;&gt;&gt; cell_gdf = read_gdf(\"cells.json\")\n            &gt;&gt;&gt; interface_context = InterfaceContext(\n            ...     area_gdf=area_gdf,\n            ...     cell_gdf=cell_gdf,\n            ...     top_labels=[\"area_cin\"],\n            ...     bottom_labels=[\"area_stroma\"],\n            ...     buffer_dist=250.0,\n            ...     graph_type=\"delaunay\",\n            ...     silence_warnings=True,\n            ...     min_area_size=100000.0,\n            ... )\n            &gt;&gt;&gt; interface_context.fit(parallel=False)\n            &gt;&gt;&gt; interface_context.plot(\"interface_area\", show_legends=True)\n            &lt;AxesSubplot: &gt;\n        \"\"\"\n        get_context_func = partial(\n            InterfaceContext._get_context,\n            backend=self.backend,\n            context_area=self.context_area,\n            context_area2=self.context_area2,\n            cell_gdf=self.cell_gdf,\n            fit_network=fit_graph,\n            fit_grid=fit_grid,\n            grid_type=self.grid_type,\n            resolution=self.resolution,\n            predicate=self.predicate,\n            buffer_dist=self.buffer_dist,\n            silence_warnings=self.silence_warnings,\n            graph_type=self.graph_type,\n            dist_thresh=self.dist_thresh,\n            patch_size=self.patch_size,\n            stride=self.stride,\n            pad=self.pad,\n            parallel=self.parallel,\n            num_processes=self.cpus,\n        )\n\n        if self.backend_name == \"geopandas\" and self.parallel:\n            # run in parallel\n            context_dict = gdf_apply(\n                self.context_area,\n                func=get_context_func,\n                columns=[\"global_id\"],\n                parallel=True,\n                pbar=verbose,\n                num_processes=self.cpus,\n            ).to_dict()\n        else:\n            context_dict = {}\n            pbar = (\n                tqdm(self.context_area.index, total=self.context_area.shape[0])\n                if verbose\n                else self.context_area.index\n            )\n\n            for ix in pbar:\n                if verbose:\n                    pbar.set_description(f\"Processing roi area: {ix}\")\n\n                if self.backend_name == \"dask-geopandas\" and self.parallel:\n                    get_context_func = partial(\n                        get_context_func, cell_gdf_dgp=self.backend.cell_gdf_dgp\n                    )\n\n                context_dict[ix] = get_context_func(ix=ix)\n\n        self.context = context_dict\n\n    @staticmethod\n    def _get_context(\n        ix: int,\n        backend,\n        context_area: gpd.GeoDataFrame,\n        context_area2: gpd.GeoDataFrame,\n        cell_gdf: gpd.GeoDataFrame,\n        buffer_dist: int = 200,\n        fit_network: bool = True,\n        fit_grid: bool = True,\n        grid_type: str = \"square\",\n        resolution: int = 9,\n        predicate: str = \"intersects\",\n        silence_warnings: bool = True,\n        graph_type: str = \"distband\",\n        dist_thresh: float = 75.0,\n        patch_size: Tuple[int, int] = (256, 256),\n        stride: Tuple[int, int] = (256, 256),\n        pad: int = None,\n        parallel: bool = False,\n        num_processes: int = None,\n        **kwargs,\n    ) -&gt; Dict[int, Any]:\n        \"\"\"Get the context dict of the given index.\"\"\"\n        roi_area: gpd.GeoDataFrame = backend.roi(ix=ix, context_area=context_area)\n        roi_cells: gpd.GeoDataFrame = backend.roi_cells(\n            roi_area=roi_area,\n            cell_gdf=cell_gdf,\n            predicate=predicate,\n            silence_warnings=silence_warnings,\n            parallel=parallel,\n            num_processes=num_processes,\n            **kwargs,\n        )\n        context_dict = {\"roi_area\": roi_area}\n        context_dict[\"roi_cells\"] = roi_cells\n\n        # interface context\n        iface_area: gpd.GeoDataFrame = backend.interface(\n            top_roi_area=roi_area, bottom_gdf=context_area2, buffer_dist=buffer_dist\n        )\n        iface_cells: gpd.GeoDataFrame = backend.roi_cells(\n            roi_area=iface_area,\n            cell_gdf=cell_gdf,\n            predicate=predicate,\n            silence_warnings=silence_warnings,\n            parallel=parallel,\n            num_processes=num_processes,\n            **kwargs,\n        )\n        context_dict[\"interface_area\"] = iface_area\n        context_dict[\"interface_cells\"] = iface_cells\n\n        # context networks\n        if fit_network:\n            if (iface_cells is None or iface_cells.empty) or (\n                roi_cells is None or roi_cells.empty\n            ):\n                context_dict[\"full_network\"] = None\n                context_dict[\"roi_network\"] = None\n                context_dict[\"interface_network\"] = None\n                context_dict[\"border_network\"] = None\n            else:\n                # merge the gdfs to compute union weights\n                cells = pd.concat([roi_cells, iface_cells], sort=False)\n\n                # fit the union graph\n                context_dict[\"full_network\"] = fit_graph(\n                    cells,\n                    type=graph_type,\n                    id_col=\"global_id\",\n                    thresh=dist_thresh,\n                    use_index=False,\n                )\n\n                # Get the weight subsets\n                context_dict[\"roi_network\"] = w_subset(\n                    context_dict[\"full_network\"],\n                    sorted(set(roi_cells.global_id)),\n                    silence_warnings=silence_warnings,\n                )\n                context_dict[\"interface_network\"] = w_subset(\n                    context_dict[\"full_network\"],\n                    sorted(set(iface_cells.global_id)),\n                    silence_warnings=silence_warnings,\n                )\n\n                # get the weights 4 the nodes that have links crossing the iface border\n                context_dict[\"border_network\"] = get_border_crosser_links(\n                    union_weights=context_dict[\"full_network\"],\n                    roi_weights=context_dict[\"roi_network\"],\n                    iface_weights=context_dict[\"interface_network\"],\n                    only_border_crossers=True,\n                )\n\n        if fit_grid:\n            if grid_type == \"hex\":\n                kwargs = {\"resolution\": resolution}\n            else:\n                kwargs = {\n                    \"patch_size\": patch_size,\n                    \"stride\": stride,\n                    \"pad\": pad,\n                    \"predicate\": predicate,\n                }\n\n            context_dict[\"roi_grid\"] = fit_spatial_grid(\n                gdf=roi_area, grid_type=grid_type, **kwargs\n            )\n            context_dict[\"interface_grid\"] = fit_spatial_grid(\n                gdf=iface_area, grid_type=grid_type, **kwargs\n            )\n\n        return context_dict\n\n    def context2weights(self, key: str) -&gt; W:\n        \"\"\"Merge the networks of type `key` into one spatial weights obj.\n\n        Parameters:\n            key (str):\n                The key of the context dictionary that contains the spatial\n                weights to be merged. One of \"roi_network\", \"full_network\",\n                \"interface_network\", \"border_network\"\n\n        Returns:\n            libpysal.weights.W:\n                A spatial weights object containing all the distinct networks\n                in the context.\n        \"\"\"\n        allowed = (\"roi_network\", \"full_network\", \"interface_network\", \"border_network\")\n        if key not in allowed:\n            raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n        cxs = list(self.context.items())\n        wout = W({0: [0]})\n        for _, c in cxs:\n            w = c[key]\n            if isinstance(w, W):\n                wout = w_union(wout, w, silence_warnings=True)\n\n        # remove self loops\n        wout = w_subset(wout, list(wout.neighbors.keys())[1:], silence_warnings=True)\n\n        return wout\n\n    def context2gdf(self, key: str) -&gt; gpd.GeoDataFrame:\n        \"\"\"Merge the GeoDataFrames of type `key` into one geodataframe.\n\n        Note:\n            Returns None if no data is found.\n\n        Parameters:\n            key (str):\n                The key of the context dictionary that contains the data to be converted\n                to gdf. One of \"roi_area\", \"roi_cells\", \"interface_area\", \"roi_grid\",\n                \"interface_grid\", \"interface_cells\", \"roi_interface_cells\"\n\n        Returns:\n            gpd.GeoDataFrame:\n                Geo dataframe containing all the objects\n        \"\"\"\n        allowed = (\n            \"roi_area\",\n            \"roi_cells\",\n            \"interface_area\",\n            \"roi_grid\",\n            \"interface_grid\",\n            \"interface_cells\",\n            \"roi_interface_cells\",\n        )\n        if key not in allowed:\n            raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n        con = []\n        for i in self.context.keys():\n            if self.context[i][key] is not None:\n                if isinstance(self.context[i][key], tuple):\n                    con.append(self.context[i][key][0])\n                else:\n                    con.append(self.context[i][key])\n\n        if not con:\n            return\n\n        gdf = pd.concat(\n            con,\n            keys=[i for i in self.context.keys() if self.context[i][key] is not None],\n        )\n        gdf = gdf.explode(ignore_index=True)\n\n        return (\n            gdf.reset_index(level=0, names=\"label\")\n            .drop_duplicates(\"geometry\")\n            .set_geometry(\"geometry\")\n        )\n\n    def plot(\n        self,\n        key: str,\n        network_key: str = None,\n        grid_key: str = None,\n        show_legends: bool = True,\n        color: str = None,\n        figsize: Tuple[int, int] = (12, 12),\n        edge_kws: Dict[str, Any] = None,\n        **kwargs,\n    ) -&gt; plt.Axes:\n        \"\"\"Plot the context with areas, cells, and interface areas highlighted.\n\n        Parameters:\n            key (str):\n                The key of the context dictionary that contains the data to be plotted.\n                One of \"roi_area\",\n            network_key (str):\n                The key of the context dictionary that contains the spatial weights to\n                be plotted. One of \"roi_network\"\n            grid_key (str):\n                The key of the context dictionary that contains the grid to be plotted.\n                One of \"roi_grid\"\n            show_legends (bool):\n                Flag, whether to include legends for each in the plot.\n            color (str):\n                A color for the interfaces or rois, Ignored if `show_legends=True`.\n            figsize (Tuple[int, int]):\n                Size of the figure.\n            **kwargs (Dict[str, Any])]):\n                Extra keyword arguments passed to the `plot` method of the\n                geodataframes.\n\n        Returns:\n            AxesSubplot\n\n        Examples:\n            Plot the tumor-stroma areas.\n\n            &gt;&gt;&gt; from cellseg_gsontools.spatial_context import InterfaceContext\n            &gt;&gt;&gt; cells = read_gdf(\"cells.feather\")\n            &gt;&gt;&gt; areas = read_gdf(\"areas.feather\")\n            &gt;&gt;&gt; ts_iface = InterfaceContext(\n            ...     area_gdf=areas,\n            ...     cell_gdf=cells,\n            ...     top_labels=\"tumor\",\n            ...     bottom_labels=\"stroma\",\n            ... )\n            &gt;&gt;&gt; ts_iface.fit(verbose=False)\n            &gt;&gt;&gt; ts_iface.plot(\"interface_area\", show_legends=True)\n            &lt;AxesSubplot: &gt;\n        \"\"\"\n        allowed = (\"roi_area\", \"interface_area\")\n        if key not in allowed:\n            raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n        context_gdf = self.context2gdf(key)\n\n        grid_gdf = None\n        if grid_key is not None:\n            grid_gdf = self.context2gdf(grid_key)\n\n        network_gdf = None\n        if network_key is not None:\n            edge_kws = edge_kws or {}\n            w = self.context2weights(network_key)\n            network_gdf = weights2gdf(self.cell_gdf, w)\n\n        return plot_all(\n            cell_gdf=self.cell_gdf.set_geometry(\"geometry\"),\n            area_gdf=self.area_gdf.set_geometry(\"geometry\"),\n            context_gdf=context_gdf,\n            grid_gdf=grid_gdf,\n            network_gdf=network_gdf,\n            show_legends=show_legends,\n            color=color,\n            figsize=figsize,\n            edge_kws=edge_kws,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/spatial_contexts/iface_context_ref/#cellseg_gsontools.spatial_context.InterfaceContext.fit","title":"<code>fit(verbose=True, fit_graph=True, fit_grid=True)</code>","text":"<p>Fit the interface context.</p> <p>This sets the <code>self.context</code> class attribute.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Flag, whether to use tqdm pbar when creating the interfaces.</p> <code>True</code> <code>fit_graph</code> <code>bool</code> <p>Flag, whether to fit the spatial weights networks for the context.</p> <code>True</code> <code>fit_grid</code> <code>bool</code> <p>Flag, whether to fit the a grid on the contextes.</p> <code>True</code> <p>Examples:</p> <p>Define an tumor-stroma interface context and plot the cells inside the interface area.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.backend import InterfaceContext\n&gt;&gt;&gt; area_gdf = read_gdf(\"area.json\")\n&gt;&gt;&gt; cell_gdf = read_gdf(\"cells.json\")\n&gt;&gt;&gt; interface_context = InterfaceContext(\n...     area_gdf=area_gdf,\n...     cell_gdf=cell_gdf,\n...     top_labels=[\"area_cin\"],\n...     bottom_labels=[\"area_stroma\"],\n...     buffer_dist=250.0,\n...     graph_type=\"delaunay\",\n...     silence_warnings=True,\n...     min_area_size=100000.0,\n... )\n&gt;&gt;&gt; interface_context.fit(parallel=False)\n&gt;&gt;&gt; interface_context.plot(\"interface_area\", show_legends=True)\n&lt;AxesSubplot: &gt;\n</code></pre> Source code in <code>cellseg_gsontools/spatial_context/interface.py</code> <pre><code>def fit(\n    self,\n    verbose: bool = True,\n    fit_graph: bool = True,\n    fit_grid: bool = True,\n) -&gt; None:\n    \"\"\"Fit the interface context.\n\n    This sets the `self.context` class attribute.\n\n    Parameters:\n        verbose (bool):\n            Flag, whether to use tqdm pbar when creating the interfaces.\n        fit_graph (bool):\n            Flag, whether to fit the spatial weights networks for the\n            context.\n        fit_grid (bool):\n            Flag, whether to fit the a grid on the contextes.\n\n    Examples:\n        Define an tumor-stroma interface context and plot the cells inside the\n        interface area.\n\n        &gt;&gt;&gt; from cellseg_gsontools.backend import InterfaceContext\n        &gt;&gt;&gt; area_gdf = read_gdf(\"area.json\")\n        &gt;&gt;&gt; cell_gdf = read_gdf(\"cells.json\")\n        &gt;&gt;&gt; interface_context = InterfaceContext(\n        ...     area_gdf=area_gdf,\n        ...     cell_gdf=cell_gdf,\n        ...     top_labels=[\"area_cin\"],\n        ...     bottom_labels=[\"area_stroma\"],\n        ...     buffer_dist=250.0,\n        ...     graph_type=\"delaunay\",\n        ...     silence_warnings=True,\n        ...     min_area_size=100000.0,\n        ... )\n        &gt;&gt;&gt; interface_context.fit(parallel=False)\n        &gt;&gt;&gt; interface_context.plot(\"interface_area\", show_legends=True)\n        &lt;AxesSubplot: &gt;\n    \"\"\"\n    get_context_func = partial(\n        InterfaceContext._get_context,\n        backend=self.backend,\n        context_area=self.context_area,\n        context_area2=self.context_area2,\n        cell_gdf=self.cell_gdf,\n        fit_network=fit_graph,\n        fit_grid=fit_grid,\n        grid_type=self.grid_type,\n        resolution=self.resolution,\n        predicate=self.predicate,\n        buffer_dist=self.buffer_dist,\n        silence_warnings=self.silence_warnings,\n        graph_type=self.graph_type,\n        dist_thresh=self.dist_thresh,\n        patch_size=self.patch_size,\n        stride=self.stride,\n        pad=self.pad,\n        parallel=self.parallel,\n        num_processes=self.cpus,\n    )\n\n    if self.backend_name == \"geopandas\" and self.parallel:\n        # run in parallel\n        context_dict = gdf_apply(\n            self.context_area,\n            func=get_context_func,\n            columns=[\"global_id\"],\n            parallel=True,\n            pbar=verbose,\n            num_processes=self.cpus,\n        ).to_dict()\n    else:\n        context_dict = {}\n        pbar = (\n            tqdm(self.context_area.index, total=self.context_area.shape[0])\n            if verbose\n            else self.context_area.index\n        )\n\n        for ix in pbar:\n            if verbose:\n                pbar.set_description(f\"Processing roi area: {ix}\")\n\n            if self.backend_name == \"dask-geopandas\" and self.parallel:\n                get_context_func = partial(\n                    get_context_func, cell_gdf_dgp=self.backend.cell_gdf_dgp\n                )\n\n            context_dict[ix] = get_context_func(ix=ix)\n\n    self.context = context_dict\n</code></pre>"},{"location":"reference/spatial_contexts/iface_context_ref/#cellseg_gsontools.spatial_context.InterfaceContext.context2gdf","title":"<code>context2gdf(key)</code>","text":"<p>Merge the GeoDataFrames of type <code>key</code> into one geodataframe.</p> Note <p>Returns None if no data is found.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the context dictionary that contains the data to be converted to gdf. One of \"roi_area\", \"roi_cells\", \"interface_area\", \"roi_grid\", \"interface_grid\", \"interface_cells\", \"roi_interface_cells\"</p> required <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: Geo dataframe containing all the objects</p> Source code in <code>cellseg_gsontools/spatial_context/interface.py</code> <pre><code>def context2gdf(self, key: str) -&gt; gpd.GeoDataFrame:\n    \"\"\"Merge the GeoDataFrames of type `key` into one geodataframe.\n\n    Note:\n        Returns None if no data is found.\n\n    Parameters:\n        key (str):\n            The key of the context dictionary that contains the data to be converted\n            to gdf. One of \"roi_area\", \"roi_cells\", \"interface_area\", \"roi_grid\",\n            \"interface_grid\", \"interface_cells\", \"roi_interface_cells\"\n\n    Returns:\n        gpd.GeoDataFrame:\n            Geo dataframe containing all the objects\n    \"\"\"\n    allowed = (\n        \"roi_area\",\n        \"roi_cells\",\n        \"interface_area\",\n        \"roi_grid\",\n        \"interface_grid\",\n        \"interface_cells\",\n        \"roi_interface_cells\",\n    )\n    if key not in allowed:\n        raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n    con = []\n    for i in self.context.keys():\n        if self.context[i][key] is not None:\n            if isinstance(self.context[i][key], tuple):\n                con.append(self.context[i][key][0])\n            else:\n                con.append(self.context[i][key])\n\n    if not con:\n        return\n\n    gdf = pd.concat(\n        con,\n        keys=[i for i in self.context.keys() if self.context[i][key] is not None],\n    )\n    gdf = gdf.explode(ignore_index=True)\n\n    return (\n        gdf.reset_index(level=0, names=\"label\")\n        .drop_duplicates(\"geometry\")\n        .set_geometry(\"geometry\")\n    )\n</code></pre>"},{"location":"reference/spatial_contexts/iface_context_ref/#cellseg_gsontools.spatial_context.InterfaceContext.context2weights","title":"<code>context2weights(key)</code>","text":"<p>Merge the networks of type <code>key</code> into one spatial weights obj.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the context dictionary that contains the spatial weights to be merged. One of \"roi_network\", \"full_network\", \"interface_network\", \"border_network\"</p> required <p>Returns:</p> Type Description <code>W</code> <p>libpysal.weights.W: A spatial weights object containing all the distinct networks in the context.</p> Source code in <code>cellseg_gsontools/spatial_context/interface.py</code> <pre><code>def context2weights(self, key: str) -&gt; W:\n    \"\"\"Merge the networks of type `key` into one spatial weights obj.\n\n    Parameters:\n        key (str):\n            The key of the context dictionary that contains the spatial\n            weights to be merged. One of \"roi_network\", \"full_network\",\n            \"interface_network\", \"border_network\"\n\n    Returns:\n        libpysal.weights.W:\n            A spatial weights object containing all the distinct networks\n            in the context.\n    \"\"\"\n    allowed = (\"roi_network\", \"full_network\", \"interface_network\", \"border_network\")\n    if key not in allowed:\n        raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n    cxs = list(self.context.items())\n    wout = W({0: [0]})\n    for _, c in cxs:\n        w = c[key]\n        if isinstance(w, W):\n            wout = w_union(wout, w, silence_warnings=True)\n\n    # remove self loops\n    wout = w_subset(wout, list(wout.neighbors.keys())[1:], silence_warnings=True)\n\n    return wout\n</code></pre>"},{"location":"reference/spatial_contexts/iface_context_ref/#cellseg_gsontools.spatial_context.InterfaceContext.plot","title":"<code>plot(key, network_key=None, grid_key=None, show_legends=True, color=None, figsize=(12, 12), edge_kws=None, **kwargs)</code>","text":"<p>Plot the context with areas, cells, and interface areas highlighted.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the context dictionary that contains the data to be plotted. One of \"roi_area\",</p> required <code>network_key</code> <code>str</code> <p>The key of the context dictionary that contains the spatial weights to be plotted. One of \"roi_network\"</p> <code>None</code> <code>grid_key</code> <code>str</code> <p>The key of the context dictionary that contains the grid to be plotted. One of \"roi_grid\"</p> <code>None</code> <code>show_legends</code> <code>bool</code> <p>Flag, whether to include legends for each in the plot.</p> <code>True</code> <code>color</code> <code>str</code> <p>A color for the interfaces or rois, Ignored if <code>show_legends=True</code>.</p> <code>None</code> <code>figsize</code> <code>Tuple[int, int]</code> <p>Size of the figure.</p> <code>(12, 12)</code> <code>**kwargs</code> <code>Dict[str, Any])]</code> <p>Extra keyword arguments passed to the <code>plot</code> method of the geodataframes.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>AxesSubplot</p> <p>Examples:</p> <p>Plot the tumor-stroma areas.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.spatial_context import InterfaceContext\n&gt;&gt;&gt; cells = read_gdf(\"cells.feather\")\n&gt;&gt;&gt; areas = read_gdf(\"areas.feather\")\n&gt;&gt;&gt; ts_iface = InterfaceContext(\n...     area_gdf=areas,\n...     cell_gdf=cells,\n...     top_labels=\"tumor\",\n...     bottom_labels=\"stroma\",\n... )\n&gt;&gt;&gt; ts_iface.fit(verbose=False)\n&gt;&gt;&gt; ts_iface.plot(\"interface_area\", show_legends=True)\n&lt;AxesSubplot: &gt;\n</code></pre> Source code in <code>cellseg_gsontools/spatial_context/interface.py</code> <pre><code>def plot(\n    self,\n    key: str,\n    network_key: str = None,\n    grid_key: str = None,\n    show_legends: bool = True,\n    color: str = None,\n    figsize: Tuple[int, int] = (12, 12),\n    edge_kws: Dict[str, Any] = None,\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"Plot the context with areas, cells, and interface areas highlighted.\n\n    Parameters:\n        key (str):\n            The key of the context dictionary that contains the data to be plotted.\n            One of \"roi_area\",\n        network_key (str):\n            The key of the context dictionary that contains the spatial weights to\n            be plotted. One of \"roi_network\"\n        grid_key (str):\n            The key of the context dictionary that contains the grid to be plotted.\n            One of \"roi_grid\"\n        show_legends (bool):\n            Flag, whether to include legends for each in the plot.\n        color (str):\n            A color for the interfaces or rois, Ignored if `show_legends=True`.\n        figsize (Tuple[int, int]):\n            Size of the figure.\n        **kwargs (Dict[str, Any])]):\n            Extra keyword arguments passed to the `plot` method of the\n            geodataframes.\n\n    Returns:\n        AxesSubplot\n\n    Examples:\n        Plot the tumor-stroma areas.\n\n        &gt;&gt;&gt; from cellseg_gsontools.spatial_context import InterfaceContext\n        &gt;&gt;&gt; cells = read_gdf(\"cells.feather\")\n        &gt;&gt;&gt; areas = read_gdf(\"areas.feather\")\n        &gt;&gt;&gt; ts_iface = InterfaceContext(\n        ...     area_gdf=areas,\n        ...     cell_gdf=cells,\n        ...     top_labels=\"tumor\",\n        ...     bottom_labels=\"stroma\",\n        ... )\n        &gt;&gt;&gt; ts_iface.fit(verbose=False)\n        &gt;&gt;&gt; ts_iface.plot(\"interface_area\", show_legends=True)\n        &lt;AxesSubplot: &gt;\n    \"\"\"\n    allowed = (\"roi_area\", \"interface_area\")\n    if key not in allowed:\n        raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n    context_gdf = self.context2gdf(key)\n\n    grid_gdf = None\n    if grid_key is not None:\n        grid_gdf = self.context2gdf(grid_key)\n\n    network_gdf = None\n    if network_key is not None:\n        edge_kws = edge_kws or {}\n        w = self.context2weights(network_key)\n        network_gdf = weights2gdf(self.cell_gdf, w)\n\n    return plot_all(\n        cell_gdf=self.cell_gdf.set_geometry(\"geometry\"),\n        area_gdf=self.area_gdf.set_geometry(\"geometry\"),\n        context_gdf=context_gdf,\n        grid_gdf=grid_gdf,\n        network_gdf=network_gdf,\n        show_legends=show_legends,\n        color=color,\n        figsize=figsize,\n        edge_kws=edge_kws,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/spatial_contexts/point_cluster_context_ref/","title":"PointClusterContext","text":""},{"location":"reference/spatial_contexts/point_cluster_context_ref/#cellseg_gsontools.spatial_context.PointClusterContext","title":"<code>cellseg_gsontools.spatial_context.PointClusterContext</code>","text":"<p>             Bases: <code>WithinContext</code></p> <p>Handle &amp; extract dense point clusters from <code>cell_gdf</code>.</p> <p>Point-clusters are dense regions of points. This context is useful when you want to extract dense regions of points of type <code>label</code> from <code>cell_gdf</code> such as immune-cell clusters. The clusters are extracted using one of the clustering methods: \"dbscan\", \"adbscan\", \"optics\" after which the clusters are converted to polygons/areas using alpha-shapes.</p> Note <p>This class inherits from <code>WithinContext</code> and thus has all the methods and attributes of that class.</p> Note <p><code>cell_gdf</code> has to contain a column named 'class_name'</p> <p>Parameters:</p> Name Type Description Default <code>cell_gdf</code> <code>GeoDataFrame</code> <p>A geo dataframe that contains small cellular objects that are enclosed by larger tissue areas in <code>area_gdf</code>.</p> required <code>labels</code> <code>Union[Tuple[str, ...], str]</code> <p>The class name(s) of the areas of interest. The objects within these areas are extracted. E.g. \"cancer\" or \"stroma\".</p> required <code>cluster_method</code> <code>str</code> <p>The clustering method used to extract the point-clusters. One of: \"dbscan\", \"adbscan\", \"optics\"</p> <code>'dbscan'</code> <code>min_area_size</code> <code>float or str</code> <p>The minimum area of the objects that are kept. All the objects in the <code>area_gdf</code> that are larger are kept than <code>min_area_size</code>. If None, all the areas are kept. Defaults to None.</p> <code>None</code> <code>graph_type</code> <code>str</code> <p>The type of the graph to be fitted to the cells inside interfaces. One of: \"delaunay\", \"distband\", \"relative_nhood\", \"knn\".</p> <code>'distband'</code> <code>dist_thresh</code> <code>float</code> <p>Distance threshold for the length of the network links.</p> <code>100.0</code> <code>grid_type</code> <code>str</code> <p>The type of the grid to be fitted on the roi areas. One of: \"square\", \"hex\".</p> <code>'square'</code> <code>patch_size</code> <code>Tuple[int, int]</code> <p>The size of the grid patches to be fitted on the context. This is used when <code>grid_type='square'</code>.</p> <code>(256, 256)</code> <code>stride</code> <code>Tuple[int, int]</code> <p>The stride of the sliding window for grid patching. This is used when <code>grid_type='square'</code>.</p> <code>(256, 256)</code> <code>pad</code> <code>int</code> <p>The padding to add to the bounding box on the grid. This is used when <code>grid_type='square'</code>.</p> <code>None</code> <code>resolution</code> <code>int</code> <p>The resolution of the h3 hex grid. This is used when <code>grid_type='hex'</code>.</p> <code>9</code> <code>predicate</code> <code>str</code> <p>The predicate to use for the spatial join when extracting the ROI cells. See <code>geopandas.tools.sjoin</code></p> <code>'intersects'</code> <code>silence_warnings</code> <code>bool</code> <p>Flag, whether to silence all the warnings.</p> <code>True</code> <code>parallel</code> <code>bool</code> <p>Flag, whether to parallelize the context fitting. If <code>backend == \"geopandas\"</code>, the parallelization is implemented with <code>pandarallel</code> package. If <code>backend == \"spatialpandas\"</code>, or <code>backend == \"dask-geopandas\"</code> the parallelization is implemented  with Dask library.</p> <code>False</code> <code>num_processes</code> <code>int</code> <p>The number of processes to use when parallel=True. If -1, this will use all the available cores.</p> <code>-1</code> <code>backend</code> <code>str</code> <p>The backend to use for the spatial context. One of \"geopandas\", \"spatialpandas\" \"dask-geopandas\". \"spatialpandas\" or \"dask-geopandas\" is recommended for gdfs that may contain huge polygons.</p> <code>'geopandas'</code> <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Arbitrary key-word arguments passed to the clustering methods.</p> <code>{}</code> <p>Attributes:</p> Name Type Description <code>context</code> <code>Dict[int, Dict[str, Union[GeoDataFrame, W]]]</code> <p>A nested dict that contains dicts for each of the distinct clusters. The keys of the outer dict are the indices of these areas. The inner dicts contain the keys:</p> <ul> <li><code>roi_area</code>- <code>gpd.GeoDataFrame</code>:  the alpha shape of a cell cluster.</li> <li><code>roi_cells</code> - <code>gpd.GeoDataFrame</code>: the cells that are contained         inside the <code>roi_area</code>.</li> <li><code>roi_network</code> - <code>libpysal.weights.W</code>: spatial weights network of         the cells inside the <code>roi_area</code>. This can be used to extract         graph features inside the clusters.</li> <li><code>roi_grid</code> - <code>gpd.GeoDataFrame</code>: of the grid fitted on the <code>roi_area</code>.         This can be used to extract grid features inside the clusters.</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>cell_gdf</code> don't contain 'class_name' column.</p> <p>Examples:</p> <p>Create a point cluster context and plot the cells inside one cluster area.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.spatial_context import ClusterContext\n&gt;&gt;&gt; cell_gdf = pre_proc_gdf(read_gdf(\"cells.json\"))\n&gt;&gt;&gt; cluster_context = PointClusterContext(\n...     cell_gdf=cell_gdf,\n...     labels=[\"inflammatory\"],\n...     cluster_method=\"adbscan\",\n...     silence_warnings=True,\n... )\n&gt;&gt;&gt; cluster_context.fit(parallel=False, fit_graph=False)\n&gt;&gt;&gt; cluster_context.plot(\"roi_area\", show_legends=True)\n&lt;AxesSubplot: &gt;\n</code></pre> Source code in <code>cellseg_gsontools/spatial_context/point_cluster.py</code> <pre><code>class PointClusterContext(WithinContext):\n    \"\"\"Handle &amp; extract dense point clusters from `cell_gdf`.\n\n    Point-clusters are dense regions of points. This context is useful when you\n    want to extract dense regions of points of type `label` from `cell_gdf` such as\n    immune-cell clusters. The clusters are extracted using one of the clustering\n    methods: \"dbscan\", \"adbscan\", \"optics\" after which the clusters are converted\n    to polygons/areas using alpha-shapes.\n\n    Note:\n        This class inherits from `WithinContext` and thus has all the methods\n        and attributes of that class.\n\n    Note:\n        `cell_gdf` has to contain a column named 'class_name'\n\n    Parameters:\n        cell_gdf (gpd.GeoDataFrame):\n            A geo dataframe that contains small cellular objects that are\n            enclosed by larger tissue areas in `area_gdf`.\n        labels (Union[Tuple[str, ...], str]):\n            The class name(s) of the areas of interest. The objects within\n            these areas are extracted. E.g. \"cancer\" or \"stroma\".\n        cluster_method (str):\n            The clustering method used to extract the point-clusters. One of:\n            \"dbscan\", \"adbscan\", \"optics\"\n        min_area_size (float or str, optional):\n            The minimum area of the objects that are kept. All the objects in\n            the `area_gdf` that are larger are kept than `min_area_size`. If\n            None, all the areas are kept. Defaults to None.\n        graph_type (str):\n            The type of the graph to be fitted to the cells inside interfaces.\n            One of: \"delaunay\", \"distband\", \"relative_nhood\", \"knn\".\n        dist_thresh (float):\n            Distance threshold for the length of the network links.\n        grid_type (str):\n            The type of the grid to be fitted on the roi areas. One of:\n            \"square\", \"hex\".\n        patch_size (Tuple[int, int]):\n            The size of the grid patches to be fitted on the context. This is\n            used when `grid_type='square'`.\n        stride (Tuple[int, int]):\n            The stride of the sliding window for grid patching. This is used\n            when `grid_type='square'`.\n        pad (int):\n            The padding to add to the bounding box on the grid. This is used\n            when `grid_type='square'`.\n        resolution (int):\n            The resolution of the h3 hex grid. This is used when\n            `grid_type='hex'`.\n        predicate (str):\n            The predicate to use for the spatial join when extracting the ROI\n            cells. See `geopandas.tools.sjoin`\n        silence_warnings (bool):\n            Flag, whether to silence all the warnings.\n        parallel (bool):\n            Flag, whether to parallelize the context fitting. If\n            `backend == \"geopandas\"`, the parallelization is implemented with\n            `pandarallel` package. If `backend == \"spatialpandas\"`, or\n            `backend == \"dask-geopandas\"` the parallelization is implemented\n             with Dask library.\n        num_processes (int):\n            The number of processes to use when parallel=True. If -1, this\n            will use all the available cores.\n        backend (str):\n            The backend to use for the spatial context. One of \"geopandas\",\n            \"spatialpandas\" \"dask-geopandas\". \"spatialpandas\" or\n            \"dask-geopandas\" is recommended for gdfs that may contain huge\n            polygons.\n        **kwargs (Dict[str, Any]):\n            Arbitrary key-word arguments passed to the clustering methods.\n\n    Attributes:\n        context (Dict[int, Dict[str, Union[gpd.GeoDataFrame, libpysal.weights.W]]]):\n            A nested dict that contains dicts for each of the distinct clusters.\n            The keys of the outer dict are the indices of these areas. The inner dicts\n            contain the keys:\n\n            - `roi_area`- `gpd.GeoDataFrame`:  the alpha shape of a cell cluster.\n            - `roi_cells` - `gpd.GeoDataFrame`: the cells that are contained\n                    inside the `roi_area`.\n            - `roi_network` - `libpysal.weights.W`: spatial weights network of\n                    the cells inside the `roi_area`. This can be used to extract\n                    graph features inside the clusters.\n            - `roi_grid` - `gpd.GeoDataFrame`: of the grid fitted on the `roi_area`.\n                    This can be used to extract grid features inside the clusters.\n\n    Raises:\n        ValueError:\n            if `cell_gdf` don't contain 'class_name' column.\n\n    Examples:\n        Create a point cluster context and plot the cells inside one cluster area.\n        &gt;&gt;&gt; from cellseg_gsontools.spatial_context import ClusterContext\n        &gt;&gt;&gt; cell_gdf = pre_proc_gdf(read_gdf(\"cells.json\"))\n        &gt;&gt;&gt; cluster_context = PointClusterContext(\n        ...     cell_gdf=cell_gdf,\n        ...     labels=[\"inflammatory\"],\n        ...     cluster_method=\"adbscan\",\n        ...     silence_warnings=True,\n        ... )\n        &gt;&gt;&gt; cluster_context.fit(parallel=False, fit_graph=False)\n        &gt;&gt;&gt; cluster_context.plot(\"roi_area\", show_legends=True)\n        &lt;AxesSubplot: &gt;\n    \"\"\"\n\n    def __init__(\n        self,\n        cell_gdf: gpd.GeoDataFrame,\n        labels: Union[Tuple[str, ...], str],\n        cluster_method: str = \"dbscan\",\n        min_area_size: Union[float, str] = None,\n        graph_type: str = \"distband\",\n        dist_thresh: float = 100.0,\n        grid_type: str = \"square\",\n        patch_size: Tuple[int, int] = (256, 256),\n        stride: Tuple[int, int] = (256, 256),\n        pad: int = None,\n        resolution: int = 9,\n        predicate: str = \"intersects\",\n        silence_warnings: bool = True,\n        n_jobs: int = -1,\n        parallel: bool = False,\n        num_processes: int = -1,\n        backend: str = \"geopandas\",\n        **kwargs,\n    ) -&gt; None:\n        cell_gdf.set_crs(epsg=4328, inplace=True, allow_override=True)\n        area_gdf = self.run_clustering(\n            cell_gdf, labels, cluster_method, n_jobs, **kwargs\n        )\n\n        if isinstance(labels, (list, tuple)):\n            if len(labels) == 1:\n                labels = labels[0]\n            else:\n                labels = \"-\".join(labels)\n\n        super().__init__(\n            area_gdf=area_gdf,\n            cell_gdf=cell_gdf,\n            labels=labels,\n            min_area_size=min_area_size,\n            dist_thresh=dist_thresh,\n            graph_type=graph_type,\n            patch_size=patch_size,\n            stride=stride,\n            pad=pad,\n            predicate=predicate,\n            silence_warnings=silence_warnings,\n            parallel=parallel,\n            num_processes=num_processes,\n            backend=backend,\n            grid_type=grid_type,\n            resolution=resolution,\n        )\n\n    def run_clustering(\n        self,\n        cell_gdf: gpd.GeoDataFrame,\n        labels: Union[Tuple[str, ...], str],\n        cluster_method: str,\n        n_jobs: int,\n        **kwargs,\n    ) -&gt; gpd.GeoDataFrame:\n        \"\"\"Run clustering on the cells and convert the clusters to areas.\n\n        Parameters:\n            cell_gdf (gpd.GeoDataFrame):\n                A geo dataframe that contains the cell/nuclei objects.\n            labels (Union[Tuple[str, ...], str]):\n                The class name(s of the objects of interest. E.g. \"cancer\", \"immune\".\n            cluster_method (str):\n                The clustering method used to extract the point-clusters. One of:\n                \"dbscan\", \"adbscan\", \"optics\"\n            n_jobs (int):\n                The number of processes to use in clustering.\n            **kwargs (Dict[str, Any]):\n                Arbitrary key-word arguments passed to the clustering methods.\n\n        Returns:\n            gpd.GeoDataFrame:\n                A gdf containing the areas of the clusters.\n        \"\"\"\n        # cluster the cells\n        if isinstance(labels, str):\n            # a little faster than .isin\n            cells = cell_gdf[cell_gdf[\"class_name\"] == labels].copy()\n        else:\n            if len(labels) == 1:\n                cells = cell_gdf[cell_gdf[\"class_name\"] == labels[0]].copy()\n            else:\n                cells = cell_gdf[cell_gdf[\"class_name\"].isin(labels)].copy()\n\n        cells = cluster_points(cells, method=cluster_method, n_jobs=n_jobs, **kwargs)\n\n        # convert the clusters to areas with alpha-shapes\n        labs = cells[\"labels\"].unique()\n        area_data = {\"geometry\": []}\n        for lab in labs:\n            if lab == str(-1) or lab == int(-1):\n                continue\n\n            if isinstance(lab, str):\n                lab = str(lab)\n\n            c = cells[cells[\"labels\"] == lab]\n            coords = np.vstack([c.centroid.x, c.centroid.y]).T\n            alpha_shape = alpha_shape_auto(coords, step=15)\n            area_data[\"geometry\"].append(alpha_shape.buffer(10.0).buffer(-20.0))\n\n        area_gdf = gpd.GeoDataFrame(area_data)\n\n        if isinstance(labels, (list, tuple)):\n            if len(labels) == 1:\n                labels = labels[0]\n            else:\n                labels = \"-\".join(labels)\n\n        area_gdf[\"class_name\"] = [labels] * len(area_gdf)\n\n        return area_gdf\n</code></pre>"},{"location":"reference/spatial_contexts/point_cluster_context_ref/#cellseg_gsontools.spatial_context.PointClusterContext.run_clustering","title":"<code>run_clustering(cell_gdf, labels, cluster_method, n_jobs, **kwargs)</code>","text":"<p>Run clustering on the cells and convert the clusters to areas.</p> <p>Parameters:</p> Name Type Description Default <code>cell_gdf</code> <code>GeoDataFrame</code> <p>A geo dataframe that contains the cell/nuclei objects.</p> required <code>labels</code> <code>Union[Tuple[str, ...], str]</code> <p>The class name(s of the objects of interest. E.g. \"cancer\", \"immune\".</p> required <code>cluster_method</code> <code>str</code> <p>The clustering method used to extract the point-clusters. One of: \"dbscan\", \"adbscan\", \"optics\"</p> required <code>n_jobs</code> <code>int</code> <p>The number of processes to use in clustering.</p> required <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Arbitrary key-word arguments passed to the clustering methods.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: A gdf containing the areas of the clusters.</p> Source code in <code>cellseg_gsontools/spatial_context/point_cluster.py</code> <pre><code>def run_clustering(\n    self,\n    cell_gdf: gpd.GeoDataFrame,\n    labels: Union[Tuple[str, ...], str],\n    cluster_method: str,\n    n_jobs: int,\n    **kwargs,\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Run clustering on the cells and convert the clusters to areas.\n\n    Parameters:\n        cell_gdf (gpd.GeoDataFrame):\n            A geo dataframe that contains the cell/nuclei objects.\n        labels (Union[Tuple[str, ...], str]):\n            The class name(s of the objects of interest. E.g. \"cancer\", \"immune\".\n        cluster_method (str):\n            The clustering method used to extract the point-clusters. One of:\n            \"dbscan\", \"adbscan\", \"optics\"\n        n_jobs (int):\n            The number of processes to use in clustering.\n        **kwargs (Dict[str, Any]):\n            Arbitrary key-word arguments passed to the clustering methods.\n\n    Returns:\n        gpd.GeoDataFrame:\n            A gdf containing the areas of the clusters.\n    \"\"\"\n    # cluster the cells\n    if isinstance(labels, str):\n        # a little faster than .isin\n        cells = cell_gdf[cell_gdf[\"class_name\"] == labels].copy()\n    else:\n        if len(labels) == 1:\n            cells = cell_gdf[cell_gdf[\"class_name\"] == labels[0]].copy()\n        else:\n            cells = cell_gdf[cell_gdf[\"class_name\"].isin(labels)].copy()\n\n    cells = cluster_points(cells, method=cluster_method, n_jobs=n_jobs, **kwargs)\n\n    # convert the clusters to areas with alpha-shapes\n    labs = cells[\"labels\"].unique()\n    area_data = {\"geometry\": []}\n    for lab in labs:\n        if lab == str(-1) or lab == int(-1):\n            continue\n\n        if isinstance(lab, str):\n            lab = str(lab)\n\n        c = cells[cells[\"labels\"] == lab]\n        coords = np.vstack([c.centroid.x, c.centroid.y]).T\n        alpha_shape = alpha_shape_auto(coords, step=15)\n        area_data[\"geometry\"].append(alpha_shape.buffer(10.0).buffer(-20.0))\n\n    area_gdf = gpd.GeoDataFrame(area_data)\n\n    if isinstance(labels, (list, tuple)):\n        if len(labels) == 1:\n            labels = labels[0]\n        else:\n            labels = \"-\".join(labels)\n\n    area_gdf[\"class_name\"] = [labels] * len(area_gdf)\n\n    return area_gdf\n</code></pre>"},{"location":"reference/spatial_contexts/within_context_ref/","title":"WithinContext","text":""},{"location":"reference/spatial_contexts/within_context_ref/#cellseg_gsontools.spatial_context.WithinContext","title":"<code>cellseg_gsontools.spatial_context.WithinContext</code>","text":"<p>Handle &amp; extract cells from <code>cell_gdf</code> within the ROIs of <code>area_gdf</code>.</p> Note <p><code>area_gdf</code> and <code>cell_gdf</code> have to contain a column named 'class_name'</p> <p>Parameters:</p> Name Type Description Default <code>area_gdf</code> <code>GeoDataFrame</code> <p>A geo dataframe that contains large tissue area polygons enclosing the smaller cellular objects in <code>cell_gdf</code>.</p> required <code>cell_gdf</code> <code>GeoDataFrame</code> <p>A geo dataframe that contains small cellular objects that are enclosed by larger tissue areas in <code>area_gdf</code>.</p> required <code>labels</code> <code>Union[Tuple[str, ...], str]</code> <p>The class name(s) of the areas of interest. The objects within these areas are extracted. E.g. \"cancer\" or \"stroma\".</p> required <code>min_area_size</code> <code>float or str</code> <p>The minimum area of the objects that are kept. All the objects in the <code>area_gdf</code> that are larger are kept than <code>min_area_size</code>. If None, all the areas are kept. Defaults to None.</p> <code>None</code> <code>graph_type</code> <code>str</code> <p>The type of the graph to be fitted to the cells inside interfaces. One of: \"delaunay\", \"distband\", \"relative_nhood\", \"knn\".</p> <code>'distband'</code> <code>dist_thresh</code> <code>float</code> <p>Distance threshold for the length of the network links.</p> <code>100.0</code> <code>grid_type</code> <code>str</code> <p>The type of the grid to be fitted on the roi areas. One of: \"square\", \"hex\".</p> <code>'square'</code> <code>patch_size</code> <code>Tuple[int, int]</code> <p>The size of the grid patches to be fitted on the context. This is used when <code>grid_type='square'</code>.</p> <code>(256, 256)</code> <code>stride</code> <code>Tuple[int, int]</code> <p>The stride of the sliding window for grid patching. This is used when <code>grid_type='square'</code>.</p> <code>(256, 256)</code> <code>pad</code> <code>int</code> <p>The padding to add to the bounding box on the grid. This is used when <code>grid_type='square'</code>.</p> <code>None</code> <code>resolution</code> <code>int</code> <p>The resolution of the h3 hex grid. This is used when <code>grid_type='hex'</code>.</p> <code>9</code> <code>predicate</code> <code>str</code> <p>The predicate to use for the spatial join when extracting the ROI cells. See <code>geopandas.tools.sjoin</code></p> <code>'intersects'</code> <code>silence_warnings</code> <code>bool</code> <p>Flag, whether to silence all the warnings.</p> <code>True</code> <code>parallel</code> <code>bool</code> <p>Flag, whether to parallelize the context fitting. If <code>backend == \"geopandas\"</code>, the parallelization is implemented with <code>pandarallel</code> package. If <code>backend == \"spatialpandas\"</code>, or <code>backend == \"dask-geopandas\"</code> the parallelization is implemented  with Dask library.</p> <code>False</code> <code>num_processes</code> <code>int</code> <p>The number of processes to use when parallel=True. If -1, this will use all the available cores.</p> <code>-1</code> <code>backend</code> <code>str</code> <p>The backend to use for the spatial context. One of \"geopandas\", \"spatialpandas\" \"dask-geopandas\". \"spatialpandas\" or \"dask-geopandas\" is recommended for gdfs that may contain huge polygons.</p> <code>'geopandas'</code> <p>Attributes:</p> Name Type Description <code>context</code> <code>Dict[int, Dict[str, Union[GeoDataFrame, W]]]</code> <p>A nested dict that contains dicts for each of the distinct ROIs of type <code>label</code>. The keys of the outer dict are the indices of these areas. The inner dicts contain the keys:</p> <ul> <li><code>roi_area</code>- <code>gpd.GeoDataFrame</code>: the roi area. Roi area is the         tissue area of type <code>label</code>.</li> <li><code>roi_cells</code> - <code>gpd.GeoDataFrame</code>: the cells that are contained         inside the <code>roi_area</code>.</li> <li><code>roi_network</code> - <code>libpysal.weights.W</code>: spatial weights network of         the cells inside the <code>roi_area</code>. This can be used to extract         graph features inside the roi_.</li> <li><code>roi_grid</code> - <code>gpd.GeoDataFrame</code>: of the grid fitted on the <code>roi_area</code>.         This can be used to extract grid features inside the <code>roi_area</code>.</li> </ul> <p>Raises:</p> Type Description <code>ValueError</code> <p>if <code>area_gdf</code> or <code>cell_gdf</code> don't contain 'class_name' column.</p> Source code in <code>cellseg_gsontools/spatial_context/within.py</code> <pre><code>class WithinContext:\n    \"\"\"Handle &amp; extract cells from `cell_gdf` within the ROIs of `area_gdf`.\n\n    Note:\n        `area_gdf` and `cell_gdf` have to contain a column named 'class_name'\n\n    Parameters:\n        area_gdf (gpd.GeoDataFrame):\n            A geo dataframe that contains large tissue area polygons enclosing\n            the smaller cellular objects in `cell_gdf`.\n        cell_gdf (gpd.GeoDataFrame):\n            A geo dataframe that contains small cellular objects that are\n            enclosed by larger tissue areas in `area_gdf`.\n        labels (Union[Tuple[str, ...], str]):\n            The class name(s) of the areas of interest. The objects within\n            these areas are extracted. E.g. \"cancer\" or \"stroma\".\n        min_area_size (float or str, optional):\n            The minimum area of the objects that are kept. All the objects in\n            the `area_gdf` that are larger are kept than `min_area_size`. If\n            None, all the areas are kept. Defaults to None.\n        graph_type (str):\n            The type of the graph to be fitted to the cells inside interfaces.\n            One of: \"delaunay\", \"distband\", \"relative_nhood\", \"knn\".\n        dist_thresh (float):\n            Distance threshold for the length of the network links.\n        grid_type (str):\n            The type of the grid to be fitted on the roi areas. One of:\n            \"square\", \"hex\".\n        patch_size (Tuple[int, int]):\n            The size of the grid patches to be fitted on the context. This is\n            used when `grid_type='square'`.\n        stride (Tuple[int, int]):\n            The stride of the sliding window for grid patching. This is used\n            when `grid_type='square'`.\n        pad (int):\n            The padding to add to the bounding box on the grid. This is used\n            when `grid_type='square'`.\n        resolution (int):\n            The resolution of the h3 hex grid. This is used when\n            `grid_type='hex'`.\n        predicate (str):\n            The predicate to use for the spatial join when extracting the ROI\n            cells. See `geopandas.tools.sjoin`\n        silence_warnings (bool):\n            Flag, whether to silence all the warnings.\n        parallel (bool):\n            Flag, whether to parallelize the context fitting. If\n            `backend == \"geopandas\"`, the parallelization is implemented with\n            `pandarallel` package. If `backend == \"spatialpandas\"`, or\n            `backend == \"dask-geopandas\"` the parallelization is implemented\n             with Dask library.\n        num_processes (int):\n            The number of processes to use when parallel=True. If -1, this\n            will use all the available cores.\n        backend (str):\n            The backend to use for the spatial context. One of \"geopandas\",\n            \"spatialpandas\" \"dask-geopandas\". \"spatialpandas\" or\n            \"dask-geopandas\" is recommended for gdfs that may contain huge\n            polygons.\n\n    Attributes:\n        context (Dict[int, Dict[str, Union[gpd.GeoDataFrame, libpysal.weights.W]]]):\n            A nested dict that contains dicts for each of the distinct ROIs\n            of type `label`. The keys of the outer dict are the indices of\n            these areas. The inner dicts contain the keys:\n\n            - `roi_area`- `gpd.GeoDataFrame`: the roi area. Roi area is the\n                    tissue area of type `label`.\n            - `roi_cells` - `gpd.GeoDataFrame`: the cells that are contained\n                    inside the `roi_area`.\n            - `roi_network` - `libpysal.weights.W`: spatial weights network of\n                    the cells inside the `roi_area`. This can be used to extract\n                    graph features inside the roi_.\n            - `roi_grid` - `gpd.GeoDataFrame`: of the grid fitted on the `roi_area`.\n                    This can be used to extract grid features inside the `roi_area`.\n\n    Raises:\n        ValueError:\n            if `area_gdf` or `cell_gdf` don't contain 'class_name' column.\n    \"\"\"\n\n    def __init__(\n        self,\n        area_gdf: gpd.GeoDataFrame,\n        cell_gdf: gpd.GeoDataFrame,\n        labels: Union[Tuple[str, ...], str],\n        min_area_size: Union[float, str] = None,\n        graph_type: str = \"distband\",\n        dist_thresh: float = 100.0,\n        grid_type: str = \"square\",\n        patch_size: Tuple[int, int] = (256, 256),\n        stride: Tuple[int, int] = (256, 256),\n        pad: int = None,\n        resolution: int = 9,\n        predicate: str = \"intersects\",\n        silence_warnings: bool = True,\n        parallel: bool = False,\n        num_processes: int = -1,\n        backend: str = \"geopandas\",\n    ) -&gt; None:\n        self.backend_name = backend\n        if backend == \"geopandas\":\n            self.backend = _SpatialContextGP()\n        # elif backend == \"spatialpandas\":\n        #     self.backend = _SpatialContextSP()\n        # elif backend == \"dask-geopandas\":\n        #     self.backend = _SpatialContextDGP()\n        else:\n            raise ValueError(\n                f\"Unknown backend: {backend}. \"\n                \"Allowed: 'spatialpandas', 'geopandas', 'dask-geopandas'\"\n            )\n\n        # check if the 'class_name' column is present\n        self.backend.check_columns(area_gdf, cell_gdf)\n\n        # set up the attributes\n        self.min_area_size = min_area_size\n        self.dist_thresh = dist_thresh\n        self.graph_type = graph_type\n        self.patch_size = patch_size\n        self.stride = stride\n        self.pad = pad\n        self.silence_warnings = silence_warnings\n        self.labels = labels\n        self.predicate = predicate\n        self.parallel = parallel\n        self.num_processes = num_processes\n        self.grid_type = grid_type\n        self.resolution = resolution\n\n        # set to geocentric cartesian crs. (unit is metre by default)\n        # helps to avoid warning flooding\n        self.cell_gdf = set_uid(cell_gdf, id_col=\"global_id\")\n        self.cell_gdf.set_crs(epsg=4328, inplace=True, allow_override=True)\n\n        # cache the full area gdf for plotting\n        self.area_gdf = area_gdf\n        self.area_gdf.set_crs(epsg=4328, inplace=True, allow_override=True)\n\n        # filter small areas and tissue types of interest for the tissue gdf\n        self.context_area = self.backend.filter_areas(\n            self.area_gdf, labels, min_area_size\n        )\n        self.context_area = set_uid(self.context_area, id_col=\"global_id\")\n\n        # set up cpu count\n        if parallel:\n            self.cpus = (\n                psutil.cpu_count(logical=False)\n                if self.num_processes == -1 or self.num_processes is None\n                else self.num_processes\n            )\n        else:\n            self.cpus = 1\n\n        # convert the gdfs to the backend format\n        self.context_area = self.backend.convert_area_gdf(self.context_area)\n\n        self.cell_gdf = self.backend.convert_cell_gdf(\n            self.cell_gdf, parallel=parallel, n_partitions=self.cpus\n        )\n\n    def __getattr__(self, name):\n        \"\"\"Get attribute.\"\"\"\n        return self.backend.__getattribute__(name)\n\n    def fit(\n        self,\n        verbose: bool = True,\n        fit_graph: bool = True,\n        fit_grid: bool = True,\n    ) -&gt; None:\n        \"\"\"Fit the context.\n\n        This sets the `self.context` attribute.\n\n        Parameters:\n            verbose (bool):\n                Flag, whether to use tqdm pbar when creating the interfaces.\n            fit_graph (bool):\n                Flag, whether to fit the spatial weights networks for the\n                context.\n            fit_grid (bool):\n                Flag, whether to fit the a grid on the contextes.\n\n        Examples:\n            Define a within context and plot the cells inside a specific ROI.\n\n            &gt;&gt;&gt; from cellseg_gsontools.spatial_context import WithinContext\n            &gt;&gt;&gt; area_gdf = read_gdf(\"area.json\")\n            &gt;&gt;&gt; cell_gdf = read_gdf(\"cells.json\")\n            &gt;&gt;&gt; within_context = WithinContext(\n            ...     area_gdf=area_gdf,\n            ...     cell_gdf=cell_gdf,\n            ...     labels=[\"area_cin\"],\n            ...     silence_warnings=True,\n            ...     min_area_size=100000.0,\n            ... )\n            &gt;&gt;&gt; within_context.fit()\n            &gt;&gt;&gt; within_context.plot(\"roi_area\", show_legends=True)\n            &lt;AxesSubplot: &gt;\n        \"\"\"\n        get_context_func = partial(\n            WithinContext._get_context,\n            backend=self.backend,\n            context_area=self.context_area,\n            cell_gdf=self.cell_gdf,\n            fit_network=fit_graph,\n            fit_grid=fit_grid,\n            predicate=self.predicate,\n            silence_warnings=self.silence_warnings,\n            graph_type=self.graph_type,\n            grid_type=self.grid_type,\n            resolution=self.resolution,\n            dist_thresh=self.dist_thresh,\n            patch_size=self.patch_size,\n            stride=self.stride,\n            pad=self.pad,\n            parallel=self.parallel,\n            num_processes=self.cpus,\n        )\n\n        if self.backend_name == \"geopandas\" and self.parallel:\n            # run in parallel\n            context_dict = gdf_apply(\n                self.context_area,\n                func=get_context_func,\n                columns=[\"global_id\"],\n                parallel=True,\n                pbar=verbose,\n                num_processes=self.cpus,\n            ).to_dict()\n        else:\n            context_dict = {}\n            pbar = (\n                tqdm(self.context_area.index, total=self.context_area.shape[0])\n                if verbose\n                else self.context_area.index\n            )\n\n            for ix in pbar:\n                if verbose:\n                    pbar.set_description(f\"Processing roi area: {ix}\")\n\n                if self.backend_name == \"dask-geopandas\" and self.parallel:\n                    get_context_func = partial(\n                        get_context_func, cell_gdf_dgp=self.backend.cell_gdf_dgp\n                    )\n\n                context_dict[ix] = get_context_func(ix=ix)\n\n        self.context = context_dict\n\n    @staticmethod\n    def _get_context(\n        ix: int,\n        backend,\n        context_area: gpd.GeoDataFrame,\n        cell_gdf: gpd.GeoDataFrame,\n        fit_network: bool = True,\n        fit_grid: bool = True,\n        predicate: str = \"intersects\",\n        silence_warnings: bool = True,\n        graph_type: str = \"distband\",\n        grid_type: str = \"square\",\n        resolution: int = 9,\n        dist_thresh: float = 75.0,\n        patch_size: Tuple[int, int] = (256, 256),\n        stride: Tuple[int, int] = (256, 256),\n        pad: int = None,\n        parallel: bool = False,\n        num_processes: int = None,\n        **kwargs,\n    ) -&gt; Dict[str, Any]:\n        \"\"\"Get the context dict of the given index.\"\"\"\n        roi_area: gpd.GeoDataFrame = backend.roi(ix=ix, context_area=context_area)\n        roi_cells: gpd.GeoDataFrame = backend.roi_cells(\n            roi_area=roi_area,\n            cell_gdf=cell_gdf,\n            predicate=predicate,\n            silence_warnings=silence_warnings,\n            parallel=parallel,\n            num_processes=num_processes,\n            **kwargs,\n        )\n        context_dict = {\"roi_area\": roi_area}\n        context_dict[\"roi_cells\"] = roi_cells\n\n        if fit_network:\n            roi_net: W = fit_graph(\n                gdf=roi_cells,\n                type=graph_type,\n                id_col=\"global_id\",\n                thresh=dist_thresh,\n                use_index=False,\n            )\n            context_dict[\"roi_network\"] = roi_net\n\n        if fit_grid:\n            if grid_type == \"hex\":\n                kwargs = {\"resolution\": resolution}\n            else:\n                kwargs = {\n                    \"patch_size\": patch_size,\n                    \"stride\": stride,\n                    \"pad\": pad,\n                    \"predicate\": predicate,\n                }\n\n            context_dict[\"roi_grid\"] = fit_spatial_grid(\n                gdf=roi_area, grid_type=grid_type, **kwargs\n            )\n\n        return context_dict\n\n    def context2weights(self, key: str) -&gt; W:\n        \"\"\"Merge the networks of type `key` into one spatial weights obj.\n\n        Parameters:\n            key (str):\n                The key of the context dictionary that contains the spatial\n                weights to be merged. One of \"roi_network\"\n\n        Returns:\n            libpysal.weights.W:\n                A spatial weights object containing all the distinct networks\n                in the context.\n        \"\"\"\n        allowed = (\"roi_network\",)\n        if key not in allowed:\n            raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n        cxs = list(self.context.items())\n        wout = W({0: [0]})\n        for _, c in cxs:\n            w = c[key]\n            if isinstance(w, W):\n                wout = w_union(wout, w, silence_warnings=True)\n\n        # remove self loops\n        wout = w_subset(\n            wout,\n            list(wout.neighbors.keys())[1:],\n            silence_warnings=True,\n        )\n\n        return wout\n\n    def context2gdf(self, key: str) -&gt; gpd.GeoDataFrame:\n        \"\"\"Merge the GeoDataFrames of type `key` into one geodataframe.\n\n        Note:\n            Returns None if no data is found.\n\n        Parameters:\n            key (str):\n                The key of the context dictionary that contains the data to be\n                converted to gdf. One of \"roi_area\", \"roi_cells\", \"roi_grid\",\n\n        Returns:\n            gpd.GeoDataFrame:\n                Geo dataframe containing all the objects\n        \"\"\"\n        allowed = (\n            \"roi_area\",\n            \"roi_cells\",\n            \"roi_grid\",\n        )\n        if key not in allowed:\n            raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n        con = []\n        for i in self.context.keys():\n            if self.context[i][key] is not None:\n                if isinstance(self.context[i][key], tuple):\n                    con.append(self.context[i][key][0])\n                else:\n                    con.append(self.context[i][key])\n\n        if not con:\n            return\n\n        gdf = pd.concat(\n            con,\n            keys=[i for i in self.context.keys() if self.context[i][key] is not None],\n        )\n        gdf = gdf.explode(ignore_index=True)\n\n        return (\n            gdf.reset_index(level=0, names=\"label\")\n            .drop_duplicates(\"geometry\")\n            .set_geometry(\"geometry\")\n        )\n\n    def plot(\n        self,\n        key: str,\n        network_key: str = None,\n        grid_key: str = None,\n        show_legends: bool = True,\n        color: str = None,\n        figsize: Tuple[int, int] = (12, 12),\n        edge_kws: Dict[str, Any] = None,\n        **kwargs,\n    ) -&gt; plt.Axes:\n        \"\"\"Plot the context with areas, cells, and ROIs highlighted.\n\n        Parameters:\n            key (str):\n                The key of the context dictionary that contains the data to be plotted.\n                One of \"roi_area\",\n            network_key (str):\n                The key of the context dictionary that contains the spatial weights to\n                be plotted. One of \"roi_network\"\n            grid_key (str):\n                The key of the context dictionary that contains the grid to be plotted.\n                One of \"roi_grid\"\n            show_legends (bool):\n                Flag, whether to include legends for each in the plot.\n            color (str):\n                A color for the interfaces or rois, Ignored if `show_legends=True`.\n            figsize (Tuple[int, int]):\n                Size of the figure.\n            **kwargs (Dict[str, Any])]):\n                Extra keyword arguments passed to the `plot` method of the\n                geodataframes.\n\n        Returns:\n            AxesSubplot\n\n        Examples:\n            Plot the context with stromal areas highlighted.\n\n            &gt;&gt;&gt; from cellseg_gsontools.spatial_context import WithinContext\n            &gt;&gt;&gt; cells = read_gdf(\"cells.feather\")\n            &gt;&gt;&gt; areas = read_gdf(\"areas.feather\")\n            &gt;&gt;&gt; stroma = WithinContext(\n            ...     cell_gdf=cells,\n            ...     area_gdf=areas,\n            ...     labels=\"stroma\",\n            ... )\n            &gt;&gt;&gt; stroma.fit(verbose=False)\n            &gt;&gt;&gt; stroma.plot(\"roi_area\", show_legends=True)\n            &lt;AxesSubplot: &gt;\n        \"\"\"\n        allowed = \"roi_area\"\n        if key != allowed:\n            raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n        context_gdf = self.context2gdf(key)\n\n        grid_gdf = None\n        if grid_key is not None:\n            grid_gdf = self.context2gdf(grid_key)\n\n        network_gdf = None\n        if network_key is not None:\n            edge_kws = edge_kws or {}\n            w = self.context2weights(network_key)\n            network_gdf = weights2gdf(self.cell_gdf, w)\n\n        return plot_all(\n            cell_gdf=self.cell_gdf.set_geometry(\"geometry\"),\n            area_gdf=self.area_gdf.set_geometry(\"geometry\"),\n            context_gdf=context_gdf,\n            grid_gdf=grid_gdf,\n            network_gdf=network_gdf,\n            show_legends=show_legends,\n            color=color,\n            figsize=figsize,\n            edge_kws=edge_kws,\n            **kwargs,\n        )\n</code></pre>"},{"location":"reference/spatial_contexts/within_context_ref/#cellseg_gsontools.spatial_context.WithinContext.fit","title":"<code>fit(verbose=True, fit_graph=True, fit_grid=True)</code>","text":"<p>Fit the context.</p> <p>This sets the <code>self.context</code> attribute.</p> <p>Parameters:</p> Name Type Description Default <code>verbose</code> <code>bool</code> <p>Flag, whether to use tqdm pbar when creating the interfaces.</p> <code>True</code> <code>fit_graph</code> <code>bool</code> <p>Flag, whether to fit the spatial weights networks for the context.</p> <code>True</code> <code>fit_grid</code> <code>bool</code> <p>Flag, whether to fit the a grid on the contextes.</p> <code>True</code> <p>Examples:</p> <p>Define a within context and plot the cells inside a specific ROI.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.spatial_context import WithinContext\n&gt;&gt;&gt; area_gdf = read_gdf(\"area.json\")\n&gt;&gt;&gt; cell_gdf = read_gdf(\"cells.json\")\n&gt;&gt;&gt; within_context = WithinContext(\n...     area_gdf=area_gdf,\n...     cell_gdf=cell_gdf,\n...     labels=[\"area_cin\"],\n...     silence_warnings=True,\n...     min_area_size=100000.0,\n... )\n&gt;&gt;&gt; within_context.fit()\n&gt;&gt;&gt; within_context.plot(\"roi_area\", show_legends=True)\n&lt;AxesSubplot: &gt;\n</code></pre> Source code in <code>cellseg_gsontools/spatial_context/within.py</code> <pre><code>def fit(\n    self,\n    verbose: bool = True,\n    fit_graph: bool = True,\n    fit_grid: bool = True,\n) -&gt; None:\n    \"\"\"Fit the context.\n\n    This sets the `self.context` attribute.\n\n    Parameters:\n        verbose (bool):\n            Flag, whether to use tqdm pbar when creating the interfaces.\n        fit_graph (bool):\n            Flag, whether to fit the spatial weights networks for the\n            context.\n        fit_grid (bool):\n            Flag, whether to fit the a grid on the contextes.\n\n    Examples:\n        Define a within context and plot the cells inside a specific ROI.\n\n        &gt;&gt;&gt; from cellseg_gsontools.spatial_context import WithinContext\n        &gt;&gt;&gt; area_gdf = read_gdf(\"area.json\")\n        &gt;&gt;&gt; cell_gdf = read_gdf(\"cells.json\")\n        &gt;&gt;&gt; within_context = WithinContext(\n        ...     area_gdf=area_gdf,\n        ...     cell_gdf=cell_gdf,\n        ...     labels=[\"area_cin\"],\n        ...     silence_warnings=True,\n        ...     min_area_size=100000.0,\n        ... )\n        &gt;&gt;&gt; within_context.fit()\n        &gt;&gt;&gt; within_context.plot(\"roi_area\", show_legends=True)\n        &lt;AxesSubplot: &gt;\n    \"\"\"\n    get_context_func = partial(\n        WithinContext._get_context,\n        backend=self.backend,\n        context_area=self.context_area,\n        cell_gdf=self.cell_gdf,\n        fit_network=fit_graph,\n        fit_grid=fit_grid,\n        predicate=self.predicate,\n        silence_warnings=self.silence_warnings,\n        graph_type=self.graph_type,\n        grid_type=self.grid_type,\n        resolution=self.resolution,\n        dist_thresh=self.dist_thresh,\n        patch_size=self.patch_size,\n        stride=self.stride,\n        pad=self.pad,\n        parallel=self.parallel,\n        num_processes=self.cpus,\n    )\n\n    if self.backend_name == \"geopandas\" and self.parallel:\n        # run in parallel\n        context_dict = gdf_apply(\n            self.context_area,\n            func=get_context_func,\n            columns=[\"global_id\"],\n            parallel=True,\n            pbar=verbose,\n            num_processes=self.cpus,\n        ).to_dict()\n    else:\n        context_dict = {}\n        pbar = (\n            tqdm(self.context_area.index, total=self.context_area.shape[0])\n            if verbose\n            else self.context_area.index\n        )\n\n        for ix in pbar:\n            if verbose:\n                pbar.set_description(f\"Processing roi area: {ix}\")\n\n            if self.backend_name == \"dask-geopandas\" and self.parallel:\n                get_context_func = partial(\n                    get_context_func, cell_gdf_dgp=self.backend.cell_gdf_dgp\n                )\n\n            context_dict[ix] = get_context_func(ix=ix)\n\n    self.context = context_dict\n</code></pre>"},{"location":"reference/spatial_contexts/within_context_ref/#cellseg_gsontools.spatial_context.WithinContext.context2gdf","title":"<code>context2gdf(key)</code>","text":"<p>Merge the GeoDataFrames of type <code>key</code> into one geodataframe.</p> Note <p>Returns None if no data is found.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the context dictionary that contains the data to be converted to gdf. One of \"roi_area\", \"roi_cells\", \"roi_grid\",</p> required <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: Geo dataframe containing all the objects</p> Source code in <code>cellseg_gsontools/spatial_context/within.py</code> <pre><code>def context2gdf(self, key: str) -&gt; gpd.GeoDataFrame:\n    \"\"\"Merge the GeoDataFrames of type `key` into one geodataframe.\n\n    Note:\n        Returns None if no data is found.\n\n    Parameters:\n        key (str):\n            The key of the context dictionary that contains the data to be\n            converted to gdf. One of \"roi_area\", \"roi_cells\", \"roi_grid\",\n\n    Returns:\n        gpd.GeoDataFrame:\n            Geo dataframe containing all the objects\n    \"\"\"\n    allowed = (\n        \"roi_area\",\n        \"roi_cells\",\n        \"roi_grid\",\n    )\n    if key not in allowed:\n        raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n    con = []\n    for i in self.context.keys():\n        if self.context[i][key] is not None:\n            if isinstance(self.context[i][key], tuple):\n                con.append(self.context[i][key][0])\n            else:\n                con.append(self.context[i][key])\n\n    if not con:\n        return\n\n    gdf = pd.concat(\n        con,\n        keys=[i for i in self.context.keys() if self.context[i][key] is not None],\n    )\n    gdf = gdf.explode(ignore_index=True)\n\n    return (\n        gdf.reset_index(level=0, names=\"label\")\n        .drop_duplicates(\"geometry\")\n        .set_geometry(\"geometry\")\n    )\n</code></pre>"},{"location":"reference/spatial_contexts/within_context_ref/#cellseg_gsontools.spatial_context.WithinContext.context2weights","title":"<code>context2weights(key)</code>","text":"<p>Merge the networks of type <code>key</code> into one spatial weights obj.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the context dictionary that contains the spatial weights to be merged. One of \"roi_network\"</p> required <p>Returns:</p> Type Description <code>W</code> <p>libpysal.weights.W: A spatial weights object containing all the distinct networks in the context.</p> Source code in <code>cellseg_gsontools/spatial_context/within.py</code> <pre><code>def context2weights(self, key: str) -&gt; W:\n    \"\"\"Merge the networks of type `key` into one spatial weights obj.\n\n    Parameters:\n        key (str):\n            The key of the context dictionary that contains the spatial\n            weights to be merged. One of \"roi_network\"\n\n    Returns:\n        libpysal.weights.W:\n            A spatial weights object containing all the distinct networks\n            in the context.\n    \"\"\"\n    allowed = (\"roi_network\",)\n    if key not in allowed:\n        raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n    cxs = list(self.context.items())\n    wout = W({0: [0]})\n    for _, c in cxs:\n        w = c[key]\n        if isinstance(w, W):\n            wout = w_union(wout, w, silence_warnings=True)\n\n    # remove self loops\n    wout = w_subset(\n        wout,\n        list(wout.neighbors.keys())[1:],\n        silence_warnings=True,\n    )\n\n    return wout\n</code></pre>"},{"location":"reference/spatial_contexts/within_context_ref/#cellseg_gsontools.spatial_context.WithinContext.plot","title":"<code>plot(key, network_key=None, grid_key=None, show_legends=True, color=None, figsize=(12, 12), edge_kws=None, **kwargs)</code>","text":"<p>Plot the context with areas, cells, and ROIs highlighted.</p> <p>Parameters:</p> Name Type Description Default <code>key</code> <code>str</code> <p>The key of the context dictionary that contains the data to be plotted. One of \"roi_area\",</p> required <code>network_key</code> <code>str</code> <p>The key of the context dictionary that contains the spatial weights to be plotted. One of \"roi_network\"</p> <code>None</code> <code>grid_key</code> <code>str</code> <p>The key of the context dictionary that contains the grid to be plotted. One of \"roi_grid\"</p> <code>None</code> <code>show_legends</code> <code>bool</code> <p>Flag, whether to include legends for each in the plot.</p> <code>True</code> <code>color</code> <code>str</code> <p>A color for the interfaces or rois, Ignored if <code>show_legends=True</code>.</p> <code>None</code> <code>figsize</code> <code>Tuple[int, int]</code> <p>Size of the figure.</p> <code>(12, 12)</code> <code>**kwargs</code> <code>Dict[str, Any])]</code> <p>Extra keyword arguments passed to the <code>plot</code> method of the geodataframes.</p> <code>{}</code> <p>Returns:</p> Type Description <code>Axes</code> <p>AxesSubplot</p> <p>Examples:</p> <p>Plot the context with stromal areas highlighted.</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools.spatial_context import WithinContext\n&gt;&gt;&gt; cells = read_gdf(\"cells.feather\")\n&gt;&gt;&gt; areas = read_gdf(\"areas.feather\")\n&gt;&gt;&gt; stroma = WithinContext(\n...     cell_gdf=cells,\n...     area_gdf=areas,\n...     labels=\"stroma\",\n... )\n&gt;&gt;&gt; stroma.fit(verbose=False)\n&gt;&gt;&gt; stroma.plot(\"roi_area\", show_legends=True)\n&lt;AxesSubplot: &gt;\n</code></pre> Source code in <code>cellseg_gsontools/spatial_context/within.py</code> <pre><code>def plot(\n    self,\n    key: str,\n    network_key: str = None,\n    grid_key: str = None,\n    show_legends: bool = True,\n    color: str = None,\n    figsize: Tuple[int, int] = (12, 12),\n    edge_kws: Dict[str, Any] = None,\n    **kwargs,\n) -&gt; plt.Axes:\n    \"\"\"Plot the context with areas, cells, and ROIs highlighted.\n\n    Parameters:\n        key (str):\n            The key of the context dictionary that contains the data to be plotted.\n            One of \"roi_area\",\n        network_key (str):\n            The key of the context dictionary that contains the spatial weights to\n            be plotted. One of \"roi_network\"\n        grid_key (str):\n            The key of the context dictionary that contains the grid to be plotted.\n            One of \"roi_grid\"\n        show_legends (bool):\n            Flag, whether to include legends for each in the plot.\n        color (str):\n            A color for the interfaces or rois, Ignored if `show_legends=True`.\n        figsize (Tuple[int, int]):\n            Size of the figure.\n        **kwargs (Dict[str, Any])]):\n            Extra keyword arguments passed to the `plot` method of the\n            geodataframes.\n\n    Returns:\n        AxesSubplot\n\n    Examples:\n        Plot the context with stromal areas highlighted.\n\n        &gt;&gt;&gt; from cellseg_gsontools.spatial_context import WithinContext\n        &gt;&gt;&gt; cells = read_gdf(\"cells.feather\")\n        &gt;&gt;&gt; areas = read_gdf(\"areas.feather\")\n        &gt;&gt;&gt; stroma = WithinContext(\n        ...     cell_gdf=cells,\n        ...     area_gdf=areas,\n        ...     labels=\"stroma\",\n        ... )\n        &gt;&gt;&gt; stroma.fit(verbose=False)\n        &gt;&gt;&gt; stroma.plot(\"roi_area\", show_legends=True)\n        &lt;AxesSubplot: &gt;\n    \"\"\"\n    allowed = \"roi_area\"\n    if key != allowed:\n        raise ValueError(f\"Illegal key. Got: {key}. Allowed: {allowed}\")\n\n    context_gdf = self.context2gdf(key)\n\n    grid_gdf = None\n    if grid_key is not None:\n        grid_gdf = self.context2gdf(grid_key)\n\n    network_gdf = None\n    if network_key is not None:\n        edge_kws = edge_kws or {}\n        w = self.context2weights(network_key)\n        network_gdf = weights2gdf(self.cell_gdf, w)\n\n    return plot_all(\n        cell_gdf=self.cell_gdf.set_geometry(\"geometry\"),\n        area_gdf=self.area_gdf.set_geometry(\"geometry\"),\n        context_gdf=context_gdf,\n        grid_gdf=grid_gdf,\n        network_gdf=network_gdf,\n        show_legends=show_legends,\n        color=color,\n        figsize=figsize,\n        edge_kws=edge_kws,\n        **kwargs,\n    )\n</code></pre>"},{"location":"reference/tools/clip_gdf_ref/","title":"clip_gdf","text":""},{"location":"reference/tools/clip_gdf_ref/#cellseg_gsontools.clip_gdf","title":"<code>cellseg_gsontools.clip_gdf(gdf, bbox)</code>","text":"<p>Clip a gdf to a bounding box.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>Input geodataframe.</p> required <code>bbox</code> <code>Tuple[int, int, int, int]</code> <p>Bounding box to clip to. Format: (xmin, ymin, xmax, ymax).</p> required <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The Clipped gdf.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import clip_gdf\n&gt;&gt;&gt; gdf = clip_gdf(gdf, bbox=(0, 0, 100, 100))\n</code></pre> Source code in <code>cellseg_gsontools/utils.py</code> <pre><code>def clip_gdf(\n    gdf: gpd.GeoDataFrame, bbox: Tuple[int, int, int, int]\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Clip a gdf to a bounding box.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            Input geodataframe.\n        bbox (Tuple[int, int, int, int]):\n            Bounding box to clip to. Format: (xmin, ymin, xmax, ymax).\n\n    Returns:\n        gpd.GeoDataFrame:\n            The Clipped gdf.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools import clip_gdf\n        &gt;&gt;&gt; gdf = clip_gdf(gdf, bbox=(0, 0, 100, 100))\n    \"\"\"\n    xmin = bbox[0]\n    ymin = bbox[1]\n    xmax = bbox[2]\n    ymax = bbox[3]\n\n    crop = Polygon(\n        [(xmin, ymin), (xmin, ymax), (xmax, ymax), (xmax, ymin), (xmin, ymin)]\n    )\n\n    return gdf.clip(crop)\n</code></pre>"},{"location":"reference/tools/gdf_apply_ref/","title":"gdf_apply","text":""},{"location":"reference/tools/gdf_apply_ref/#cellseg_gsontools.gdf_apply","title":"<code>cellseg_gsontools.gdf_apply(gdf, func, axis=1, parallel=True, num_processes=-1, pbar=False, columns=None, **kwargs)</code>","text":"<p>Apply or parallel apply a function to any col or row of a GeoDataFrame.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>Input GeoDataFrame.</p> required <code>func</code> <code>Callable</code> <p>A callable function.</p> required <code>axis</code> <code>int, default=1</code> <p>The gdf axis to apply the function on.axis=1 means rowise. axis=0 means columnwise.</p> <code>1</code> <code>parallel</code> <code>bool, default=True</code> <p>Flag, whether to parallelize the operation with <code>pandarallel</code>.</p> <code>True</code> <code>num_processes</code> <code>int, default=-1</code> <p>The number of processes to use when parallel=True. If -1, this will use all available cores.</p> <code>-1</code> <code>pbar</code> <code>bool, default=False</code> <p>Show progress bar when executing in parallel mode. Ignored if <code>parallel=False</code>.</p> <code>False</code> <code>columns</code> <code>Optional[Tuple[str, ...]], default=None</code> <p>A tuple of column names to apply the function on. If None, this will apply the function to all columns.</p> <code>None</code> <code>**kwargs</code> <code>Dict[str, Any]</code> <p>Arbitrary keyword args for the <code>func</code> callable.</p> <code>{}</code> <p>Returns:</p> Type Description <code>GeoSeries</code> <p>gpd.GeoSeries: A GeoSeries object containing the computed values for each row or col in the input gdf.</p> <p>Examples:</p> <p>Get the compactness of the polygons in a gdf</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import gdf_apply\n&gt;&gt;&gt; gdf[\"compactness\"] = gdf_apply(\n...     gdf, compactness, columns=[\"geometry\"], parallel=True\n... )\n</code></pre> Source code in <code>cellseg_gsontools/apply.py</code> <pre><code>def gdf_apply(\n    gdf: gpd.GeoDataFrame,\n    func: Callable,\n    axis: int = 1,\n    parallel: bool = True,\n    num_processes: Optional[int] = -1,\n    pbar: bool = False,\n    columns: Optional[Tuple[str, ...]] = None,\n    **kwargs,\n) -&gt; gpd.GeoSeries:\n    \"\"\"Apply or parallel apply a function to any col or row of a GeoDataFrame.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            Input GeoDataFrame.\n        func (Callable):\n            A callable function.\n        axis (int, default=1):\n            The gdf axis to apply the function on.axis=1 means rowise. axis=0\n            means columnwise.\n        parallel (bool, default=True):\n            Flag, whether to parallelize the operation with `pandarallel`.\n        num_processes (int, default=-1):\n            The number of processes to use when parallel=True. If -1,\n            this will use all available cores.\n        pbar (bool, default=False):\n            Show progress bar when executing in parallel mode. Ignored if\n            `parallel=False`.\n        columns (Optional[Tuple[str, ...]], default=None):\n            A tuple of column names to apply the function on. If None,\n            this will apply the function to all columns.\n        **kwargs (Dict[str, Any]): Arbitrary keyword args for the `func` callable.\n\n    Returns:\n        gpd.GeoSeries:\n            A GeoSeries object containing the computed values for each\n            row or col in the input gdf.\n\n    Examples:\n        Get the compactness of the polygons in a gdf\n        &gt;&gt;&gt; from cellseg_gsontools import gdf_apply\n        &gt;&gt;&gt; gdf[\"compactness\"] = gdf_apply(\n        ...     gdf, compactness, columns=[\"geometry\"], parallel=True\n        ... )\n    \"\"\"\n    if columns is not None:\n        if not isinstance(columns, (tuple, list)):\n            raise ValueError(f\"columns must be a tuple or list, got {type(columns)}\")\n        gdf = gdf[columns]\n\n    if not parallel:\n        res = gdf.apply(lambda x: func(*x, **kwargs), axis=axis)\n    else:\n        cpus = psutil.cpu_count(logical=False) if num_processes == -1 else num_processes\n        pandarallel.initialize(verbose=1, progress_bar=pbar, nb_workers=cpus)\n        res = gdf.parallel_apply(lambda x: func(*x, **kwargs), axis=axis)\n\n    return res\n</code></pre>"},{"location":"reference/tools/lonlat_to_xy_ref/","title":"lonlat_to_xy","text":""},{"location":"reference/tools/lonlat_to_xy_ref/#cellseg_gsontools.lonlat_to_xy","title":"<code>cellseg_gsontools.lonlat_to_xy(lon, lat)</code>","text":"<p>Converts lon, lat coordinates to x, y coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>lon</code> <code>Union[float, Sequence]</code> <p>Longitude coordinate(s).</p> required <code>lat</code> <code>Union[float, Sequence]</code> <p>Latitude coordinate(s).</p> required <p>Returns:</p> Type Description <code>Tuple[Union[float, Sequence], Union[float, Sequence]]</code> <p>Tuple[Union[float, Sequence], Union[float, Sequence]]: x, y coordinates.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from shapely.geometry import Polygon\n&gt;&gt;&gt; from cellseg_gsontools import lonlat_to_xy\n&gt;&gt;&gt; poly = Polygon([(10, 10), (10, 0), (20, 10)])\n&gt;&gt;&gt; lon, lat = poly.exterior.coords.xy\n&gt;&gt;&gt; x, y = lonlat_to_xy(lon, lat)\n&gt;&gt;&gt; x, y\n(array('d', [-48636.648, -57087.120, 1048636.648, -48636.648]),\n array('d', [1109577.311, 0.0, 1109577.311, 1109577.311]))\n</code></pre> Source code in <code>cellseg_gsontools/utils.py</code> <pre><code>def lonlat_to_xy(\n    lon: Union[float, Sequence], lat: Union[float, Sequence]\n) -&gt; Tuple[Union[float, Sequence], Union[float, Sequence]]:\n    \"\"\"Converts lon, lat coordinates to x, y coordinates.\n\n    Parameters:\n        lon (Union[float, Sequence]):\n            Longitude coordinate(s).\n        lat (Union[float, Sequence]):\n            Latitude coordinate(s).\n\n    Returns:\n        Tuple[Union[float, Sequence], Union[float, Sequence]]:\n            x, y coordinates.\n\n    Examples:\n        &gt;&gt;&gt; from shapely.geometry import Polygon\n        &gt;&gt;&gt; from cellseg_gsontools import lonlat_to_xy\n        &gt;&gt;&gt; poly = Polygon([(10, 10), (10, 0), (20, 10)])\n        &gt;&gt;&gt; lon, lat = poly.exterior.coords.xy\n        &gt;&gt;&gt; x, y = lonlat_to_xy(lon, lat)\n        &gt;&gt;&gt; x, y\n        (array('d', [-48636.648, -57087.120, 1048636.648, -48636.648]),\n         array('d', [1109577.311, 0.0, 1109577.311, 1109577.311]))\n    \"\"\"\n    crs_utm = CRS(proj=\"utm\", zone=33, ellps=\"WGS84\")\n    crs_latlon = CRS(proj=\"latlong\", zone=33, ellps=\"WGS84\")\n    transformer = Transformer.from_crs(crs_latlon, crs_utm, always_xy=True)\n    xy = transformer.transform(lon, lat)\n\n    return xy[0], xy[1]\n</code></pre>"},{"location":"reference/tools/pre_proc_gdf_ref/","title":"pre_proc_gdf","text":""},{"location":"reference/tools/pre_proc_gdf_ref/#cellseg_gsontools.pre_proc_gdf","title":"<code>cellseg_gsontools.pre_proc_gdf(gdf, min_size=None)</code>","text":"<p>Apply some light pre-processing of a geodataframe.</p> <p>Namely, remove invalid polygons, empty geometries and add bounds to the gdf.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>Input geodataframe.</p> required <code>min_size</code> <code>int</code> <p>The minimum size of the polygons in pixels.</p> <code>None</code> <p>Returns:</p> Type Description <code>Union[GeoDataFrame, None]</code> <p>gpd.GeoDataFrame: The pre-processed gdf or None if input gdf is empty or None.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import pre_proc_gdf\n&gt;&gt;&gt; gdf = pre_proc_gdf(gdf, min_size=100)\n</code></pre> Source code in <code>cellseg_gsontools/utils.py</code> <pre><code>def pre_proc_gdf(\n    gdf: gpd.GeoDataFrame, min_size: int = None\n) -&gt; Union[gpd.GeoDataFrame, None]:\n    \"\"\"Apply some light pre-processing of a geodataframe.\n\n    Namely, remove invalid polygons, empty geometries and add bounds to the gdf.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            Input geodataframe.\n        min_size (int, optional):\n            The minimum size of the polygons in pixels.\n\n    Returns:\n        gpd.GeoDataFrame:\n            The pre-processed gdf or None if input gdf is empty or None.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools import pre_proc_gdf\n        &gt;&gt;&gt; gdf = pre_proc_gdf(gdf, min_size=100)\n    \"\"\"\n    if gdf.empty or gdf is None:\n        return gdf\n\n    # drop invalid geometries if there are any after buffer\n    gdf.geometry = gdf.geometry.buffer(0)\n    gdf = gdf[gdf.is_valid]\n\n    # drop empty geometries\n    gdf = gdf[~gdf.is_empty]\n\n    # if there are multipolygon geometries, explode them\n    if \"MultiPolygon\" in list(gdf[\"geometry\"].geom_type):\n        gdf = gdf.explode(index_parts=False).reset_index(drop=True)\n\n    # drop geometries that are less than min_size pixels\n    if min_size is not None:\n        gdf = gdf[gdf.area &gt; min_size]\n\n    # drop geometries that are not polygons\n    gdf = gdf[gdf.geom_type == \"Polygon\"]\n\n    try:\n        # add bounding box coords of the polygons to the gdfs\n        # and correct for the max coords\n        gdf[\"xmin\"] = gdf.bounds[\"minx\"].astype(int)\n        gdf[\"ymin\"] = gdf.bounds[\"miny\"].astype(int)\n        gdf[\"ymax\"] = gdf.bounds[\"maxy\"].astype(int) + 1\n        gdf[\"xmax\"] = gdf.bounds[\"maxx\"].astype(int) + 1\n    except Exception:\n        warnings.warn(\"Could not create bounds cols to gdf.\", RuntimeWarning)\n\n    return gdf\n</code></pre>"},{"location":"reference/tools/set_uid_ref/","title":"set_uid","text":""},{"location":"reference/tools/set_uid_ref/#cellseg_gsontools.set_uid","title":"<code>cellseg_gsontools.set_uid(gdf, start_ix=0, id_col='uid', drop=False)</code>","text":"<p>Set a unique identifier column to gdf.</p> Note <p>by default sets a running index column to gdf as the uid.</p> <p>Parameters:</p> Name Type Description Default <code>gdf</code> <code>GeoDataFrame</code> <p>Input Geodataframe.</p> required <code>start_ix</code> <code>int, default=0</code> <p>The starting index of the id column.</p> <code>0</code> <code>id_col</code> <code>str, default=\"uid\"</code> <p>The name of the column that will be used or set to the id.</p> <code>'uid'</code> <code>drop</code> <code>bool, default=False</code> <p>Drop the column after it is added to index.</p> <code>False</code> <p>Returns:</p> Type Description <code>GeoDataFrame</code> <p>gpd.GeoDataFrame: The input gdf with a \"uid\" column added to it.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import set_uid\n&gt;&gt;&gt; gdf = set_uid(gdf, drop=True)\n</code></pre> Source code in <code>cellseg_gsontools/utils.py</code> <pre><code>def set_uid(\n    gdf: gpd.GeoDataFrame, start_ix: int = 0, id_col: str = \"uid\", drop: bool = False\n) -&gt; gpd.GeoDataFrame:\n    \"\"\"Set a unique identifier column to gdf.\n\n    Note:\n        by default sets a running index column to gdf as the uid.\n\n    Parameters:\n        gdf (gpd.GeoDataFrame):\n            Input Geodataframe.\n        start_ix (int, default=0):\n            The starting index of the id column.\n        id_col (str, default=\"uid\"):\n            The name of the column that will be used or set to the id.\n        drop (bool, default=False):\n            Drop the column after it is added to index.\n\n    Returns:\n        gpd.GeoDataFrame:\n            The input gdf with a \"uid\" column added to it.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools import set_uid\n        &gt;&gt;&gt; gdf = set_uid(gdf, drop=True)\n    \"\"\"\n    gdf = gdf.copy()\n    if id_col not in gdf.columns:\n        gdf[id_col] = range(start_ix, len(gdf) + start_ix)\n\n    gdf = gdf.set_index(id_col, drop=drop)\n\n    return gdf\n</code></pre>"},{"location":"reference/tools/xy_to_lonlat_ref/","title":"xy_to_lonlat","text":""},{"location":"reference/tools/xy_to_lonlat_ref/#cellseg_gsontools.xy_to_lonlat","title":"<code>cellseg_gsontools.xy_to_lonlat(x, y)</code>","text":"<p>Converts x, y coordinates to lon, lat coordinates.</p> <p>Parameters:</p> Name Type Description Default <code>x</code> <code>Union[float, Sequence]</code> <p>x coordinate(s).</p> required <code>y</code> <code>Union[float, Sequence]</code> <p>y coordinate(s).</p> required <p>Returns:</p> Type Description <code>Tuple[Union[float, Sequence], Union[float, Sequence]]</code> <p>Tuple[Union[float, Sequence], Union[float, Sequence]]: lon, lat coordinates.</p> <p>Examples:</p> <pre><code>&gt;&gt;&gt; from cellseg_gsontools import xy_to_lonlat\n&gt;&gt;&gt; from shapely.geometry import Polygon\n&gt;&gt;&gt; poly = Polygon([(0, 0), (0, 1), (1, 1)])\n&gt;&gt;&gt; x, y = poly.exterior.coords.xy\n&gt;&gt;&gt; lon, lat = xy_to_lonlat(x, y)\n&gt;&gt;&gt; lon, lat\n(array('d', [10.511, 10.511, 10.511, 10.511]),\n array('d', [0.0, 9.019e-06, 9.019e-06, 0.0]))\n</code></pre> Source code in <code>cellseg_gsontools/utils.py</code> <pre><code>def xy_to_lonlat(\n    x: Union[float, Sequence], y: Union[float, Sequence]\n) -&gt; Tuple[Union[float, Sequence], Union[float, Sequence]]:\n    \"\"\"Converts x, y coordinates to lon, lat coordinates.\n\n    Parameters:\n        x (Union[float, Sequence]):\n            x coordinate(s).\n        y (Union[float, Sequence]):\n            y coordinate(s).\n\n    Returns:\n        Tuple[Union[float, Sequence], Union[float, Sequence]]:\n            lon, lat coordinates.\n\n    Examples:\n        &gt;&gt;&gt; from cellseg_gsontools import xy_to_lonlat\n        &gt;&gt;&gt; from shapely.geometry import Polygon\n        &gt;&gt;&gt; poly = Polygon([(0, 0), (0, 1), (1, 1)])\n        &gt;&gt;&gt; x, y = poly.exterior.coords.xy\n        &gt;&gt;&gt; lon, lat = xy_to_lonlat(x, y)\n        &gt;&gt;&gt; lon, lat\n        (array('d', [10.511, 10.511, 10.511, 10.511]),\n         array('d', [0.0, 9.019e-06, 9.019e-06, 0.0]))\n    \"\"\"\n    crs_utm = CRS(proj=\"utm\", zone=33, ellps=\"WGS84\")\n    crs_latlon = CRS(proj=\"latlong\", zone=33, ellps=\"WGS84\")\n    transformer = Transformer.from_crs(crs_utm, crs_latlon, always_xy=True)\n    lonlat = transformer.transform(x, y)\n\n    return lonlat[0], lonlat[1]\n</code></pre>"},{"location":"user_guide/cell_clustering/","title":"Cell Clustering","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nfrom cellseg_gsontools import read_gdf\n\ntissue_path = Path(\"/path/to/tissues.geojson\")\nnuc_path = Path(\"/path/to/nuclei.geojson\")\n\ntissues = read_gdf(tissue_path)[[\"geometry\", \"class_name\"]] # take only relevant columns\nnuclei = read_gdf(nuc_path)[[\"geometry\", \"class_name\"]]\n\ntissues.head(5)\n</pre> from pathlib import Path from cellseg_gsontools import read_gdf  tissue_path = Path(\"/path/to/tissues.geojson\") nuc_path = Path(\"/path/to/nuclei.geojson\")  tissues = read_gdf(tissue_path)[[\"geometry\", \"class_name\"]] # take only relevant columns nuclei = read_gdf(nuc_path)[[\"geometry\", \"class_name\"]]  tissues.head(5) Out[1]: geometry class_name 0 POLYGON ((15254.29000 111406.03000, 15249.5200... areastroma 1 POLYGON ((13930.07000 104644.52000, 13930.0300... areastroma 2 POLYGON ((13980.29000 104162.03000, 13976.5200... areastroma 3 POLYGON ((12774.89000 109112.00000, 12771.5200... areastroma 4 POLYGON ((11829.07000 103235.52000, 11829.0000... areastroma In\u00a0[2]: Copied! <pre>tissues.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None)\n</pre> tissues.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None) Out[2]: <pre>&lt;Axes: &gt;</pre> In\u00a0[3]: Copied! <pre>nuclei.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None)\n</pre> nuclei.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None) Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>from cellseg_gsontools.clustering import cluster_points\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimmune = nuclei.loc[nuclei[\"class_name\"] == \"inflammatory\"]\n\n# cluster the immune cells\nimmune = cluster_points(immune[[\"geometry\"]], eps=120, min_samples=20, method=\"dbscan\")\nimmune = immune.loc[immune[\"labels\"] != -1] # rename noise points\nimmune.labels.value_counts()\n</pre> from cellseg_gsontools.clustering import cluster_points import warnings warnings.filterwarnings(\"ignore\")  immune = nuclei.loc[nuclei[\"class_name\"] == \"inflammatory\"]  # cluster the immune cells immune = cluster_points(immune[[\"geometry\"]], eps=120, min_samples=20, method=\"dbscan\") immune = immune.loc[immune[\"labels\"] != -1] # rename noise points immune.labels.value_counts() Out[4]: <pre>labels\n2     4814\n1      333\n15     330\n0      134\n16     132\n7       86\n6       82\n10      74\n3       70\n4       35\n17      34\n11      32\n14      32\n12      27\n9       26\n8       25\n13      20\n5       13\nName: count, dtype: int64</pre> In\u00a0[5]: Copied! <pre>ax = tissues.plot(\n    figsize=(10, 15),\n    alpha=0.1,\n    column=\"class_name\",\n    aspect=None\n)\nimmune.plot(\n    ax=ax,\n    column=\"labels\",\n    categorical=True,\n    cmap=\"tab20\",\n    legend=True,\n    aspect=None\n)\n</pre> ax = tissues.plot(     figsize=(10, 15),     alpha=0.1,     column=\"class_name\",     aspect=None ) immune.plot(     ax=ax,     column=\"labels\",     categorical=True,     cmap=\"tab20\",     legend=True,     aspect=None ) Out[5]: <pre>&lt;Axes: &gt;</pre> <p>In the above plots you can see the immune cell clusters highlighted. There appears to be one major cluster and a number of smaller ones in this sample.</p> In\u00a0[6]: Copied! <pre>import shapely\nimport geopandas as gpd\nimport numpy as np\n\ndef get_dispersion(cells: gpd.GeoDataFrame):\n    xy = np.vstack([cells.centroid.x, cells.centroid.y]).T\n    n, p = xy.shape\n    m = xy.mean(axis=0)\n    return np.sqrt(((xy * xy).sum(axis=0) / n - m * m).sum())\n\ncluster_std_distances = immune.groupby(\"labels\").apply(\n    lambda x: get_dispersion(x[\"geometry\"])\n)\n\ncluster_std_distances\n</pre> import shapely import geopandas as gpd import numpy as np  def get_dispersion(cells: gpd.GeoDataFrame):     xy = np.vstack([cells.centroid.x, cells.centroid.y]).T     n, p = xy.shape     m = xy.mean(axis=0)     return np.sqrt(((xy * xy).sum(axis=0) / n - m * m).sum())  cluster_std_distances = immune.groupby(\"labels\").apply(     lambda x: get_dispersion(x[\"geometry\"]) )  cluster_std_distances Out[6]: <pre>labels\n0      211.546143\n1      352.403063\n2     1577.865794\n3      137.323195\n4      109.390956\n5       58.157829\n6      170.360235\n7      187.765813\n8       94.702071\n9       83.982071\n10     176.933932\n11     124.720200\n12      96.967663\n13      85.344381\n14     104.803038\n15     451.613534\n16     252.208297\n17     110.009231\ndtype: float64</pre> <p>From the results above we can see that the large cluster has a very large dispersion and the smaller clusters have a smaller dispersion. The cluster dispersion is typically heavily correlated with the cluster size. The larger the cluster, the larger the dispersion. It is a good indication of how wide the cluster has spread.</p> In\u00a0[7]: Copied! <pre>import shapely\nimport geopandas as gpd\nimport numpy as np\n\ndef get_mean_center(cells: gpd.GeoDataFrame):\n    xy = np.vstack([cells.centroid.x, cells.centroid.y]).T\n    return xy.mean(axis=0)\n\n\ncluster_centroids = immune.groupby(\"labels\").apply(\n    lambda x: get_mean_center(x[\"geometry\"])\n)\ndata = []\nfor i, v in cluster_centroids.items():\n    data.append([shapely.Point(v), i])\n\ncentroids = gpd.GeoDataFrame(data, columns=[\"geometry\", \"labels\"])\ncentroids\n</pre> import shapely import geopandas as gpd import numpy as np  def get_mean_center(cells: gpd.GeoDataFrame):     xy = np.vstack([cells.centroid.x, cells.centroid.y]).T     return xy.mean(axis=0)   cluster_centroids = immune.groupby(\"labels\").apply(     lambda x: get_mean_center(x[\"geometry\"]) ) data = [] for i, v in cluster_centroids.items():     data.append([shapely.Point(v), i])  centroids = gpd.GeoDataFrame(data, columns=[\"geometry\", \"labels\"]) centroids Out[7]: geometry labels 0 POINT (11532.623 104915.359) 0 1 POINT (10501.028 109281.822) 1 2 POINT (11263.304 106775.933) 2 3 POINT (8014.802 104356.890) 3 4 POINT (6542.005 110150.184) 4 5 POINT (6411.446 110370.355) 5 6 POINT (7212.627 109052.086) 6 7 POINT (6935.348 109777.326) 7 8 POINT (7080.838 109361.423) 8 9 POINT (8581.878 105405.632) 9 10 POINT (9905.450 104758.680) 10 11 POINT (9677.164 105735.919) 11 12 POINT (10089.710 109797.747) 12 13 POINT (11350.779 108116.340) 13 14 POINT (12636.433 105728.758) 14 15 POINT (12577.431 108426.139) 15 16 POINT (13392.943 105878.423) 16 17 POINT (13748.272 108258.991) 17 In\u00a0[8]: Copied! <pre>ax = tissues.plot(\n    figsize=(10, 15),\n    alpha=0.1,\n    column=\"class_name\",\n    aspect=None\n)\nimmune.plot(\n    ax=ax,\n    column=\"labels\",\n    categorical=True,\n    cmap=\"tab20\",\n    legend=True,\n    aspect=None\n)\ncentroids.plot(\n    ax=ax,\n    cmap=\"tab20\",\n    markersize=300,\n    marker=\"*\",\n    alpha=0.5\n)\n</pre> ax = tissues.plot(     figsize=(10, 15),     alpha=0.1,     column=\"class_name\",     aspect=None ) immune.plot(     ax=ax,     column=\"labels\",     categorical=True,     cmap=\"tab20\",     legend=True,     aspect=None ) centroids.plot(     ax=ax,     cmap=\"tab20\",     markersize=300,     marker=\"*\",     alpha=0.5 ) Out[8]: <pre>&lt;Axes: &gt;</pre> In\u00a0[9]: Copied! <pre>import pandas as pd\n\n# Helper function to get the distances of the cells to a given tissue class\ndef get_distances_to_tissue(objs, tissues, tissue_class):\n    tissue = tissues.loc[tissues[\"class_name\"] == tissue_class]\n\n    distances = {}\n    for i, poly in tissue.reset_index().iterrows():\n        dist = objs.distance(poly.geometry)\n        distances[i] = dist\n\n    min_dists = pd.DataFrame(distances).min(axis=1)\n    min_dists.name = f\"distance_to_{tissue_class}\"\n\n    return objs.join(other=min_dists, how=\"left\")\n\n# get the distances to the tissue classes\ncentroids = get_distances_to_tissue(centroids, tissues, \"area_cin\")\ncentroids = get_distances_to_tissue(centroids, tissues, \"areasquam\")\ncentroids = get_distances_to_tissue(centroids, tissues, \"areagland\")\n\n# get the clusters that are within 250 microns of the lesion\ncentroids[\"clust_within_250_micron_form_lesion\"] = (\n    centroids[\"distance_to_area_cin\"] &lt; 500\n)\n\n# get the closest tissue class\ncentroids[\"closest_tissue\"] = (\n    centroids[\n        [\"distance_to_area_cin\", \"distance_to_areasquam\", \"distance_to_areagland\"]\n    ]\n    .idxmin(axis=1)\n    .str.replace(\"distance_to_\", \"closest_to_\")\n)\n\n# get the distance to the closest tissue class\ncentroids[\"distance_to_tissue\"] = centroids[\n    [\"distance_to_area_cin\", \"distance_to_areasquam\", \"distance_to_areagland\"]\n].min(axis=1)\n\ncentroids.head(5)\n</pre> import pandas as pd  # Helper function to get the distances of the cells to a given tissue class def get_distances_to_tissue(objs, tissues, tissue_class):     tissue = tissues.loc[tissues[\"class_name\"] == tissue_class]      distances = {}     for i, poly in tissue.reset_index().iterrows():         dist = objs.distance(poly.geometry)         distances[i] = dist      min_dists = pd.DataFrame(distances).min(axis=1)     min_dists.name = f\"distance_to_{tissue_class}\"      return objs.join(other=min_dists, how=\"left\")  # get the distances to the tissue classes centroids = get_distances_to_tissue(centroids, tissues, \"area_cin\") centroids = get_distances_to_tissue(centroids, tissues, \"areasquam\") centroids = get_distances_to_tissue(centroids, tissues, \"areagland\")  # get the clusters that are within 250 microns of the lesion centroids[\"clust_within_250_micron_form_lesion\"] = (     centroids[\"distance_to_area_cin\"] &lt; 500 )  # get the closest tissue class centroids[\"closest_tissue\"] = (     centroids[         [\"distance_to_area_cin\", \"distance_to_areasquam\", \"distance_to_areagland\"]     ]     .idxmin(axis=1)     .str.replace(\"distance_to_\", \"closest_to_\") )  # get the distance to the closest tissue class centroids[\"distance_to_tissue\"] = centroids[     [\"distance_to_area_cin\", \"distance_to_areasquam\", \"distance_to_areagland\"] ].min(axis=1)  centroids.head(5) Out[9]: geometry labels distance_to_area_cin distance_to_areasquam distance_to_areagland clust_within_250_micron_form_lesion closest_tissue distance_to_tissue 0 POINT (11532.623 104915.359) 0 420.999237 358.591268 429.959676 True closest_to_areasquam 358.591268 1 POINT (10501.028 109281.822) 1 3133.244304 4498.854424 313.917045 False closest_to_areagland 313.917045 2 POINT (11263.304 106775.933) 2 2235.382378 1888.740965 711.974376 False closest_to_areagland 711.974376 3 POINT (8014.802 104356.890) 3 0.000000 1947.313708 454.891400 True closest_to_area_cin 0.000000 4 POINT (6542.005 110150.184) 4 635.961553 7283.810143 125.302327 False closest_to_areagland 125.302327 <p>Let's now plot the distances. We will bin the distance values with the Fisher-Jenks method in the plot.</p> In\u00a0[10]: Copied! <pre>ax = tissues.plot(\n    figsize=(10, 15),\n    alpha=0.1,\n    column=\"class_name\",\n    aspect=None\n)\nimmune.plot(\n    ax=ax,\n    legend=False,\n    aspect=None\n)\ncentroids.plot(\n    ax=ax,\n    column=\"distance_to_area_cin\",\n    cmap=\"turbo\",\n    legend=True,\n    categorical=True,\n    scheme=\"fisherjenks\",\n    markersize=300,\n    marker=\"*\",\n    alpha=0.5\n)\n</pre> ax = tissues.plot(     figsize=(10, 15),     alpha=0.1,     column=\"class_name\",     aspect=None ) immune.plot(     ax=ax,     legend=False,     aspect=None ) centroids.plot(     ax=ax,     column=\"distance_to_area_cin\",     cmap=\"turbo\",     legend=True,     categorical=True,     scheme=\"fisherjenks\",     markersize=300,     marker=\"*\",     alpha=0.5 ) Out[10]: <pre>&lt;Axes: &gt;</pre> <p>Let's plot which clusters are within 250 microns from the lesion.</p> In\u00a0[11]: Copied! <pre>ax = tissues.plot(\n    figsize=(10, 15),\n    alpha=0.1,\n    column=\"class_name\",\n    aspect=None\n)\nimmune.plot(\n    ax=ax,\n    legend=False,\n    aspect=None\n)\ncentroids.plot(\n    ax=ax,\n    column=\"clust_within_250_micron_form_lesion\",\n    cmap=\"Paired\",\n    legend=True,\n    categorical=True,\n    markersize=300,\n    marker=\"*\",\n    alpha=0.5\n)\n</pre> ax = tissues.plot(     figsize=(10, 15),     alpha=0.1,     column=\"class_name\",     aspect=None ) immune.plot(     ax=ax,     legend=False,     aspect=None ) centroids.plot(     ax=ax,     column=\"clust_within_250_micron_form_lesion\",     cmap=\"Paired\",     legend=True,     categorical=True,     markersize=300,     marker=\"*\",     alpha=0.5 ) Out[11]: <pre>&lt;Axes: &gt;</pre> <p>We can see from the plot that we have only small clusters residing less than 250 microns from the lesion (when computed from the centroid). Let's now plot the closest tissue per cluster.</p> In\u00a0[12]: Copied! <pre>ax = tissues.plot(\n    figsize=(10, 15),\n    alpha=0.1,\n    column=\"class_name\",\n    aspect=None\n)\nimmune.plot(\n    ax=ax,\n    legend=False,\n    aspect=None\n)\ncentroids.plot(\n    ax=ax,\n    column=\"closest_tissue\",\n    cmap=\"tab20\",\n    legend=True,\n    categorical=True,\n    markersize=300,\n    marker=\"*\",\n    alpha=0.5\n)\n</pre> ax = tissues.plot(     figsize=(10, 15),     alpha=0.1,     column=\"class_name\",     aspect=None ) immune.plot(     ax=ax,     legend=False,     aspect=None ) centroids.plot(     ax=ax,     column=\"closest_tissue\",     cmap=\"tab20\",     legend=True,     categorical=True,     markersize=300,     marker=\"*\",     alpha=0.5 ) Out[12]: <pre>&lt;Axes: &gt;</pre> <p>There is only one cluster centroid that is closest to the lesion, although, we can clearly tell that part of the big cluster is located closer to the lesion than any other tissues. This is a problem with measuring distance from the centroid since if a cluster is very large the centroid of the cluster can be located far away from the tissues of interest. Let's rather plot the distances between the clustered cells and the tissues to see the difference.</p> In\u00a0[13]: Copied! <pre># get the distances to the tissue classes\nimmune = get_distances_to_tissue(immune, tissues, \"area_cin\")\nimmune = get_distances_to_tissue(immune, tissues, \"areasquam\")\nimmune = get_distances_to_tissue(immune, tissues, \"areagland\")\n\n# get the closest tissue class\nimmune[\"closest_tissue\"] = (\n    immune[\n        [\"distance_to_area_cin\", \"distance_to_areasquam\", \"distance_to_areagland\"]\n    ]\n    .idxmin(axis=1)\n    .str.replace(\"distance_to_\", \"closest_to_\")\n)\n\nimmune.head(5)\n</pre> # get the distances to the tissue classes immune = get_distances_to_tissue(immune, tissues, \"area_cin\") immune = get_distances_to_tissue(immune, tissues, \"areasquam\") immune = get_distances_to_tissue(immune, tissues, \"areagland\")  # get the closest tissue class immune[\"closest_tissue\"] = (     immune[         [\"distance_to_area_cin\", \"distance_to_areasquam\", \"distance_to_areagland\"]     ]     .idxmin(axis=1)     .str.replace(\"distance_to_\", \"closest_to_\") )  immune.head(5) Out[13]: geometry labels distance_to_area_cin distance_to_areasquam distance_to_areagland closest_tissue 310 POLYGON ((6990.00000 108951.02000, 6984.01000 ... 6 292.849898 6008.916691 0.0 closest_to_areagland 342 POLYGON ((7144.00000 109740.02000, 7140.01000 ... 7 438.542862 6650.941868 0.0 closest_to_areagland 947 POLYGON ((10332.25000 108920.00000, 10328.8300... 1 2779.557095 4223.818837 0.0 closest_to_areagland 948 POLYGON ((10739.00000 109002.02000, 10737.0100... 1 3165.189791 4152.713902 0.0 closest_to_areagland 971 POLYGON ((9964.00000 109266.02000, 9961.01000 ... 1 2716.858126 4693.418744 0.0 closest_to_areagland In\u00a0[14]: Copied! <pre>ax = tissues.plot(\n    figsize=(10, 15),\n    alpha=0.1,\n    column=\"class_name\",\n    aspect=None\n)\nimmune.plot(\n    ax=ax,\n    column=\"closest_tissue\",\n    legend=True,\n    cmap=\"Paired\",\n    categorical=True,\n    aspect=None\n)\n</pre> ax = tissues.plot(     figsize=(10, 15),     alpha=0.1,     column=\"class_name\",     aspect=None ) immune.plot(     ax=ax,     column=\"closest_tissue\",     legend=True,     cmap=\"Paired\",     categorical=True,     aspect=None ) Out[14]: <pre>&lt;Axes: &gt;</pre> <p>The results didn't change much, but now we see that some of the cells belonging to the big cluster are actually closer to the lesion than other tissues.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/cell_clustering/#cell-clustering","title":"Cell Clustering\u00b6","text":"<p>Like in the previous examples, we have been interested in the clustering of cells. We will continue on this path but instead of computing autocorrelations or other fancy metrics, we will just directly cluster the cells without the use of some proxy metric. Like previously, we will be looking at the distances of the clusters to regions of interest.</p> <p>In this notebook, we will demonstrate how to cluster immune cells in a nuclei segmentation mask. We will also look at different cluster metrics such as the dispersion and centroid of the clusters and their distance to the lesion.</p>"},{"location":"user_guide/cell_clustering/#the-data","title":"The Data\u00b6","text":"<p>The data used in this example is a cervical pre-cancerous biopsy. The data is not publicly available, so this serves only as a demonstration of <code>cellseg_gsontools</code> functionality.</p>"},{"location":"user_guide/cell_clustering/#clustering-immune-cells","title":"Clustering Immune Cells\u00b6","text":"<p>Yet again, we are interested in clustering immune cells. Clustering is simple and <code>cellseg_gsontools</code> provides a simple UI to run clustering: the <code>cluster_points</code> function. The <code>cluster_points</code> function is a wrapper for the DBSCAN related clustering algorithms from the <code>sklearn.cluster</code> module. The allowed clustering algorithms are:</p> <ul> <li>DBSCAN</li> <li>OPTICS</li> <li>HDBSCAN</li> <li>ADBSCAN</li> </ul> <p>We will be using the DBSCAN algorithm for this example. We will set the epsilon parameter to 120 (considers cells within 60 microns) and the minimum number of points to 20 (a cluster has to contain at least 20 points).</p>"},{"location":"user_guide/cell_clustering/#compute-cluster-dispersion","title":"Compute Cluster Dispersion\u00b6","text":"<p>The dispersion of the clusters or the standard deviation of the distances between points in the cluster is an indication of how tightly packed the clusters are. Now we'll computer them to see how tight the immune cell clusters are.</p>"},{"location":"user_guide/cell_clustering/#compute-cluster-centroids","title":"Compute Cluster Centroids\u00b6","text":"<p>Next, we'll compute the mean centers of the clusters. A cluster centroid is basically the mean coordinates of the cluster. We will use these to compute the distance between the cluster centroids and the lesions.</p>"},{"location":"user_guide/cell_clustering/#compute-distances-to-different-tissues","title":"Compute Distances to Different Tissues\u00b6","text":"<p>Next we'll compute the distances between the cluster centroids and the tissues in the sample. We will also get the closest tissue per cluster and all the clusters that are within 250 microns from the lesion.</p>"},{"location":"user_guide/cell_morphology/","title":"Cell/Nuclei Morphology","text":"<p>Cell/nuclei morphologies are often computed to quantify the shape of cells or nuclei. Different morphological metrics can be used, for example, to quantify differences in shapes between cell types or even within a cell type. For example, cells of some type can have varying shape based on their subtype or their localization in the tissue. If you need some intuition on what morphological metrics are, please check out this old but great slide deck from the University of Guelph.</p> <p>In this notebook, We will be looking at the different shape metrics that can be computed with <code>cellseg_gsontools</code>.</p> In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import gland_cells\n\ngc = gland_cells()\ngc.plot(column=\"class_name\", figsize=(10,10), legend=True)\n</pre> from cellseg_gsontools.data import gland_cells  gc = gland_cells() gc.plot(column=\"class_name\", figsize=(10,10), legend=True) Out[1]: <pre>&lt;Axes: &gt;</pre> In\u00a0[2]: Copied! <pre>gc\n</pre> gc Out[2]: type geometry class_name 0 Feature POLYGON ((92.000 1083.984, 95.990 1079.993, 99... glandular_epithel 1 Feature POLYGON ((61.005 1085.988, 64.755 1086.000, 68... glandular_epithel 2 Feature POLYGON ((138.997 1093.988, 142.992 1092.988, ... glandular_epithel 3 Feature POLYGON ((109.005 1092.988, 115.995 1092.988, ... glandular_epithel 4 Feature POLYGON ((69.012 1091.997, 70.011 1094.994, 72... glandular_epithel ... ... ... ... 1354 Feature POLYGON ((1932.004 1671.988, 1936.755 1672.000... glandular_epithel 1355 Feature POLYGON ((1944.005 1691.988, 1951.996 1691.988... glandular_epithel 1356 Feature POLYGON ((1981.005 1723.988, 1985.996 1723.988... glandular_epithel 1357 Feature POLYGON ((1962.007 1726.990, 1965.005 1728.988... glandular_epithel 1358 Feature POLYGON ((1991.012 1739.997, 1992.011 1742.994... glandular_epithel <p>1359 rows \u00d7 3 columns</p> In\u00a0[3]: Copied! <pre>from cellseg_gsontools.geometry import shape_metric\n\nmetrics = [\n    \"area\",\n    \"solidity\",\n    \"major_axis_len\",\n    \"major_axis_angle\",\n    \"minor_axis_len\",\n    \"minor_axis_angle\",\n    \"convexity\",\n    \"compactness\",\n    \"circularity\",\n    \"eccentricity\",\n    \"elongation\",\n    \"equivalent_rectangular_index\",\n    \"rectangularity\",\n    \"squareness\",\n    \"sphericity\",\n    \"shape_index\",\n    \"fractal_dimension\"\n]\n\ngc = shape_metric(\n    gc,\n    metrics=metrics,\n    parallel=True,\n)\n\n# compute perimeter\nmetrics.append(\"perimeter\")\ngc[\"perimeter\"] = gc.length\ngc\n</pre> from cellseg_gsontools.geometry import shape_metric  metrics = [     \"area\",     \"solidity\",     \"major_axis_len\",     \"major_axis_angle\",     \"minor_axis_len\",     \"minor_axis_angle\",     \"convexity\",     \"compactness\",     \"circularity\",     \"eccentricity\",     \"elongation\",     \"equivalent_rectangular_index\",     \"rectangularity\",     \"squareness\",     \"sphericity\",     \"shape_index\",     \"fractal_dimension\" ]  gc = shape_metric(     gc,     metrics=metrics,     parallel=True, )  # compute perimeter metrics.append(\"perimeter\") gc[\"perimeter\"] = gc.length gc Out[3]: type geometry class_name area solidity major_axis_len major_axis_angle minor_axis_len minor_axis_angle convexity ... circularity eccentricity elongation equivalent_rectangular_index rectangularity squareness sphericity shape_index fractal_dimension perimeter 0 Feature POLYGON ((92.000 1083.984, 95.990 1079.993, 99... glandular_epithel 520.239144 0.966439 42.279910 157.380527 15.206325 67.380527 0.998190 ... 0.664169 0.933084 0.599828 0.777647 0.809179 0.842588 0.298672 0.607703 0.933084 99.392555 1 Feature POLYGON ((61.005 1085.988, 64.755 1086.000, 68... glandular_epithel 565.581197 0.979205 42.556314 164.055301 18.107017 74.055301 0.998635 ... 0.720651 0.904966 0.549867 0.702213 0.733980 0.915058 0.377672 0.628537 0.904966 99.445024 2 Feature POLYGON ((138.997 1093.988, 142.992 1092.988, ... glandular_epithel 721.500898 0.992876 45.132745 157.165715 20.639463 67.165715 0.998725 ... 0.764039 0.889310 0.609533 0.729744 0.774545 0.970325 0.417713 0.671005 0.889310 109.073619 3 Feature POLYGON ((109.005 1092.988, 115.995 1092.988, ... glandular_epithel 435.911486 0.982687 35.627477 165.963336 14.965253 75.963336 0.998602 ... 0.734751 0.907502 0.575812 0.772660 0.817578 0.932899 0.370378 0.650374 0.907502 86.465279 4 Feature POLYGON ((69.012 1091.997, 70.011 1094.994, 72... glandular_epithel 302.260204 1.000000 22.618201 134.951251 14.843037 44.951251 1.000000 ... 0.869898 0.754550 0.999997 0.836853 0.900327 1.107589 0.582249 0.807680 0.754550 66.078655 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1354 Feature POLYGON ((1932.004 1671.988, 1936.755 1672.000... glandular_epithel 473.859283 1.000000 36.154051 155.225946 15.899675 65.225946 1.000000 ... 0.767510 0.898108 0.687020 0.768171 0.824336 0.977224 0.396189 0.674762 0.898108 88.082112 1355 Feature POLYGON ((1944.005 1691.988, 1951.996 1691.988... glandular_epithel 803.788422 0.993490 51.851271 153.435627 19.205898 63.435627 0.999133 ... 0.705127 0.928871 0.595539 0.757277 0.807138 0.896240 0.344882 0.616768 0.928871 119.789518 1356 Feature POLYGON ((1981.005 1723.988, 1985.996 1723.988... glandular_epithel 603.424619 0.995804 46.700700 162.474799 17.039395 72.474799 0.999346 ... 0.675694 0.931061 0.511644 0.724112 0.758308 0.859195 0.324170 0.589923 0.931061 106.004838 1357 Feature POLYGON ((1962.007 1726.990, 1965.005 1728.988... glandular_epithel 509.535284 1.000000 33.989143 0.026300 17.986912 90.026300 1.000000 ... 0.829131 0.848500 0.529248 0.771767 0.833446 1.055682 0.466899 0.743267 0.848500 87.878070 1358 Feature POLYGON ((1991.012 1739.997, 1992.011 1742.994... glandular_epithel 163.492979 0.851175 33.228779 180.000000 8.988087 90.000000 0.990231 ... 0.359102 0.962722 0.270491 0.669348 0.547416 0.448333 0.212360 0.424890 0.962722 76.385164 <p>1359 rows \u00d7 21 columns</p> In\u00a0[4]: Copied! <pre># !pip install seaborn\n</pre> # !pip install seaborn In\u00a0[5]: Copied! <pre>import seaborn\n\n# Let's first define a quick function to plot the data distributions with seaborn\ndef plot_kde(tidy_data):\n    seaborn.set_style(\"whitegrid\")\n    seaborn.set(font_scale=1.5)\n\n    # Setup the facets\n    facets = seaborn.FacetGrid(\n        data=tidy_data,\n        col=\"Attribute\",\n        hue=\"Cell Type\",\n        sharey=False,\n        sharex=False,\n        aspect=2,\n        col_wrap=2,\n    )\n\n    # Build the plot from `sns.kdeplot`\n    kde_ax = facets.map(seaborn.kdeplot, \"Values\", fill=True).add_legend()\n    return kde_ax\n</pre> import seaborn  # Let's first define a quick function to plot the data distributions with seaborn def plot_kde(tidy_data):     seaborn.set_style(\"whitegrid\")     seaborn.set(font_scale=1.5)      # Setup the facets     facets = seaborn.FacetGrid(         data=tidy_data,         col=\"Attribute\",         hue=\"Cell Type\",         sharey=False,         sharex=False,         aspect=2,         col_wrap=2,     )      # Build the plot from `sns.kdeplot`     kde_ax = facets.map(seaborn.kdeplot, \"Values\", fill=True).add_legend()     return kde_ax <p>Let's tidy up the data first</p> In\u00a0[6]: Copied! <pre>m = list(metrics)\ntidy = gc.reset_index().set_index(\"class_name\")\ntidy = tidy[m]\ntidy = tidy.stack()\ntidy = tidy.reset_index()\ntidy = tidy.rename(\n    columns={\"class_name\": \"Cell Type\", \"level_1\": \"Attribute\", 0: \"Values\"}\n)\ntidy\n</pre> m = list(metrics) tidy = gc.reset_index().set_index(\"class_name\") tidy = tidy[m] tidy = tidy.stack() tidy = tidy.reset_index() tidy = tidy.rename(     columns={\"class_name\": \"Cell Type\", \"level_1\": \"Attribute\", 0: \"Values\"} ) tidy Out[6]: Cell Type Attribute Values 0 glandular_epithel area 520.239144 1 glandular_epithel solidity 0.966439 2 glandular_epithel major_axis_len 42.279910 3 glandular_epithel major_axis_angle 157.380527 4 glandular_epithel minor_axis_len 15.206325 ... ... ... ... 24457 glandular_epithel squareness 0.448333 24458 glandular_epithel sphericity 0.212360 24459 glandular_epithel shape_index 0.424890 24460 glandular_epithel fractal_dimension 0.962722 24461 glandular_epithel perimeter 76.385164 <p>24462 rows \u00d7 3 columns</p> In\u00a0[7]: Copied! <pre>plot_kde(tidy)\n</pre> plot_kde(tidy) Out[7]: <pre>&lt;seaborn.axisgrid.FacetGrid at 0x7ffb14f77cd0&gt;</pre> <p>We can clearly see that the inflammatory cells differ from the stormal and glandular cells based on the distributions. They tend to be smaller, more circular, compact, spherical and have a lower major axis length, eccentricity and fractal dimension (fractal dimension measures the complexity of the boundary). This is in line with what we would expect from inflammatory cells, since they are a lot smaller and have less variance in their shapes than stromal or epithelial cells. On the other hand, the glandular epithelial cells and stromal/connective cells are much more similar in their shape distributions.</p> In\u00a0[8]: Copied! <pre># !pip install legendgram\n</pre> # !pip install legendgram In\u00a0[9]: Copied! <pre>import mapclassify\nimport geopandas as gpd\nimport matplotlib.pyplot as plt\nimport palettable as palet\nfrom legendgram import legendgram\n\n\n# helper function to replace legend items\ndef replace_legend_items(legend, mapping):\n    for txt in legend.texts:\n        for k, v in mapping.items():\n            if txt.get_text() == str(k):\n                txt.set_text(v)\n    \n\n# Helper function to plot cells with a feature value highlighted\ndef plot_cells(f, ax, cells: gpd.GeoDataFrame, col: str):\n    # bin the values with the Fisher-Jenks method\n    bins = mapclassify.FisherJenks(cells[col], k=5)\n    cells[\"bin_vals\"] = bins.yb\n\n    ax = cells.plot(\n        ax=ax,\n        column=\"bin_vals\",\n        cmap=\"viridis\",\n        categorical=True,\n        legend=True,\n        legend_kwds={\n            \"fontsize\": 8,\n            \"loc\": \"center left\",\n            \"bbox_to_anchor\": (1.0, 0.94),\n        },\n    )\n\n    bin_legends = bins.get_legend_classes()\n    mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n    replace_legend_items(ax.get_legend(), mapping)\n    ax.set_title(col)\n    ax = legendgram(\n        f,\n        ax,\n        cells[col],\n        bins=30,\n        breaks=bins.bins,\n        pal=palet.matplotlib.Viridis_5,\n        loc=\"lower left\",\n    )\n    ax.set_axis_off()\n\n    return ax\n\nfig, ax = plt.subplots(9, 2, figsize=(13, 43))\nax = ax.flatten()\nplot_cells(fig, ax[0], gc, \"area\")\nplot_cells(fig, ax[1], gc, \"solidity\")\nplot_cells(fig, ax[2], gc, \"major_axis_len\")\nplot_cells(fig, ax[3], gc, \"major_axis_angle\")\nplot_cells(fig, ax[4], gc, \"minor_axis_len\")\nplot_cells(fig, ax[5], gc, \"minor_axis_angle\")\nplot_cells(fig, ax[6], gc, \"convexity\")\nplot_cells(fig, ax[7], gc, \"compactness\")\nplot_cells(fig, ax[8], gc, \"circularity\")\nplot_cells(fig, ax[9], gc, \"eccentricity\")\nplot_cells(fig, ax[10], gc, \"elongation\")\nplot_cells(fig, ax[11], gc, \"equivalent_rectangular_index\")\nplot_cells(fig, ax[12], gc, \"rectangularity\")\nplot_cells(fig, ax[13], gc, \"squareness\")\nplot_cells(fig, ax[14], gc, \"sphericity\")\nplot_cells(fig, ax[15], gc, \"shape_index\")\nplot_cells(fig, ax[16], gc, \"fractal_dimension\")\nplot_cells(fig, ax[17], gc, \"perimeter\")\n</pre> import mapclassify import geopandas as gpd import matplotlib.pyplot as plt import palettable as palet from legendgram import legendgram   # helper function to replace legend items def replace_legend_items(legend, mapping):     for txt in legend.texts:         for k, v in mapping.items():             if txt.get_text() == str(k):                 txt.set_text(v)       # Helper function to plot cells with a feature value highlighted def plot_cells(f, ax, cells: gpd.GeoDataFrame, col: str):     # bin the values with the Fisher-Jenks method     bins = mapclassify.FisherJenks(cells[col], k=5)     cells[\"bin_vals\"] = bins.yb      ax = cells.plot(         ax=ax,         column=\"bin_vals\",         cmap=\"viridis\",         categorical=True,         legend=True,         legend_kwds={             \"fontsize\": 8,             \"loc\": \"center left\",             \"bbox_to_anchor\": (1.0, 0.94),         },     )      bin_legends = bins.get_legend_classes()     mapping = dict([(i, s) for i, s in enumerate(bin_legends)])     replace_legend_items(ax.get_legend(), mapping)     ax.set_title(col)     ax = legendgram(         f,         ax,         cells[col],         bins=30,         breaks=bins.bins,         pal=palet.matplotlib.Viridis_5,         loc=\"lower left\",     )     ax.set_axis_off()      return ax  fig, ax = plt.subplots(9, 2, figsize=(13, 43)) ax = ax.flatten() plot_cells(fig, ax[0], gc, \"area\") plot_cells(fig, ax[1], gc, \"solidity\") plot_cells(fig, ax[2], gc, \"major_axis_len\") plot_cells(fig, ax[3], gc, \"major_axis_angle\") plot_cells(fig, ax[4], gc, \"minor_axis_len\") plot_cells(fig, ax[5], gc, \"minor_axis_angle\") plot_cells(fig, ax[6], gc, \"convexity\") plot_cells(fig, ax[7], gc, \"compactness\") plot_cells(fig, ax[8], gc, \"circularity\") plot_cells(fig, ax[9], gc, \"eccentricity\") plot_cells(fig, ax[10], gc, \"elongation\") plot_cells(fig, ax[11], gc, \"equivalent_rectangular_index\") plot_cells(fig, ax[12], gc, \"rectangularity\") plot_cells(fig, ax[13], gc, \"squareness\") plot_cells(fig, ax[14], gc, \"sphericity\") plot_cells(fig, ax[15], gc, \"shape_index\") plot_cells(fig, ax[16], gc, \"fractal_dimension\") plot_cells(fig, ax[17], gc, \"perimeter\")  Out[9]: <pre>&lt;Axes: &gt;</pre> <p>From the plot above, we can see some spatial patterns. For example, we can see that the high eccentricity and high fractal dimension cells are located in the upper glandular epithelium. We can also see that the largest cells are located in the center of the image in the stroma and the high sphericity cells seem to be mostly the immune cells in the stroma. All of the cells seem to be quite solid and non-convex meaning that there are little irregular boundaries among the cells. All of these results are expected and in line with what we would expect from the different cell types.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/cell_morphology/#cellnuclei-morphology","title":"Cell/Nuclei Morphology\u00b6","text":""},{"location":"user_guide/cell_morphology/#the-data","title":"The Data\u00b6","text":"<p>We'll be taking a look at some glandular epithelial cells and their shapes espically. <code>cellseg_gsontools</code> provides a small example segmentation mask that contains a lot glandular epithelial cells.</p>"},{"location":"user_guide/cell_morphology/#computing-morphological-metrics","title":"Computing Morphological Metrics\u00b6","text":"<p>We will compute all of the different morphological metrics that are available in <code>cellseg_gsontools</code> and then visualize them. The morphological metrics can be computed with the <code>shape_metric</code>-function. The available metrics are:</p> <ul> <li>Area</li> <li>Perimeter</li> <li>Solidity</li> <li>Major Axis Length</li> <li>Minor Axis Length</li> <li>Major Axis Angle</li> <li>Minor Axis Angle</li> <li>Convexity</li> <li>Compactness</li> <li>Circularity</li> <li>Eccentricity</li> <li>Elongation</li> <li>Equivalent Recatangular Index</li> <li>Rectangularity</li> <li>Squareness</li> <li>Sphericity</li> <li>Shape Index</li> <li>Fractal Dimension</li> </ul>"},{"location":"user_guide/cell_morphology/#plotting-the-metrics","title":"Plotting the Metrics\u00b6","text":"<p>Let's start plotting these metrics if we can see some differences between the cell types present.</p>"},{"location":"user_guide/cell_morphology/#spatial-distributions-of-morphological-metrics","title":"Spatial Distributions of Morphological Metrics\u00b6","text":"<p>Let's now look at how the metrics distribute spatially.</p>"},{"location":"user_guide/cell_neighborhood_characteristics/","title":"Cell/Nuclei Neighborhood Distances and Characteristics","text":"In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import tumor_stroma_intreface_cells\n\ntsc = tumor_stroma_intreface_cells()\ntsc.plot(column=\"class_name\", figsize=(10,10), legend=True)\n</pre> from cellseg_gsontools.data import tumor_stroma_intreface_cells  tsc = tumor_stroma_intreface_cells() tsc.plot(column=\"class_name\", figsize=(10,10), legend=True) Out[1]: <pre>&lt;Axes: &gt;</pre> In\u00a0[2]: Copied! <pre>from cellseg_gsontools.graphs import fit_graph\nfrom cellseg_gsontools.utils import set_uid\n\n# To fit the delaunay graph, we need to set a unique id for each cell first\ntsc = set_uid(tsc, id_col=\"uid\")\nw = fit_graph(tsc, type=\"delaunay\", thresh=100, id_col=\"uid\")\nw\n</pre> from cellseg_gsontools.graphs import fit_graph from cellseg_gsontools.utils import set_uid  # To fit the delaunay graph, we need to set a unique id for each cell first tsc = set_uid(tsc, id_col=\"uid\") w = fit_graph(tsc, type=\"delaunay\", thresh=100, id_col=\"uid\") w Out[2]: <pre>&lt;libpysal.weights.weights.W at 0x7fa52ba9f130&gt;</pre> In\u00a0[3]: Copied! <pre># let's convert the graph to a dataframe and plot it\nfrom cellseg_gsontools.links import weights2gdf\n\nwdf = weights2gdf(tsc, w)\nax = tsc.plot(column=\"class_name\", figsize=(10,10), legend=True)\nwdf.plot(\n    ax=ax,\n    linewidth=0.5,\n    column=\"class_name\",\n    cmap=\"Set1_r\",\n    legend=True,\n    legend_kwds={\n        \"loc\": \"center left\",\n        \"bbox_to_anchor\": (1.0, 0.91)\n    }\n)\n</pre> # let's convert the graph to a dataframe and plot it from cellseg_gsontools.links import weights2gdf  wdf = weights2gdf(tsc, w) ax = tsc.plot(column=\"class_name\", figsize=(10,10), legend=True) wdf.plot(     ax=ax,     linewidth=0.5,     column=\"class_name\",     cmap=\"Set1_r\",     legend=True,     legend_kwds={         \"loc\": \"center left\",         \"bbox_to_anchor\": (1.0, 0.91)     } ) Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>from cellseg_gsontools.geometry import shape_metric\n\n# let's first compute a couple shape metrics\nmetrics = [\n    \"area\",\n    \"eccentricity\",\n    \"sphericity\",\n    \"fractal_dimension\"\n]\n\ntsc = shape_metric(\n    tsc,\n    metrics=metrics,\n    parallel=True,\n)\n\ntsc.head(4)\n</pre> from cellseg_gsontools.geometry import shape_metric  # let's first compute a couple shape metrics metrics = [     \"area\",     \"eccentricity\",     \"sphericity\",     \"fractal_dimension\" ]  tsc = shape_metric(     tsc,     metrics=metrics,     parallel=True, )  tsc.head(4) Out[4]: type geometry class_name uid area eccentricity sphericity fractal_dimension uid 0 Feature POLYGON ((169.012 42.997, 170.011 45.994, 174.... neoplastic 0 943.538625 0.405200 0.794631 0.405200 1 Feature POLYGON ((183.996 97.988, 192.079 94.544, 194.... neoplastic 1 1075.707286 0.435784 0.553602 0.435784 2 Feature POLYGON ((130.006 97.989, 133.003 98.988, 136.... neoplastic 2 1044.121328 0.822321 0.496494 0.822321 3 Feature POLYGON ((63.174 103.174, 70.007 109.990, 72.0... neoplastic 3 833.673039 0.795212 0.556992 0.795212 In\u00a0[5]: Copied! <pre>import mapclassify\nimport matplotlib.pyplot as plt\nimport geopandas as gpd\nimport palettable as palet\nfrom legendgram import legendgram\n\n# helper function to replace legend items\ndef replace_legend_items(legend, mapping):\n    for txt in legend.texts:\n        for k, v in mapping.items():\n            if txt.get_text() == str(k):\n                txt.set_text(v)\n\n\n# Helper function to plot cells with a feature value highlighted\ndef plot_cells(f, ax, cells: gpd.GeoDataFrame, col: str):\n    # bin the values with the Fisher-Jenks method\n    bins = mapclassify.FisherJenks(cells[col], k=5)\n    cells[\"bin_vals\"] = bins.yb\n\n    ax = cells.plot(\n        ax=ax,\n        column=\"bin_vals\",\n        cmap=\"viridis\",\n        categorical=True,\n        legend=True,\n        legend_kwds={\n            \"fontsize\": 8,\n            \"loc\": \"center left\",\n            \"bbox_to_anchor\": (1.0, 0.88),\n        },\n    )\n\n    bin_legends = bins.get_legend_classes()\n    mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n    replace_legend_items(ax.get_legend(), mapping)\n    ax.set_axis_off()\n    ax.set_title(col)\n    ax = legendgram(\n        f,\n        ax,\n        cells[col],\n        bins=30,\n        breaks=bins.bins,\n        pal=palet.matplotlib.Viridis_5,\n        loc=\"lower left\",\n    )\n    ax.set_axis_off()\n\n    return ax\n\nfig, ax = plt.subplots(2, 2, figsize=(16, 15))\nax = ax.flatten()\nplot_cells(fig, ax[0], tsc, \"area\")\nplot_cells(fig, ax[1], tsc, \"eccentricity\")\nplot_cells(fig, ax[2], tsc, \"sphericity\")\nplot_cells(fig, ax[3], tsc, \"fractal_dimension\")\n</pre> import mapclassify import matplotlib.pyplot as plt import geopandas as gpd import palettable as palet from legendgram import legendgram  # helper function to replace legend items def replace_legend_items(legend, mapping):     for txt in legend.texts:         for k, v in mapping.items():             if txt.get_text() == str(k):                 txt.set_text(v)   # Helper function to plot cells with a feature value highlighted def plot_cells(f, ax, cells: gpd.GeoDataFrame, col: str):     # bin the values with the Fisher-Jenks method     bins = mapclassify.FisherJenks(cells[col], k=5)     cells[\"bin_vals\"] = bins.yb      ax = cells.plot(         ax=ax,         column=\"bin_vals\",         cmap=\"viridis\",         categorical=True,         legend=True,         legend_kwds={             \"fontsize\": 8,             \"loc\": \"center left\",             \"bbox_to_anchor\": (1.0, 0.88),         },     )      bin_legends = bins.get_legend_classes()     mapping = dict([(i, s) for i, s in enumerate(bin_legends)])     replace_legend_items(ax.get_legend(), mapping)     ax.set_axis_off()     ax.set_title(col)     ax = legendgram(         f,         ax,         cells[col],         bins=30,         breaks=bins.bins,         pal=palet.matplotlib.Viridis_5,         loc=\"lower left\",     )     ax.set_axis_off()      return ax  fig, ax = plt.subplots(2, 2, figsize=(16, 15)) ax = ax.flatten() plot_cells(fig, ax[0], tsc, \"area\") plot_cells(fig, ax[1], tsc, \"eccentricity\") plot_cells(fig, ax[2], tsc, \"sphericity\") plot_cells(fig, ax[3], tsc, \"fractal_dimension\")  Out[5]: <pre>&lt;Axes: &gt;</pre> In\u00a0[6]: Copied! <pre>from cellseg_gsontools.character import local_character\n\ntsc = local_character(\n    tsc,\n    w,\n    val_col=(\"eccentricity\", \"area\"),\n    id_col=\"uid\",\n    reductions=(\"mean\", \"std\"),\n    parallel=True,\n)\n\ntsc.head(4)\n</pre> from cellseg_gsontools.character import local_character  tsc = local_character(     tsc,     w,     val_col=(\"eccentricity\", \"area\"),     id_col=\"uid\",     reductions=(\"mean\", \"std\"),     parallel=True, )  tsc.head(4) Out[6]: type geometry class_name uid area eccentricity sphericity fractal_dimension bin_vals eccentricity_nhood_mean eccentricity_nhood_std area_nhood_mean area_nhood_std uid 0 Feature POLYGON ((169.012 42.997, 170.011 45.994, 174.... neoplastic 0 943.538625 0.405200 0.794631 0.405200 1 0.609431 0.179600 888.701111 350.895749 1 Feature POLYGON ((183.996 97.988, 192.079 94.544, 194.... neoplastic 1 1075.707286 0.435784 0.553602 0.435784 1 0.534537 0.205870 933.802622 335.974217 2 Feature POLYGON ((130.006 97.989, 133.003 98.988, 136.... neoplastic 2 1044.121328 0.822321 0.496494 0.822321 4 0.491460 0.236136 1035.535479 116.271775 3 Feature POLYGON ((63.174 103.174, 70.007 109.990, 72.0... neoplastic 3 833.673039 0.795212 0.556992 0.795212 3 0.724457 0.233204 1004.582806 488.473078 In\u00a0[7]: Copied! <pre># Aand some plots\ndef plot_character(ax, cells, col, plot_weights=True, cmap=\"viridis\"):\n    # bin the values with the FisherJenks method for visualization\n    bins = mapclassify.FisherJenks(cells[col], k=5)\n    cells[\"bin_vals\"] = bins.yb\n    ax = cells.plot(\n        ax=ax,\n        column=\"bin_vals\",\n        categorical=True,\n        cmap=cmap,\n        legend=True,\n        legend_kwds={\n            \"fontsize\": 8,\n            \"loc\": \"center left\",\n            \"bbox_to_anchor\": (1.0, 0.90),\n        },\n    )\n\n    bin_legends = bins.get_legend_classes()\n    mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n    replace_legend_items(ax.get_legend(), mapping)\n    ax.set_title(col)\n    \n    if plot_weights:\n        ax = wdf.plot(\n            ax=ax,\n            linewidth=0.5,\n            column=\"class_name\",\n            cmap=\"Set1_r\",\n        )\n    ax.set_axis_off()\n\n    return ax\n\n\nfig, ax = plt.subplots(2, 2, figsize=(15, 15))\nax = ax.flatten()\n\nplot_character(ax[0], tsc, \"area_nhood_mean\", plot_weights=True)\nplot_character(ax[1], tsc, \"area_nhood_std\", plot_weights=True)\nplot_character(ax[2], tsc, \"eccentricity_nhood_mean\", plot_weights=True)\nplot_character(ax[3], tsc, \"eccentricity_nhood_std\", plot_weights=True)\n</pre> # Aand some plots def plot_character(ax, cells, col, plot_weights=True, cmap=\"viridis\"):     # bin the values with the FisherJenks method for visualization     bins = mapclassify.FisherJenks(cells[col], k=5)     cells[\"bin_vals\"] = bins.yb     ax = cells.plot(         ax=ax,         column=\"bin_vals\",         categorical=True,         cmap=cmap,         legend=True,         legend_kwds={             \"fontsize\": 8,             \"loc\": \"center left\",             \"bbox_to_anchor\": (1.0, 0.90),         },     )      bin_legends = bins.get_legend_classes()     mapping = dict([(i, s) for i, s in enumerate(bin_legends)])     replace_legend_items(ax.get_legend(), mapping)     ax.set_title(col)          if plot_weights:         ax = wdf.plot(             ax=ax,             linewidth=0.5,             column=\"class_name\",             cmap=\"Set1_r\",         )     ax.set_axis_off()      return ax   fig, ax = plt.subplots(2, 2, figsize=(15, 15)) ax = ax.flatten()  plot_character(ax[0], tsc, \"area_nhood_mean\", plot_weights=True) plot_character(ax[1], tsc, \"area_nhood_std\", plot_weights=True) plot_character(ax[2], tsc, \"eccentricity_nhood_mean\", plot_weights=True) plot_character(ax[3], tsc, \"eccentricity_nhood_std\", plot_weights=True) Out[7]: <pre>&lt;Axes: title={'center': 'eccentricity_nhood_std'}&gt;</pre> <p>Based on the plot, the high eccentricity neighborhoods tend to cluster around the blood vessels and the tumor-stroma interface. The high area neighborhoods are more evenly distributed, although, they reside in the tumor tissue since tumor cells tend to be larger than stromal cells. The cells with high area or eccentricity standard deviation seem to be scattered quite randomly in places where there are abundance of differently shaped cells, that is in the tumor area. Thus, we can conclude that the tumor cells tend to have more variance in their shapes than the stromal cells from this plot.</p> In\u00a0[8]: Copied! <pre>from cellseg_gsontools.character import local_distances\n\ntsc = local_distances(\n    tsc,\n    w,\n    id_col=\"uid\",\n    reductions=(\"mean\", \"std\"),\n    invert=False,\n    parallel=True,\n)\n\ntsc[[\"geometry\", \"class_name\", \"nhood_dists_mean\", \"nhood_dists_std\"]].head(4)\n</pre> from cellseg_gsontools.character import local_distances  tsc = local_distances(     tsc,     w,     id_col=\"uid\",     reductions=(\"mean\", \"std\"),     invert=False,     parallel=True, )  tsc[[\"geometry\", \"class_name\", \"nhood_dists_mean\", \"nhood_dists_std\"]].head(4) Out[8]: geometry class_name nhood_dists_mean nhood_dists_std uid 0 POLYGON ((169.012 42.997, 170.011 45.994, 174.... neoplastic 43.8952 25.682826 1 POLYGON ((183.996 97.988, 192.079 94.544, 194.... neoplastic 38.8290 17.875030 2 POLYGON ((130.006 97.989, 133.003 98.988, 136.... neoplastic 48.5410 24.549408 3 POLYGON ((63.174 103.174, 70.007 109.990, 72.0... neoplastic 49.6515 26.040834 In\u00a0[9]: Copied! <pre>fig, ax = plt.subplots(1, 2, figsize=(15, 15))\nax = ax.flatten()\n\n# let's not plot the weights to see the effect of the distance better\nplot_character(ax[0], tsc, \"nhood_dists_mean\", plot_weights=False, cmap=\"viridis_r\")\nplot_character(ax[1], tsc, \"nhood_dists_std\", plot_weights=False, cmap=\"viridis_r\")\n</pre> fig, ax = plt.subplots(1, 2, figsize=(15, 15)) ax = ax.flatten()  # let's not plot the weights to see the effect of the distance better plot_character(ax[0], tsc, \"nhood_dists_mean\", plot_weights=False, cmap=\"viridis_r\") plot_character(ax[1], tsc, \"nhood_dists_std\", plot_weights=False, cmap=\"viridis_r\") Out[9]: <pre>&lt;Axes: title={'center': 'nhood_dists_std'}&gt;</pre> <p>We can see that by computing the neighborhood distances, we can easily highlight the densely packed cells. In this example, the densely packed cells are lymphocytes residing close to the tumor-stroma interface. These kind of immune clusters are of interest when researching the immune response of the tumor.</p>"},{"location":"user_guide/cell_neighborhood_characteristics/#cellnuclei-neighborhood-distances-and-characteristics","title":"Cell/Nuclei Neighborhood Distances and Characteristics\u00b6","text":"<p>The neighborhood of a cell is defined by the cells that are within a certain distance from the cell. These neighborhoods show spatial patterns related to cell-cell interactions. Often, we are interested in some reduced summaries (mean/median etc) of the neighborhoods (neighborhood characteristics) that can tell us whether there exist some non-random patterns in the spatial distribution of the cell-cell interactions.</p> <p>In this notebook, we will be looking at computing neighborhood characters and also take a look at computing neighborhood distances of the cells.</p>"},{"location":"user_guide/cell_neighborhood_characteristics/#the-data","title":"The Data\u00b6","text":"<p>We'll be taking a look at a small tile of cells at the tumor-stroma interface i.e. at the border where the tumor meets stroma. The tumor in the data also contains a couple small blood vessels that introduce tumor-stroma interface within the tumor.</p>"},{"location":"user_guide/cell_neighborhood_characteristics/#spatial-weights","title":"Spatial Weights\u00b6","text":"<p>To get the neighborhoods of the cells, we will first fit a connectivity graph (called spatial weights in geospatial analysis jargon) to the <code>GeoDataFrame</code>. <code>cellseg_gsontools</code> provides a <code>fit_graph</code> function which can be used to do that. The actual fitting is done with the <code>libpysal</code> package and the <code>fit_graph</code>-function is basically a wrapper around different graph fitting methods. The allowed spatial weights are:</p> <ul> <li><code>knn</code>: k-nearest neighbors</li> <li><code>delaunay</code> - Delaunay triangulation</li> <li><code>distband</code> - Distance band i.e. a distance thresholded knn graph</li> <li><code>relative_nhood</code> - Relative neighborhood graph</li> </ul> <p>We will be using the <code>delaunay</code> method in this example, however, note that for large data the <code>delaunay</code> method can get quite slow and for example the <code>distband</code> method is a lot faster. Here, we will set a distance threshold for the neighbors to be within 50 microns of the cell centroid. The distance unit in the example data is in pixels so 50 microns in pixels of 20x magnified segmentation mask is around 50*2 = 100 pixels.</p>"},{"location":"user_guide/cell_neighborhood_characteristics/#neighborhood-characters","title":"Neighborhood Characters\u00b6","text":"<p>To compute neighborhood character, we first need to compute some real valued columns to the <code>GeoDataFrame</code>. These columns will be used to compute the neighborhood characters. The <code>cellseg_gsontools</code> package provides a <code>local_characters</code> function for this purpose. But first, let's use the <code>shape_metric</code>-function to compute some morphological features.</p>"},{"location":"user_guide/cell_neighborhood_characteristics/#computing-morphological-features","title":"Computing Morphological Features\u00b6","text":""},{"location":"user_guide/cell_neighborhood_characteristics/#computing-neighborhood-characters","title":"Computing Neighborhood Characters\u00b6","text":"<p>Let's now compute the neighborhood characteristics. We will reduce the neighborhood feature values with mean and std.</p>"},{"location":"user_guide/cell_neighborhood_characteristics/#neighborhood-distances","title":"Neighborhood Distances\u00b6","text":"<p>Let's now compute some neighborhood distances. The mean distances of the neighborhoods can be computed with the <code>local_distances</code>-function. The mean neighborhood distances highlight the cells whose neighbors are either densely packed or further apart. It is a nice way of highlighting dense clusters of cells in a segmentation map. Here, we will invert the color map of the plot so that the densely packed cells are highlighted instead of the cells whose neighbors are far apart.</p>"},{"location":"user_guide/cell_neighborhood_diversity/","title":"Cell/Nuclei Neighborhood Diversities","text":"In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import tumor_stroma_intreface_cells\n\ntsc = tumor_stroma_intreface_cells()\ntsc.plot(column=\"class_name\", figsize=(10,10), legend=True)\n</pre> from cellseg_gsontools.data import tumor_stroma_intreface_cells  tsc = tumor_stroma_intreface_cells() tsc.plot(column=\"class_name\", figsize=(10,10), legend=True) Out[1]: <pre>&lt;Axes: &gt;</pre> In\u00a0[2]: Copied! <pre>tsc\n</pre> tsc Out[2]: type geometry class_name 0 Feature POLYGON ((169.012 42.997, 170.011 45.994, 174.... neoplastic 1 Feature POLYGON ((183.996 97.988, 192.079 94.544, 194.... neoplastic 2 Feature POLYGON ((130.006 97.989, 133.003 98.988, 136.... neoplastic 3 Feature POLYGON ((63.174 103.174, 70.007 109.990, 72.0... neoplastic 4 Feature POLYGON ((122.012 131.995, 125.007 135.990, 13... neoplastic ... ... ... ... 1236 Feature POLYGON ((1853.012 1950.996, 1854.010 1952.993... connective 1237 Feature POLYGON ((1774.012 1955.996, 1775.010 1957.993... connective 1238 Feature POLYGON ((1751.012 1965.997, 1752.011 1968.994... connective 1239 Feature POLYGON ((1758.012 1984.997, 1759.011 1987.995... inflammatory 1240 Feature POLYGON ((1937.012 1988.996, 1938.010 1990.993... connective <p>1241 rows \u00d7 3 columns</p> In\u00a0[3]: Copied! <pre>from cellseg_gsontools.graphs import fit_graph\nfrom cellseg_gsontools.utils import set_uid\n\n# To fit the delaunay graph, we need to set a unique id for each cell first\ntsc = set_uid(tsc, id_col=\"uid\")\nw = fit_graph(tsc, type=\"delaunay\", thresh=100, id_col=\"uid\")\nw\n</pre> from cellseg_gsontools.graphs import fit_graph from cellseg_gsontools.utils import set_uid  # To fit the delaunay graph, we need to set a unique id for each cell first tsc = set_uid(tsc, id_col=\"uid\") w = fit_graph(tsc, type=\"delaunay\", thresh=100, id_col=\"uid\") w Out[3]: <pre>&lt;libpysal.weights.weights.W at 0x7fc396b7f850&gt;</pre> In\u00a0[4]: Copied! <pre># let's convert the graph to a dataframe and plot it\nfrom cellseg_gsontools.links import weights2gdf\n\nwdf = weights2gdf(tsc, w)\nax = tsc.plot(column=\"class_name\", figsize=(10,10), legend=True)\nwdf.plot(\n    ax=ax,\n    linewidth=0.5,\n    column=\"class_name\",\n    cmap=\"Set1_r\",\n    legend=True,\n    legend_kwds={\n        \"loc\": \"center left\",\n        \"bbox_to_anchor\": (1.0, 0.91)\n    }\n)\n</pre> # let's convert the graph to a dataframe and plot it from cellseg_gsontools.links import weights2gdf  wdf = weights2gdf(tsc, w) ax = tsc.plot(column=\"class_name\", figsize=(10,10), legend=True) wdf.plot(     ax=ax,     linewidth=0.5,     column=\"class_name\",     cmap=\"Set1_r\",     legend=True,     legend_kwds={         \"loc\": \"center left\",         \"bbox_to_anchor\": (1.0, 0.91)     } ) Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre>from cellseg_gsontools.diversity import local_diversity\n\ntsc = local_diversity(\n    tsc,\n    w,\n    val_col=\"class_name\",\n    id_col=\"uid\",\n    metrics=(\"simpson_index\", \"shannon_index\"),\n    parallel=True,\n)\n\ntsc\n</pre> from cellseg_gsontools.diversity import local_diversity  tsc = local_diversity(     tsc,     w,     val_col=\"class_name\",     id_col=\"uid\",     metrics=(\"simpson_index\", \"shannon_index\"),     parallel=True, )  tsc Out[5]: type geometry class_name uid class_name_simpson_index class_name_shannon_index uid 0 Feature POLYGON ((169.012 42.997, 170.011 45.994, 174.... neoplastic 0 0.000000 0.000000 1 Feature POLYGON ((183.996 97.988, 192.079 94.544, 194.... neoplastic 1 0.000000 0.000000 2 Feature POLYGON ((130.006 97.989, 133.003 98.988, 136.... neoplastic 2 0.000000 0.000000 3 Feature POLYGON ((63.174 103.174, 70.007 109.990, 72.0... neoplastic 3 0.000000 0.000000 4 Feature POLYGON ((122.012 131.995, 125.007 135.990, 13... neoplastic 4 0.000000 0.000000 ... ... ... ... ... ... ... 1236 Feature POLYGON ((1853.012 1950.996, 1854.010 1952.993... connective 1236 0.320000 0.500402 1237 Feature POLYGON ((1774.012 1955.996, 1775.010 1957.993... connective 1237 0.320000 0.500402 1238 Feature POLYGON ((1751.012 1965.997, 1752.011 1968.994... connective 1238 0.244898 0.410116 1239 Feature POLYGON ((1758.012 1984.997, 1759.011 1987.995... inflammatory 1239 0.320000 0.500402 1240 Feature POLYGON ((1937.012 1988.996, 1938.010 1990.993... connective 1240 0.320000 0.500402 <p>1241 rows \u00d7 6 columns</p> <p>Let's plot the diversity metrics</p> In\u00a0[6]: Copied! <pre>import matplotlib.pyplot as plt\nimport mapclassify\n\n# helper function to replace legend items\ndef replace_legend_items(legend, mapping):\n    for txt in legend.texts:\n        for k, v in mapping.items():\n            if txt.get_text() == str(k):\n                txt.set_text(v)\n\n\ndef plot_diversity(ax, cells, col, plot_weights=True):\n    # bin the values with the FisherJenks method for visualization\n    bins = mapclassify.FisherJenks(cells[col], k=5)\n    cells[\"bin_vals\"] = bins.yb\n    ax = cells.plot(\n        ax=ax,\n        column=\"bin_vals\",\n        categorical=True,\n        cmap=\"viridis\",\n        legend=True,\n        legend_kwds={\n            \"fontsize\": 8,\n            \"loc\": \"center left\",\n            \"bbox_to_anchor\": (1.0, 0.90),\n        },\n    )\n\n    bin_legends = bins.get_legend_classes()\n    mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n    replace_legend_items(ax.get_legend(), mapping)\n    ax.set_title(col)\n    \n    if plot_weights:\n        ax = wdf.plot(\n            ax=ax,\n            linewidth=0.5,\n            column=\"class_name\",\n            cmap=\"Set1_r\",\n        )\n    ax.set_axis_off()\n\n    return ax\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 15))\n\nplot_diversity(ax[0], tsc, \"class_name_simpson_index\", plot_weights=True)\nplot_diversity(ax[1], tsc, \"class_name_shannon_index\", plot_weights=True)\n</pre> import matplotlib.pyplot as plt import mapclassify  # helper function to replace legend items def replace_legend_items(legend, mapping):     for txt in legend.texts:         for k, v in mapping.items():             if txt.get_text() == str(k):                 txt.set_text(v)   def plot_diversity(ax, cells, col, plot_weights=True):     # bin the values with the FisherJenks method for visualization     bins = mapclassify.FisherJenks(cells[col], k=5)     cells[\"bin_vals\"] = bins.yb     ax = cells.plot(         ax=ax,         column=\"bin_vals\",         categorical=True,         cmap=\"viridis\",         legend=True,         legend_kwds={             \"fontsize\": 8,             \"loc\": \"center left\",             \"bbox_to_anchor\": (1.0, 0.90),         },     )      bin_legends = bins.get_legend_classes()     mapping = dict([(i, s) for i, s in enumerate(bin_legends)])     replace_legend_items(ax.get_legend(), mapping)     ax.set_title(col)          if plot_weights:         ax = wdf.plot(             ax=ax,             linewidth=0.5,             column=\"class_name\",             cmap=\"Set1_r\",         )     ax.set_axis_off()      return ax  fig, ax = plt.subplots(1, 2, figsize=(15, 15))  plot_diversity(ax[0], tsc, \"class_name_simpson_index\", plot_weights=True) plot_diversity(ax[1], tsc, \"class_name_shannon_index\", plot_weights=True)  Out[6]: <pre>&lt;Axes: title={'center': 'class_name_shannon_index'}&gt;</pre> <p>We can see from the above plots that the metrics produce nearly identical results. Basically, the most diverse neighborhoods are located at the tissue interfaces i.e. at the small blood vessels inside the tumor and directly at the tumor-stroma interface, where there are diverse neighborhoods of stromal cells, tumor cells, and lymphocytes.</p> In\u00a0[7]: Copied! <pre>from cellseg_gsontools.geometry import shape_metric\n\n# compute a couple shape metrics\nmetrics = [\n    \"area\",\n    \"eccentricity\",\n    \"sphericity\",\n    \"fractal_dimension\"\n]\n\ntsc = shape_metric(\n    tsc,\n    metrics=metrics,\n    parallel=True,\n)\n\ntsc.head(4)\n</pre> from cellseg_gsontools.geometry import shape_metric  # compute a couple shape metrics metrics = [     \"area\",     \"eccentricity\",     \"sphericity\",     \"fractal_dimension\" ]  tsc = shape_metric(     tsc,     metrics=metrics,     parallel=True, )  tsc.head(4) Out[7]: type geometry class_name uid class_name_simpson_index class_name_shannon_index bin_vals area eccentricity sphericity fractal_dimension uid 0 Feature POLYGON ((169.012 42.997, 170.011 45.994, 174.... neoplastic 0 0.0 0.0 0 943.538625 0.405200 0.794631 0.405200 1 Feature POLYGON ((183.996 97.988, 192.079 94.544, 194.... neoplastic 1 0.0 0.0 0 1075.707286 0.435784 0.553602 0.435784 2 Feature POLYGON ((130.006 97.989, 133.003 98.988, 136.... neoplastic 2 0.0 0.0 0 1044.121328 0.822321 0.496494 0.822321 3 Feature POLYGON ((63.174 103.174, 70.007 109.990, 72.0... neoplastic 3 0.0 0.0 0 833.673039 0.795212 0.556992 0.795212 <p>Let's first plot the morphological metrics of the cells.</p> In\u00a0[8]: Copied! <pre># !pip install legendgram\n</pre> # !pip install legendgram In\u00a0[9]: Copied! <pre>import geopandas as gpd\nimport palettable as palet\nfrom legendgram import legendgram\n\n\n    # Helper function to plot cells with a feature value highlighted\ndef plot_cells(f, ax, cells: gpd.GeoDataFrame, col: str):\n    # bin the values with the Fisher-Jenks method\n    bins = mapclassify.FisherJenks(cells[col], k=5)\n    cells[\"bin_vals\"] = bins.yb\n\n    ax = cells.plot(\n        ax=ax,\n        column=\"bin_vals\",\n        cmap=\"viridis\",\n        categorical=True,\n        legend=True,\n        legend_kwds={\n            \"fontsize\": 8,\n            \"loc\": \"center left\",\n            \"bbox_to_anchor\": (1.0, 0.88),\n        },\n    )\n\n    bin_legends = bins.get_legend_classes()\n    mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n    replace_legend_items(ax.get_legend(), mapping)\n    ax.set_axis_off()\n    ax.set_title(col)\n    ax = legendgram(\n        f,\n        ax,\n        cells[col],\n        bins=30,\n        breaks=bins.bins,\n        pal=palet.matplotlib.Viridis_5,\n        loc=\"lower left\",\n    )\n    ax.set_axis_off()\n\n    return ax\n\nfig, ax = plt.subplots(2, 2, figsize=(16, 15))\nax = ax.flatten()\nplot_cells(fig, ax[0], tsc, \"area\")\nplot_cells(fig, ax[1], tsc, \"eccentricity\")\nplot_cells(fig, ax[2], tsc, \"sphericity\")\nplot_cells(fig, ax[3], tsc, \"fractal_dimension\")\n</pre> import geopandas as gpd import palettable as palet from legendgram import legendgram       # Helper function to plot cells with a feature value highlighted def plot_cells(f, ax, cells: gpd.GeoDataFrame, col: str):     # bin the values with the Fisher-Jenks method     bins = mapclassify.FisherJenks(cells[col], k=5)     cells[\"bin_vals\"] = bins.yb      ax = cells.plot(         ax=ax,         column=\"bin_vals\",         cmap=\"viridis\",         categorical=True,         legend=True,         legend_kwds={             \"fontsize\": 8,             \"loc\": \"center left\",             \"bbox_to_anchor\": (1.0, 0.88),         },     )      bin_legends = bins.get_legend_classes()     mapping = dict([(i, s) for i, s in enumerate(bin_legends)])     replace_legend_items(ax.get_legend(), mapping)     ax.set_axis_off()     ax.set_title(col)     ax = legendgram(         f,         ax,         cells[col],         bins=30,         breaks=bins.bins,         pal=palet.matplotlib.Viridis_5,         loc=\"lower left\",     )     ax.set_axis_off()      return ax  fig, ax = plt.subplots(2, 2, figsize=(16, 15)) ax = ax.flatten() plot_cells(fig, ax[0], tsc, \"area\") plot_cells(fig, ax[1], tsc, \"eccentricity\") plot_cells(fig, ax[2], tsc, \"sphericity\") plot_cells(fig, ax[3], tsc, \"fractal_dimension\")  Out[9]: <pre>&lt;Axes: &gt;</pre> In\u00a0[10]: Copied! <pre>from cellseg_gsontools.diversity import local_diversity\n\ntsc = local_diversity(\n    tsc,\n    w,\n    val_col=(\"area\", \"eccentricity\"),\n    id_col=\"uid\",\n    metrics=(\"gini_index\", \"theil_index\"),\n    parallel=True,\n)\n\ntsc\n</pre> from cellseg_gsontools.diversity import local_diversity  tsc = local_diversity(     tsc,     w,     val_col=(\"area\", \"eccentricity\"),     id_col=\"uid\",     metrics=(\"gini_index\", \"theil_index\"),     parallel=True, )  tsc Out[10]: type geometry class_name uid class_name_simpson_index class_name_shannon_index bin_vals area eccentricity sphericity fractal_dimension area_gini_index area_theil_index eccentricity_gini_index eccentricity_theil_index uid 0 Feature POLYGON ((169.012 42.997, 170.011 45.994, 174.... neoplastic 0 0.000000 0.000000 1 943.538625 0.405200 0.794631 0.405200 0.187302 0.103848 0.159341 0.043538 1 Feature POLYGON ((183.996 97.988, 192.079 94.544, 194.... neoplastic 1 0.000000 0.000000 1 1075.707286 0.435784 0.553602 0.435784 0.165736 0.087905 0.216479 0.077780 2 Feature POLYGON ((130.006 97.989, 133.003 98.988, 136.... neoplastic 2 0.000000 0.000000 4 1044.121328 0.822321 0.496494 0.822321 0.062130 0.006462 0.260549 0.114022 3 Feature POLYGON ((63.174 103.174, 70.007 109.990, 72.0... neoplastic 3 0.000000 0.000000 3 833.673039 0.795212 0.556992 0.795212 0.262713 0.114134 0.168073 0.061453 4 Feature POLYGON ((122.012 131.995, 125.007 135.990, 13... neoplastic 4 0.000000 0.000000 1 1167.520029 0.266585 0.809407 0.266585 0.170704 0.051128 0.211602 0.082661 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 1236 Feature POLYGON ((1853.012 1950.996, 1854.010 1952.993... connective 1236 0.320000 0.500402 0 432.189909 0.032139 0.718006 0.032139 0.082873 0.018006 0.445169 0.453477 1237 Feature POLYGON ((1774.012 1955.996, 1775.010 1957.993... connective 1237 0.320000 0.500402 3 137.291665 0.726723 0.447882 0.726723 0.309179 0.157230 0.283330 0.231866 1238 Feature POLYGON ((1751.012 1965.997, 1752.011 1968.994... connective 1238 0.244898 0.410116 4 124.983503 0.827244 0.358475 0.827244 0.307508 0.164763 0.165414 0.042874 1239 Feature POLYGON ((1758.012 1984.997, 1759.011 1987.995... inflammatory 1239 0.320000 0.500402 2 381.149497 0.494062 0.689854 0.494062 0.379105 0.245069 0.293331 0.237886 1240 Feature POLYGON ((1937.012 1988.996, 1938.010 1990.993... connective 1240 0.320000 0.500402 2 465.555405 0.542822 0.729013 0.542822 0.164228 0.052950 0.246897 0.183139 <p>1241 rows \u00d7 15 columns</p> In\u00a0[11]: Copied! <pre># Aand some plots\n\nfig, ax = plt.subplots(2, 2, figsize=(15, 15))\nax = ax.flatten()\n\nplot_diversity(ax[0], tsc, \"area_theil_index\", plot_weights=True)\nplot_diversity(ax[1], tsc, \"area_gini_index\", plot_weights=True)\nplot_diversity(ax[2], tsc, \"eccentricity_theil_index\", plot_weights=True)\nplot_diversity(ax[3], tsc, \"eccentricity_gini_index\", plot_weights=True)\n</pre> # Aand some plots  fig, ax = plt.subplots(2, 2, figsize=(15, 15)) ax = ax.flatten()  plot_diversity(ax[0], tsc, \"area_theil_index\", plot_weights=True) plot_diversity(ax[1], tsc, \"area_gini_index\", plot_weights=True) plot_diversity(ax[2], tsc, \"eccentricity_theil_index\", plot_weights=True) plot_diversity(ax[3], tsc, \"eccentricity_gini_index\", plot_weights=True)  Out[11]: <pre>&lt;Axes: title={'center': 'eccentricity_gini_index'}&gt;</pre> <p>As expected, the Theil an Gini inequality indicices of eccentric cells are low around the tissue interfaces. This means that the eccentricity of the cells is more homogenous around the tissue interfaces which can be seen from the previous plots where the elliptic cells cluster around the tissue interfaces. On the other hand, the Theil and Gini indices of the cell areas are high around the tissue interfaces which means that the cell area is more heterogenous around the tissue interfaces.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/cell_neighborhood_diversity/#cellnuclei-neighborhood-diversities","title":"Cell/Nuclei Neighborhood Diversities\u00b6","text":"<p>As in the last example of the cell neighborhood characteristics, we will again be looking at the cell neighborhoods. However, this time we will be looking at the diversity of the cell neighborhoods. The diversity can be understood as the heterogeneity or homogeneity of the neighborhoods, for example, whether a region of interest contains a mix of various cell types or just only a few. In other words, diversity metrics can be used to quantify the intermixing patterns of cells in a region of interest. The diversity metrics can be computed for any type of attribute of the cells e.g. categorical attributes (cell type), real valued attributes (cell shape metrics), etc.</p> <p>In this notebook, we will be looking at different ways to compute neighborhood diversities for the cells.</p> <p>Note: This notebook is the same as the previous notebook until we start to compute diversity metrics.</p>"},{"location":"user_guide/cell_neighborhood_diversity/#the-data","title":"The Data\u00b6","text":"<p>We'll be taking a look at a small tile of cells at the tumor-stroma interface i.e. at the border where the tumor meets stroma. The tumor in the data also contains a couple small blood vessels that introduce tumor-stroma interface within the tumor.</p>"},{"location":"user_guide/cell_neighborhood_diversity/#spatial-weights","title":"Spatial Weights\u00b6","text":"<p>To get the neighborhoods of the cells, we will first fit a connectivity graph (called spatial weights in geospatial analysis jargon) to the <code>GeoDataFrame</code>. <code>cellseg_gsontools</code> provides a <code>fit_graph</code> function which can be used to do that. The actual fitting is done with the <code>libpysal</code> package and the <code>fit_graph</code>-function is basically a wrapper around different graph fitting methods. The allowed spatial weights are:</p> <ul> <li><code>knn</code>: k-nearest neighbors</li> <li><code>delaunay</code> - Delaunay triangulation</li> <li><code>distband</code> - Distance band i.e. a distance thresholded knn graph</li> <li><code>relative_nhood</code> - Relative neighborhood graph</li> </ul> <p>We will be using the <code>delaunay</code> method in this example, however, note that for large data the <code>delaunay</code> method can get quite slow and for example the <code>distband</code> method is a lot faster. Here, we will set a distance threshold for the neighbors to be within 50 microns of the cell centroid. The distance unit in the example data is in pixels so 50 microns in pixels of 20x magnified segmentation mask is around 50*2 = 100 pixels.</p>"},{"location":"user_guide/cell_neighborhood_diversity/#diversity-metrics","title":"Diversity Metrics\u00b6","text":"<p>We will compute four different diversity metrics that are available in <code>cellseg_gsontools</code> and then visualize them. The available metrics are:</p> <ul> <li>Shannon Entropy</li> <li>Simpson Index</li> <li>Gini Index</li> <li>Theil Index</li> </ul> <p>Note that Gini Index and Theil index can be only computed for real valued data, thus we will have to compute some morpholgical metrics of the cells to compute these diversity metrics. For the simpson and shannon index, we can use the cell type information directly which is categorical.</p>"},{"location":"user_guide/cell_neighborhood_diversity/#shannon-and-simpson-indices-for-cell-type-diversity","title":"Shannon and Simpson Indices for Cell Type Diversity\u00b6","text":"<p>Let's now compute the shannon diversity and simpson diversity indices. We will use the cell type attribute for the computations. Basically these metrics measure how homogenous/heterogenous the cell types are in each neighborhood. The diversity indices are computed with the <code>local_diversity</code> function.</p>"},{"location":"user_guide/cell_neighborhood_diversity/#gini-and-theil-indices-for-morphological-diversity","title":"Gini and Theil Indices for Morphological Diversity\u00b6","text":"<p>Let's now compute the Theil and Gini indices. These metrics are often used in econometrics to compute income inequality. Here, we will use the morphological metrics of the cells to compute these metrics. So basically we will compute the ineqaulity of the morphological metrics of the cells in each neighborhood.</p>"},{"location":"user_guide/cell_neighborhood_diversity/#computing-morphological-metrics","title":"Computing Morphological Metrics\u00b6","text":""},{"location":"user_guide/cell_neighborhood_diversity/#computing-gini-and-theil-indices","title":"Computing Gini and Theil Indices\u00b6","text":""},{"location":"user_guide/cell_neighborhoods/","title":"Cell/Nuclei Neighborhoods","text":"In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import gland_cells\n\ngc = gland_cells()\ngc.plot(column=\"class_name\", figsize=(10,10), legend=True)\n</pre> from cellseg_gsontools.data import gland_cells  gc = gland_cells() gc.plot(column=\"class_name\", figsize=(10,10), legend=True) Out[1]: <pre>&lt;Axes: &gt;</pre> In\u00a0[2]: Copied! <pre>gc\n</pre> gc Out[2]: type geometry class_name 0 Feature POLYGON ((92.000 1083.984, 95.990 1079.993, 99... glandular_epithel 1 Feature POLYGON ((61.005 1085.988, 64.755 1086.000, 68... glandular_epithel 2 Feature POLYGON ((138.997 1093.988, 142.992 1092.988, ... glandular_epithel 3 Feature POLYGON ((109.005 1092.988, 115.995 1092.988, ... glandular_epithel 4 Feature POLYGON ((69.012 1091.997, 70.011 1094.994, 72... glandular_epithel ... ... ... ... 1354 Feature POLYGON ((1932.004 1671.988, 1936.755 1672.000... glandular_epithel 1355 Feature POLYGON ((1944.005 1691.988, 1951.996 1691.988... glandular_epithel 1356 Feature POLYGON ((1981.005 1723.988, 1985.996 1723.988... glandular_epithel 1357 Feature POLYGON ((1962.007 1726.990, 1965.005 1728.988... glandular_epithel 1358 Feature POLYGON ((1991.012 1739.997, 1992.011 1742.994... glandular_epithel <p>1359 rows \u00d7 3 columns</p> In\u00a0[3]: Copied! <pre>from cellseg_gsontools.graphs import fit_graph\nfrom cellseg_gsontools.utils import set_uid\n\n# To fit the delaunay graph, we need to set a unique id for each cell first\ngc = set_uid(gc, id_col=\"uid\")\nw = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\")\nw\n</pre> from cellseg_gsontools.graphs import fit_graph from cellseg_gsontools.utils import set_uid  # To fit the delaunay graph, we need to set a unique id for each cell first gc = set_uid(gc, id_col=\"uid\") w = fit_graph(gc, type=\"delaunay\", thresh=100, id_col=\"uid\") w Out[3]: <pre>&lt;libpysal.weights.weights.W at 0x7f4268c1abf0&gt;</pre> In\u00a0[4]: Copied! <pre># let's convert the graph to a dataframe and plot it\nfrom cellseg_gsontools.links import weights2gdf\n\nwdf = weights2gdf(gc, w)\nax = gc.plot(column=\"class_name\", figsize=(10,10), legend=True)\nax = wdf.plot(\n    ax=ax,\n    linewidth=0.5,\n    column=\"class_name\",\n    cmap=\"Set1_r\",\n    legend=True,\n    legend_kwds={\n        \"loc\": \"center left\",\n        \"bbox_to_anchor\": (1.0, 0.91)\n    }\n)\nax.set_title(\"Delaunay Graph Fitted on the Cells\")\n</pre> # let's convert the graph to a dataframe and plot it from cellseg_gsontools.links import weights2gdf  wdf = weights2gdf(gc, w) ax = gc.plot(column=\"class_name\", figsize=(10,10), legend=True) ax = wdf.plot(     ax=ax,     linewidth=0.5,     column=\"class_name\",     cmap=\"Set1_r\",     legend=True,     legend_kwds={         \"loc\": \"center left\",         \"bbox_to_anchor\": (1.0, 0.91)     } ) ax.set_title(\"Delaunay Graph Fitted on the Cells\") Out[4]: <pre>Text(0.5, 1.0, 'Delaunay Graph Fitted on the Cells')</pre> In\u00a0[5]: Copied! <pre>from cellseg_gsontools.apply import gdf_apply\nfrom cellseg_gsontools.neighbors import neighborhood\nfrom functools import partial\n\n# Get the neihgboring nodes of the graph\nfunc = partial(neighborhood, spatial_weights=w)\ngc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])\n\ngc.head(5)\n</pre> from cellseg_gsontools.apply import gdf_apply from cellseg_gsontools.neighbors import neighborhood from functools import partial  # Get the neihgboring nodes of the graph func = partial(neighborhood, spatial_weights=w) gc[\"nhood\"] = gdf_apply(gc, func, columns=[\"uid\"])  gc.head(5) Out[5]: type geometry class_name uid nhood uid 0 Feature POLYGON ((92.000 1083.984, 95.990 1079.993, 99... glandular_epithel 0 [0, 1, 3, 4, 483, 484] 1 Feature POLYGON ((61.005 1085.988, 64.755 1086.000, 68... glandular_epithel 1 [1, 0, 4, 482, 483, 487] 2 Feature POLYGON ((138.997 1093.988, 142.992 1092.988, ... glandular_epithel 2 [2, 3, 5, 6, 484, 493] 3 Feature POLYGON ((109.005 1092.988, 115.995 1092.988, ... glandular_epithel 3 [3, 0, 2, 4, 5, 7, 484] 4 Feature POLYGON ((69.012 1091.997, 70.011 1094.994, 72... glandular_epithel 4 [4, 0, 1, 3, 7, 487, 488] <p>Easy!, Now we have the neighbor indices neatly in our dataframe. Let's then extract some attributes of the neighbors. We will extract the areas and class names of the neighbors.</p> In\u00a0[6]: Copied! <pre>from cellseg_gsontools.neighbors import nhood_vals\n\n# # compute the areas\n# gc[\"area\"] = gc.area\n\n# get the class values of the neighbors\nfunc = partial(nhood_vals, values=gc.class_name)\ngc[\"neighbor_classes\"] = gdf_apply(\n    gc,\n    func=func,\n    parallel=True,\n    columns=[\"nhood\"],\n)\n\n# get the area values of the neighbors\nfunc = partial(nhood_vals, values=gc.area.round(2))\ngc[\"neighbor_areas\"] = gdf_apply(\n    gc,\n    func=func,\n    parallel=True,\n    columns=[\"nhood\"],\n)\n\ngc.head(5)\n</pre> from cellseg_gsontools.neighbors import nhood_vals  # # compute the areas # gc[\"area\"] = gc.area  # get the class values of the neighbors func = partial(nhood_vals, values=gc.class_name) gc[\"neighbor_classes\"] = gdf_apply(     gc,     func=func,     parallel=True,     columns=[\"nhood\"], )  # get the area values of the neighbors func = partial(nhood_vals, values=gc.area.round(2)) gc[\"neighbor_areas\"] = gdf_apply(     gc,     func=func,     parallel=True,     columns=[\"nhood\"], )  gc.head(5)  Out[6]: type geometry class_name uid nhood neighbor_classes neighbor_areas uid 0 Feature POLYGON ((92.000 1083.984, 95.990 1079.993, 99... glandular_epithel 0 [0, 1, 3, 4, 483, 484] [glandular_epithel, glandular_epithel, glandul... [520.24, 565.58, 435.91, 302.26, 241.85, 418.02] 1 Feature POLYGON ((61.005 1085.988, 64.755 1086.000, 68... glandular_epithel 1 [1, 0, 4, 482, 483, 487] [glandular_epithel, glandular_epithel, glandul... [565.58, 520.24, 302.26, 318.15, 241.85, 485.71] 2 Feature POLYGON ((138.997 1093.988, 142.992 1092.988, ... glandular_epithel 2 [2, 3, 5, 6, 484, 493] [glandular_epithel, glandular_epithel, glandul... [721.5, 435.91, 556.05, 466.96, 418.02, 678.35] 3 Feature POLYGON ((109.005 1092.988, 115.995 1092.988, ... glandular_epithel 3 [3, 0, 2, 4, 5, 7, 484] [glandular_epithel, glandular_epithel, glandul... [435.91, 520.24, 721.5, 302.26, 556.05, 655.42... 4 Feature POLYGON ((69.012 1091.997, 70.011 1094.994, 72... glandular_epithel 4 [4, 0, 1, 3, 7, 487, 488] [glandular_epithel, glandular_epithel, glandul... [302.26, 520.24, 565.58, 435.91, 655.42, 485.7... <p>That was easy! Now we have the neighbor areas and class names neatly in our dataframe. Let's then extract the cell counts of glandular epithelial cells in each neighborhood.</p> In\u00a0[7]: Copied! <pre>from cellseg_gsontools.neighbors import nhood_type_count\n\nfunc = partial(nhood_type_count, cls=\"glandular_epithel\", frac=False)\ngc[\"n_gland_neighbors\"] = gdf_apply(\n    gc,\n    func=func,\n    parallel=True,\n    columns=[\"neighbor_classes\"],\n)\n\ngc.head(5)\n</pre> from cellseg_gsontools.neighbors import nhood_type_count  func = partial(nhood_type_count, cls=\"glandular_epithel\", frac=False) gc[\"n_gland_neighbors\"] = gdf_apply(     gc,     func=func,     parallel=True,     columns=[\"neighbor_classes\"], )  gc.head(5) Out[7]: type geometry class_name uid nhood neighbor_classes neighbor_areas n_gland_neighbors uid 0 Feature POLYGON ((92.000 1083.984, 95.990 1079.993, 99... glandular_epithel 0 [0, 1, 3, 4, 483, 484] [glandular_epithel, glandular_epithel, glandul... [520.24, 565.58, 435.91, 302.26, 241.85, 418.02] 6.0 1 Feature POLYGON ((61.005 1085.988, 64.755 1086.000, 68... glandular_epithel 1 [1, 0, 4, 482, 483, 487] [glandular_epithel, glandular_epithel, glandul... [565.58, 520.24, 302.26, 318.15, 241.85, 485.71] 6.0 2 Feature POLYGON ((138.997 1093.988, 142.992 1092.988, ... glandular_epithel 2 [2, 3, 5, 6, 484, 493] [glandular_epithel, glandular_epithel, glandul... [721.5, 435.91, 556.05, 466.96, 418.02, 678.35] 6.0 3 Feature POLYGON ((109.005 1092.988, 115.995 1092.988, ... glandular_epithel 3 [3, 0, 2, 4, 5, 7, 484] [glandular_epithel, glandular_epithel, glandul... [435.91, 520.24, 721.5, 302.26, 556.05, 655.42... 7.0 4 Feature POLYGON ((69.012 1091.997, 70.011 1094.994, 72... glandular_epithel 4 [4, 0, 1, 3, 7, 487, 488] [glandular_epithel, glandular_epithel, glandul... [302.26, 520.24, 565.58, 435.91, 655.42, 485.7... 7.0 <p>Again, easy! Next, we'll bin the cell areas and get the counts of cells in each area bin.</p> In\u00a0[8]: Copied! <pre>import mapclassify\nfrom cellseg_gsontools.neighbors import nhood_counts\n\nbins = mapclassify.Quantiles(gc.area, k=5)\n\nfunc = partial(nhood_counts, values=gc.area, bins=bins.bins)\ngc[\"area_bins\"] = gdf_apply(\n    gc,\n    func,\n    columns=[\"nhood\"],\n)\n\ngc.head(5)\n</pre> import mapclassify from cellseg_gsontools.neighbors import nhood_counts  bins = mapclassify.Quantiles(gc.area, k=5)  func = partial(nhood_counts, values=gc.area, bins=bins.bins) gc[\"area_bins\"] = gdf_apply(     gc,     func,     columns=[\"nhood\"], )  gc.head(5) Out[8]: type geometry class_name uid nhood neighbor_classes neighbor_areas n_gland_neighbors area_bins uid 0 Feature POLYGON ((92.000 1083.984, 95.990 1079.993, 99... glandular_epithel 0 [0, 1, 3, 4, 483, 484] [glandular_epithel, glandular_epithel, glandul... [520.24, 565.58, 435.91, 302.26, 241.85, 418.02] 6.0 [0, 2, 0, 3, 1] 1 Feature POLYGON ((61.005 1085.988, 64.755 1086.000, 68... glandular_epithel 1 [1, 0, 4, 482, 483, 487] [glandular_epithel, glandular_epithel, glandul... [565.58, 520.24, 302.26, 318.15, 241.85, 485.71] 6.0 [0, 2, 1, 2, 1] 2 Feature POLYGON ((138.997 1093.988, 142.992 1092.988, ... glandular_epithel 2 [2, 3, 5, 6, 484, 493] [glandular_epithel, glandular_epithel, glandul... [721.5, 435.91, 556.05, 466.96, 418.02, 678.35] 6.0 [0, 0, 0, 3, 3] 3 Feature POLYGON ((109.005 1092.988, 115.995 1092.988, ... glandular_epithel 3 [3, 0, 2, 4, 5, 7, 484] [glandular_epithel, glandular_epithel, glandul... [435.91, 520.24, 721.5, 302.26, 556.05, 655.42... 7.0 [0, 1, 0, 3, 3] 4 Feature POLYGON ((69.012 1091.997, 70.011 1094.994, 72... glandular_epithel 4 [4, 0, 1, 3, 7, 487, 488] [glandular_epithel, glandular_epithel, glandul... [302.26, 520.24, 565.58, 435.91, 655.42, 485.7... 7.0 [0, 1, 0, 3, 3] <p>Nice! Now we have the counts of cells in each area bin. Finally, let's get the neighborhood distances from the cell centroid for each cell.</p> In\u00a0[9]: Copied! <pre>from cellseg_gsontools.neighbors import nhood_dists\n\nfunc = partial(nhood_dists, centroids=gc.centroid)\ngc[\"nhood_dists\"] = gdf_apply(\n    gc,\n    func,\n    columns=[\"nhood\"],\n)\n\ngc.head(5)\n</pre> from cellseg_gsontools.neighbors import nhood_dists  func = partial(nhood_dists, centroids=gc.centroid) gc[\"nhood_dists\"] = gdf_apply(     gc,     func,     columns=[\"nhood\"], )  gc.head(5) Out[9]: type geometry class_name uid nhood neighbor_classes neighbor_areas n_gland_neighbors area_bins nhood_dists uid 0 Feature POLYGON ((92.000 1083.984, 95.990 1079.993, 99... glandular_epithel 0 [0, 1, 3, 4, 483, 484] [glandular_epithel, glandular_epithel, glandul... [520.24, 565.58, 435.91, 302.26, 241.85, 418.02] 6.0 [0, 2, 0, 3, 1] [0.0, 26.675, 24.786, 30.068, 30.228, 41.284] 1 Feature POLYGON ((61.005 1085.988, 64.755 1086.000, 68... glandular_epithel 1 [1, 0, 4, 482, 483, 487] [glandular_epithel, glandular_epithel, glandul... [565.58, 520.24, 302.26, 318.15, 241.85, 485.71] 6.0 [0, 2, 1, 2, 1] [0.0, 26.675, 23.428, 42.962, 39.039, 23.949] 2 Feature POLYGON ((138.997 1093.988, 142.992 1092.988, ... glandular_epithel 2 [2, 3, 5, 6, 484, 493] [glandular_epithel, glandular_epithel, glandul... [721.5, 435.91, 556.05, 466.96, 418.02, 678.35] 6.0 [0, 0, 0, 3, 3] [0.0, 25.577, 39.348, 46.097, 34.309, 29.478] 3 Feature POLYGON ((109.005 1092.988, 115.995 1092.988, ... glandular_epithel 3 [3, 0, 2, 4, 5, 7, 484] [glandular_epithel, glandular_epithel, glandul... [435.91, 520.24, 721.5, 302.26, 556.05, 655.42... 7.0 [0, 1, 0, 3, 3] [0.0, 24.786, 25.577, 39.574, 37.829, 47.16, 3... 4 Feature POLYGON ((69.012 1091.997, 70.011 1094.994, 72... glandular_epithel 4 [4, 0, 1, 3, 7, 487, 488] [glandular_epithel, glandular_epithel, glandul... [302.26, 520.24, 565.58, 435.91, 655.42, 485.7... 7.0 [0, 1, 0, 3, 3] [0.0, 30.068, 23.428, 39.574, 29.225, 36.337, ... <p>And now we have the neighborhood distances as well!</p> <p>All of these kinds of neighborhood arrays that were computed in this noteook are used in many different spatial metrics. We will be using them exhaustively in the coming notebooks as well.</p>"},{"location":"user_guide/cell_neighborhoods/#cellnuclei-neighborhoods","title":"Cell/Nuclei Neighborhoods\u00b6","text":"<p>Cell neighborhoods are a useful concept in spatial analysis. They are defined as the set of cells that are adjacent to a given cell. In network science terms, the cells are nodes and adjacent cells are nodes that are connected to the given cell via an edge. The edges between two cells are determined by a connectivity graph algorithm. There are several algorithms to do this and <code>cellseg_gsontools</code> provides a few of them through the <code>libpysal</code> package. In our (spatial single cell analysis) domain, there is usually some sort of distance criteria that determines if there will be an edge between two cells. For example, if the distance between two cells is less than 50 microns, then there will be an edge between them.</p> <p>This notebook is a quick tutorial on how to extract the cell neighborhoods from your data with <code>cellseg_gsontools</code> and how to use them to get other related neighborhood attributes.</p> <p>To get the neighborhoods neatly extracted in your dataframe, we will be utilizing the <code>gdf_apply</code> and <code>cellseg_gsontools.neighbors</code> module. The <code>neighbors</code> module provides functions that operate on a contiuity graph and a <code>GeoDataFrame</code>. These functions are designed to be used together with the <code>gdf_apply</code> function which support parallelized operations on a <code>GeoDataFrame</code>.</p>"},{"location":"user_guide/cell_neighborhoods/#the-data","title":"The Data\u00b6","text":"<p>We'll be taking a look at some glandular epithelial cells and their shapes espically. <code>cellseg_gsontools</code> provides a small example segmentation mask that contains a lot glandular epithelial cells.</p>"},{"location":"user_guide/cell_neighborhoods/#spatial-weights","title":"Spatial Weights\u00b6","text":"<p>First, we need to fit a connectivity graph to the <code>GeoDataFrame</code> to get the neighborhoods of the cells (sometimes it is called spatial weights in geospatial analysis jargon). <code>cellseg_gsontools</code> provides a <code>fit_graph</code> function which can be used to do that. The actual fitting is done with the <code>libpysal</code> package and the <code>fit_graph</code>-function is basically a wrapper around different graph fitting methods. The allowed spatial weights are:</p> <ul> <li><code>knn</code>: k-nearest neighbors</li> <li><code>delaunay</code> - Delaunay triangulation</li> <li><code>distband</code> - Distance band i.e. a distance thresholded knn graph</li> <li><code>relative_nhood</code> - Relative neighborhood graph</li> </ul> <p>We will be using the <code>delaunay</code> method in this example, however, note that for large data the <code>delaunay</code> method can get quite slow and for example the <code>distband</code> method is a lot faster. Here, we will set a distance threshold for the neighbors to be within 50 microns of the cell centroid. The distance unit in the example data is in pixels so 50 microns in pixels of 20x magnified segmentation mask is around 50*2 = 100 pixels.</p>"},{"location":"user_guide/cell_neighborhoods/#extracting-the-neighborhood-indices","title":"Extracting the Neighborhood Indices\u00b6","text":"<p>So now we have the connectivity graph (<code>libpysal.weights.W</code>) and we can get down to business. That is, extracting the neighborhoods and their attributes. Let's start by extracting just the neighbor indices.</p>"},{"location":"user_guide/cell_regionalization/","title":"Cell Regionalization","text":"In\u00a0[1]: Copied! <pre>import numpy as np\nfrom pathlib import Path\nfrom cellseg_gsontools.utils import read_gdf\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\ntissue_path = Path(\"/path/to/tissues.geojson\")\nnuc_path = Path(\"/path/to/nuclei.geojson\")\n\ntissues = read_gdf(tissue_path)\ncells = read_gdf(nuc_path)\n\ntumor = tissues[tissues[\"class_name\"] == \"area_cin\"]\n\n# set the crs to avoid annoying warnings\ntumor.set_crs(4328, inplace=True, allow_override=True)\ntumor = tumor.loc[tumor.area &gt; 1e6] # drop small tumor areas\n\n# get the cells that intersect the tumor\n_, cell_inds = cells.sindex.query(tumor.geometry, predicate=\"intersects\")\nneoplastic = cells.iloc[np.unique(cell_inds)]\nneoplastic = neoplastic[[\"geometry\", \"class_name\"]]\nneoplastic.reset_index(drop=True, inplace=True)\nneoplastic.set_crs(4328, inplace=True, allow_override=True)\n\n# plot the tumor and neoplastic cells\nax = tumor.plot(\n    column=\"class_name\",\n    figsize=(10, 10),\n    alpha=0.2,\n    aspect=None\n)\nneoplastic.plot(\n    ax=ax,\n    column=\"class_name\",\n    aspect=None,\n    legend=True,\n    cmap=\"tab20_r\"\n)\n</pre> import numpy as np from pathlib import Path from cellseg_gsontools.utils import read_gdf  import warnings warnings.filterwarnings(\"ignore\")  tissue_path = Path(\"/path/to/tissues.geojson\") nuc_path = Path(\"/path/to/nuclei.geojson\")  tissues = read_gdf(tissue_path) cells = read_gdf(nuc_path)  tumor = tissues[tissues[\"class_name\"] == \"area_cin\"]  # set the crs to avoid annoying warnings tumor.set_crs(4328, inplace=True, allow_override=True) tumor = tumor.loc[tumor.area &gt; 1e6] # drop small tumor areas  # get the cells that intersect the tumor _, cell_inds = cells.sindex.query(tumor.geometry, predicate=\"intersects\") neoplastic = cells.iloc[np.unique(cell_inds)] neoplastic = neoplastic[[\"geometry\", \"class_name\"]] neoplastic.reset_index(drop=True, inplace=True) neoplastic.set_crs(4328, inplace=True, allow_override=True)  # plot the tumor and neoplastic cells ax = tumor.plot(     column=\"class_name\",     figsize=(10, 10),     alpha=0.2,     aspect=None ) neoplastic.plot(     ax=ax,     column=\"class_name\",     aspect=None,     legend=True,     cmap=\"tab20_r\" ) Out[1]: <pre>&lt;Axes: &gt;</pre> In\u00a0[2]: Copied! <pre>from cellseg_gsontools.geometry import shape_metric\n\nmetrics = [\n    \"area\",\n    \"compactness\",\n    \"circularity\",\n    \"convexity\",\n    \"solidity\",\n    \"elongation\",\n    \"eccentricity\",\n    \"fractal_dimension\",\n    \"sphericity\",\n    \"shape_index\",\n    \"rectangularity\",\n    \"squareness\",\n    \"equivalent_rectangular_index\",\n]\n\nneoplastic = shape_metric(neoplastic, metrics)\nneoplastic.head(4)\n</pre> from cellseg_gsontools.geometry import shape_metric  metrics = [     \"area\",     \"compactness\",     \"circularity\",     \"convexity\",     \"solidity\",     \"elongation\",     \"eccentricity\",     \"fractal_dimension\",     \"sphericity\",     \"shape_index\",     \"rectangularity\",     \"squareness\",     \"equivalent_rectangular_index\", ]  neoplastic = shape_metric(neoplastic, metrics) neoplastic.head(4) Out[2]: geometry class_name area compactness circularity convexity solidity elongation eccentricity fractal_dimension sphericity shape_index rectangularity squareness equivalent_rectangular_index 0 POLYGON ((7854.00000 5031.01000, 7850.01000 50... connective 795.21535 0.881246 0.881246 1.000000 1.000000 0.600050 0.799962 0.799962 0.530560 0.767377 0.829109 1.122037 0.757876 1 POLYGON ((7848.00000 4860.01000, 7845.01000 48... neoplastic 168.86025 0.663535 0.663535 1.000000 1.000000 0.332777 0.943005 0.943005 0.244941 0.598589 0.882420 0.844839 0.831070 2 POLYGON ((7864.00000 4862.01000, 7862.01000 48... inflammatory 156.03025 0.794335 0.794335 1.000000 1.000000 0.473130 0.880993 0.880993 0.407591 0.718114 0.915453 1.011379 0.850077 3 POLYGON ((7890.00000 4876.01000, 7886.55000 48... inflammatory 133.51025 0.890833 0.893567 0.998469 0.984696 0.922958 0.384900 0.384900 0.633114 0.825456 0.858585 1.134244 0.805529 In\u00a0[3]: Copied! <pre>from cellseg_gsontools.graphs import fit_graph\nfrom cellseg_gsontools.character import local_character\nfrom cellseg_gsontools.utils import set_uid\n\nneoplastic = set_uid(neoplastic)\nw = fit_graph(neoplastic, \"delaunay\", thresh=100, id_col=\"uid\")\n\nneoplastic = local_character(\n    neoplastic,\n    w,\n    val_col=metrics,\n    reductions=[\"mean\"]\n)\n\nneoplastic.head(4)\n</pre> from cellseg_gsontools.graphs import fit_graph from cellseg_gsontools.character import local_character from cellseg_gsontools.utils import set_uid  neoplastic = set_uid(neoplastic) w = fit_graph(neoplastic, \"delaunay\", thresh=100, id_col=\"uid\")  neoplastic = local_character(     neoplastic,     w,     val_col=metrics,     reductions=[\"mean\"] )  neoplastic.head(4) Out[3]: geometry class_name area compactness circularity convexity solidity elongation eccentricity fractal_dimension ... convexity_nhood_mean solidity_nhood_mean elongation_nhood_mean eccentricity_nhood_mean fractal_dimension_nhood_mean sphericity_nhood_mean shape_index_nhood_mean rectangularity_nhood_mean squareness_nhood_mean equivalent_rectangular_index_nhood_mean uid 0 POLYGON ((7854.00000 5031.01000, 7850.01000 50... connective 795.21535 0.881246 0.881246 1.000000 1.000000 0.600050 0.799962 0.799962 ... 0.997083 0.975846 0.646028 0.759367 0.759367 0.527334 0.766463 0.784753 1.066610 0.740143 1 POLYGON ((7848.00000 4860.01000, 7845.01000 48... neoplastic 168.86025 0.663535 0.663535 1.000000 1.000000 0.332777 0.943005 0.943005 ... 0.998897 0.990085 0.526516 0.806540 0.806540 0.399299 0.693164 0.845752 0.969814 0.800913 2 POLYGON ((7864.00000 4862.01000, 7862.01000 48... inflammatory 156.03025 0.794335 0.794335 1.000000 1.000000 0.473130 0.880993 0.880993 ... 0.998576 0.987273 0.564956 0.764074 0.764074 0.434008 0.698289 0.839377 0.972812 0.797451 3 POLYGON ((7890.00000 4876.01000, 7886.55000 48... inflammatory 133.51025 0.890833 0.893567 0.998469 0.984696 0.922958 0.384900 0.384900 ... 0.999186 0.992727 0.601116 0.751994 0.751994 0.446453 0.731006 0.844712 1.021302 0.795565 <p>4 rows \u00d7 29 columns</p> In\u00a0[4]: Copied! <pre>from cellseg_gsontools.diversity import local_diversity\n\nneoplastic = local_diversity(\n    neoplastic,\n    w,\n    val_col=metrics,\n    metrics=[\"shannon_index\"],\n    scheme=\"FisherJenks\" # binning scheme for real values\n)\n\nneoplastic.head(4)\n</pre> from cellseg_gsontools.diversity import local_diversity  neoplastic = local_diversity(     neoplastic,     w,     val_col=metrics,     metrics=[\"shannon_index\"],     scheme=\"FisherJenks\" # binning scheme for real values )  neoplastic.head(4) Out[4]: geometry class_name area compactness circularity convexity solidity elongation eccentricity fractal_dimension ... convexity_shannon_index solidity_shannon_index elongation_shannon_index eccentricity_shannon_index fractal_dimension_shannon_index sphericity_shannon_index shape_index_shannon_index rectangularity_shannon_index squareness_shannon_index equivalent_rectangular_index_shannon_index uid 0 POLYGON ((7854.00000 5031.01000, 7850.01000 50... connective 795.21535 0.881246 0.881246 1.000000 1.000000 0.600050 0.799962 0.799962 ... 0.636514 0.636514 0.636514 0.636514 0.636514 0.636514 0.000000 0.636514 1.098612 0.636514 1 POLYGON ((7848.00000 4860.01000, 7845.01000 48... neoplastic 168.86025 0.663535 0.663535 1.000000 1.000000 0.332777 0.943005 0.943005 ... 0.636514 0.867563 1.011404 0.450561 0.450561 1.329661 1.011404 0.867563 1.242453 1.011404 2 POLYGON ((7864.00000 4862.01000, 7862.01000 48... inflammatory 156.03025 0.794335 0.794335 1.000000 1.000000 0.473130 0.880993 0.880993 ... 0.693147 1.039721 1.039721 0.562335 0.562335 1.386294 1.039721 0.562335 1.039721 1.039721 3 POLYGON ((7890.00000 4876.01000, 7886.55000 48... inflammatory 133.51025 0.890833 0.893567 0.998469 0.984696 0.922958 0.384900 0.384900 ... 0.598270 0.796312 1.475076 1.153742 1.153742 1.351784 1.351784 0.955700 1.351784 0.955700 <p>4 rows \u00d7 42 columns</p> In\u00a0[5]: Copied! <pre>from cellseg_gsontools.character import local_distances\n\nneoplastic = local_distances(\n    neoplastic,\n    w,\n    reductions=[\"mean\"],\n)\n\nneoplastic.head(4)\n</pre> from cellseg_gsontools.character import local_distances  neoplastic = local_distances(     neoplastic,     w,     reductions=[\"mean\"], )  neoplastic.head(4) Out[5]: geometry class_name area compactness circularity convexity solidity elongation eccentricity fractal_dimension ... solidity_shannon_index elongation_shannon_index eccentricity_shannon_index fractal_dimension_shannon_index sphericity_shannon_index shape_index_shannon_index rectangularity_shannon_index squareness_shannon_index equivalent_rectangular_index_shannon_index nhood_dists_mean uid 0 POLYGON ((7854.00000 5031.01000, 7850.01000 50... connective 795.21535 0.881246 0.881246 1.000000 1.000000 0.600050 0.799962 0.799962 ... 0.636514 0.636514 0.636514 0.636514 0.636514 0.000000 0.636514 1.098612 0.636514 58.482000 1 POLYGON ((7848.00000 4860.01000, 7845.01000 48... neoplastic 168.86025 0.663535 0.663535 1.000000 1.000000 0.332777 0.943005 0.943005 ... 0.867563 1.011404 0.450561 0.450561 1.329661 1.011404 0.867563 1.242453 1.011404 37.818833 2 POLYGON ((7864.00000 4862.01000, 7862.01000 48... inflammatory 156.03025 0.794335 0.794335 1.000000 1.000000 0.473130 0.880993 0.880993 ... 1.039721 1.039721 0.562335 0.562335 1.386294 1.039721 0.562335 1.039721 1.039721 23.722000 3 POLYGON ((7890.00000 4876.01000, 7886.55000 48... inflammatory 133.51025 0.890833 0.893567 0.998469 0.984696 0.922958 0.384900 0.384900 ... 0.796312 1.475076 1.153742 1.153742 1.351784 1.351784 0.955700 1.351784 0.955700 32.163000 <p>4 rows \u00d7 43 columns</p> <p>Let's visualize the connectivity graph just for fun!</p> In\u00a0[6]: Copied! <pre>from cellseg_gsontools.links import weights2gdf\n\nw_gdf = weights2gdf(neoplastic, w)\nw_gdf.plot(linewidth=0.2, figsize=(10, 10))\n</pre> from cellseg_gsontools.links import weights2gdf  w_gdf = weights2gdf(neoplastic, w) w_gdf.plot(linewidth=0.2, figsize=(10, 10)) Out[6]: <pre>&lt;Axes: &gt;</pre> <p>We can clearly see that the tumor has some sparser and denser areas. That's why it would be intuitive that atleast the mean distance of the neighborhood could affect the clustering at some level.</p> In\u00a0[7]: Copied! <pre># !pip install esda\n</pre> # !pip install esda In\u00a0[8]: Copied! <pre>import esda\nimport pandas as pd\n\nnp.random.seed(420)\n\nclust_vars = neoplastic.loc[:, ~neoplastic.columns.isin([\"uid\", \"geometry\", \"class_name\"])]\n\n# Calculate Moran's I for each variable\nmi_results = [\n    esda.Moran(clust_vars[variable], w) for variable in clust_vars.columns\n]\n# Structure results as a list of tuples\nmi_results = [\n    (variable, res.I, res.p_sim)\n    for variable, res in zip(clust_vars.columns, mi_results)\n]\n# Display on table\ntable = pd.DataFrame(\n    mi_results, columns=[\"Variable\", \"Moran's I\", \"P-value\"]\n).set_index(\"Variable\")\n\ntable\n</pre> import esda import pandas as pd  np.random.seed(420)  clust_vars = neoplastic.loc[:, ~neoplastic.columns.isin([\"uid\", \"geometry\", \"class_name\"])]  # Calculate Moran's I for each variable mi_results = [     esda.Moran(clust_vars[variable], w) for variable in clust_vars.columns ] # Structure results as a list of tuples mi_results = [     (variable, res.I, res.p_sim)     for variable, res in zip(clust_vars.columns, mi_results) ] # Display on table table = pd.DataFrame(     mi_results, columns=[\"Variable\", \"Moran's I\", \"P-value\"] ).set_index(\"Variable\")  table Out[8]: Moran's I P-value Variable area 0.188537 0.001 compactness 0.297176 0.001 circularity 0.305584 0.001 convexity 0.037879 0.002 solidity 0.031049 0.001 elongation 0.315186 0.001 eccentricity 0.176556 0.001 fractal_dimension 0.176556 0.001 sphericity 0.300186 0.001 shape_index 0.299391 0.001 rectangularity 0.140452 0.001 squareness 0.297176 0.001 equivalent_rectangular_index 0.145111 0.001 area_nhood_mean 0.814709 0.001 compactness_nhood_mean 0.850340 0.001 circularity_nhood_mean 0.853726 0.001 convexity_nhood_mean 0.620014 0.001 solidity_nhood_mean 0.646014 0.001 elongation_nhood_mean 0.858630 0.001 eccentricity_nhood_mean 0.791940 0.001 fractal_dimension_nhood_mean 0.791940 0.001 sphericity_nhood_mean 0.848968 0.001 shape_index_nhood_mean 0.851196 0.001 rectangularity_nhood_mean 0.760326 0.001 squareness_nhood_mean 0.850340 0.001 equivalent_rectangular_index_nhood_mean 0.761222 0.001 area_shannon_index 0.533711 0.001 compactness_shannon_index 0.517608 0.001 circularity_shannon_index 0.528283 0.001 convexity_shannon_index 0.590485 0.001 solidity_shannon_index 0.626768 0.001 elongation_shannon_index 0.416466 0.001 eccentricity_shannon_index 0.647533 0.001 fractal_dimension_shannon_index 0.647533 0.001 sphericity_shannon_index 0.417255 0.001 shape_index_shannon_index 0.409958 0.001 rectangularity_shannon_index 0.389307 0.001 squareness_shannon_index 0.519414 0.001 equivalent_rectangular_index_shannon_index 0.370155 0.001 nhood_dists_mean 0.466052 0.001 <p>From the above table we can see that most of the morphological features are not too positively autocorrelated, however, all the features related to the neighborhoods (except the mean distances between cells) seem to have high positive autocorrelation. This means that the neighborhood features inside the lesion are not randomly distributed in space, but rather contain some sort of spatial structure.</p> <p>Note: being positively autocorrelated does not say much about how attributes co-vary over space and thus we don't know if some attributes cluster together based on the spatial autocorrelation.</p> In\u00a0[9]: Copied! <pre>import matplotlib.pyplot as plt\nfrom sklearn.cluster import AgglomerativeClustering\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.preprocessing import robust_scale, minmax_scale\n\nfrom sklearn import set_config\nset_config(transform_output = \"pandas\") # return pandas dataframes\n\n# helper function to calculate Silhouette score for a range of clusters\ndef get_silhouette(range: range, clust_vars, connectivity=None):\n    sil_score = []\n    for i in range:\n        # cluster using hierarchical clustering\n        aggl = AgglomerativeClustering(n_clusters=i, linkage=\"ward\", connectivity=connectivity)\n        aggl.fit(clust_vars)\n        labels = aggl.labels_\n        \n        # calculate Silhouette score\n        score = silhouette_score(\n            clust_vars,\n            labels,\n            metric=\"euclidean\",\n            sample_size=1000,\n            random_state=200\n        )\n        sil_score.append(score)\n\n    return sil_score\n\n# subset of features to use for clustering\nvars = [\n    \"area\",\n    \"sphericity\",\n    \"eccentricity\",\n    \"elongation\",\n    \"compactness\",\n    \"area_nhood_mean\",\n    \"sphericity_nhood_mean\",\n    \"elongation_nhood_mean\",\n    \"compactness_nhood_mean\",\n    \"eccentricity_nhood_mean\",\n    \"sphericity_shannon_index\",\n    \"elongation_shannon_index\",\n    \"compactness_shannon_index\",\n    \"eccentricity_shannon_index\",\n    \"area_shannon_index\",\n    \"nhood_dists_mean\"\n]\n\nclust_vars = neoplastic[vars]\n\n# Uncomment this if you want to scale the variables before clustering\n# cols = clust_vars.columns\n# big_feats = [\"area\", \"area_nhood_mean\", \"nhood_dists_mean\"]\n# clust_vars[big_feats] = minmax_scale(clust_vars[big_feats])\n# clust_vars.columns = cols\n\nsil_score = get_silhouette(range(3, 8), clust_vars)\nplt.plot(range(3, 8), sil_score)\n</pre> import matplotlib.pyplot as plt from sklearn.cluster import AgglomerativeClustering from sklearn.metrics import silhouette_score from sklearn.preprocessing import robust_scale, minmax_scale  from sklearn import set_config set_config(transform_output = \"pandas\") # return pandas dataframes  # helper function to calculate Silhouette score for a range of clusters def get_silhouette(range: range, clust_vars, connectivity=None):     sil_score = []     for i in range:         # cluster using hierarchical clustering         aggl = AgglomerativeClustering(n_clusters=i, linkage=\"ward\", connectivity=connectivity)         aggl.fit(clust_vars)         labels = aggl.labels_                  # calculate Silhouette score         score = silhouette_score(             clust_vars,             labels,             metric=\"euclidean\",             sample_size=1000,             random_state=200         )         sil_score.append(score)      return sil_score  # subset of features to use for clustering vars = [     \"area\",     \"sphericity\",     \"eccentricity\",     \"elongation\",     \"compactness\",     \"area_nhood_mean\",     \"sphericity_nhood_mean\",     \"elongation_nhood_mean\",     \"compactness_nhood_mean\",     \"eccentricity_nhood_mean\",     \"sphericity_shannon_index\",     \"elongation_shannon_index\",     \"compactness_shannon_index\",     \"eccentricity_shannon_index\",     \"area_shannon_index\",     \"nhood_dists_mean\" ]  clust_vars = neoplastic[vars]  # Uncomment this if you want to scale the variables before clustering # cols = clust_vars.columns # big_feats = [\"area\", \"area_nhood_mean\", \"nhood_dists_mean\"] # clust_vars[big_feats] = minmax_scale(clust_vars[big_feats]) # clust_vars.columns = cols  sil_score = get_silhouette(range(3, 8), clust_vars) plt.plot(range(3, 8), sil_score) Out[9]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f30c3247e20&gt;]</pre> <p>The best number of clusters is the max silhouette score. This means that the best number of clusters here is two. This probably indicates that the clusters are not well separable from each other based on just the cell features without spatial constraints. Let's now cluster the cells. Instead of using just two clusters, we'll use three clusters because 2 is just too little...</p> In\u00a0[10]: Copied! <pre># cluster using hierarchical clustering\nn_clust = range(3, 8)[np.argmax(sil_score)]\naggl = AgglomerativeClustering(n_clusters=n_clust, linkage=\"ward\")\naggl.fit(clust_vars)\nneoplastic[\"labels\"] = aggl.labels_\n\n# plot the tumor and neoplastic cells\nax = tumor.plot(\n    column=\"class_name\",\n    figsize=(10, 10),\n    alpha=0.2,\n    aspect=None\n)\nneoplastic.plot(\n    ax=ax,\n    column=\"labels\",\n    aspect=None,\n    legend=True,\n    categorical=True,\n    cmap=\"tab20_r\"\n)\n</pre> # cluster using hierarchical clustering n_clust = range(3, 8)[np.argmax(sil_score)] aggl = AgglomerativeClustering(n_clusters=n_clust, linkage=\"ward\") aggl.fit(clust_vars) neoplastic[\"labels\"] = aggl.labels_  # plot the tumor and neoplastic cells ax = tumor.plot(     column=\"class_name\",     figsize=(10, 10),     alpha=0.2,     aspect=None ) neoplastic.plot(     ax=ax,     column=\"labels\",     aspect=None,     legend=True,     categorical=True,     cmap=\"tab20_r\" ) Out[10]: <pre>&lt;Axes: &gt;</pre> <p>From the plot above we see that the clusters that there is little to none spatial structure in the clusters. The clusters are not spatially contiguous and the cells are scattered all over the lesion. This is probably because the clustering algorithm is not spatially constrained.</p> In\u00a0[11]: Copied! <pre>tt = neoplastic[[\"labels\"] + clust_vars.columns.tolist()].groupby(\"labels\").mean().T.round(3)\ntt\n</pre> tt = neoplastic[[\"labels\"] + clust_vars.columns.tolist()].groupby(\"labels\").mean().T.round(3) tt Out[11]: labels 0 1 2 area 615.589 196.781 351.902 sphericity 0.502 0.452 0.495 eccentricity 0.752 0.746 0.747 elongation 0.708 0.686 0.699 compactness 0.808 0.791 0.819 area_nhood_mean 447.310 265.057 389.967 sphericity_nhood_mean 0.492 0.461 0.494 elongation_nhood_mean 0.701 0.686 0.705 compactness_nhood_mean 0.811 0.794 0.815 eccentricity_nhood_mean 0.750 0.750 0.741 sphericity_shannon_index 1.083 1.064 1.096 elongation_shannon_index 1.084 1.076 1.090 compactness_shannon_index 1.005 1.014 1.004 eccentricity_shannon_index 0.917 0.888 0.955 area_shannon_index 1.117 0.878 1.077 nhood_dists_mean 41.478 35.367 38.703 In\u00a0[12]: Copied! <pre>sil_score = get_silhouette(range(3, 8), clust_vars, connectivity=w.sparse)\n\nplt.plot(range(3, 8), sil_score)\n</pre> sil_score = get_silhouette(range(3, 8), clust_vars, connectivity=w.sparse)  plt.plot(range(3, 8), sil_score) Out[12]: <pre>[&lt;matplotlib.lines.Line2D at 0x7f307858c490&gt;]</pre> In\u00a0[13]: Copied! <pre>aggl = AgglomerativeClustering(\n    linkage=\"ward\",\n    connectivity=w.sparse,\n    n_clusters=range(3, 8)[np.argmax(sil_score)]\n)\n\naggl.fit(clust_vars)\nneoplastic[\"labels_constrained\"] = aggl.labels_\n\n# plot the tumor and neoplastic cells\nax = tumor.plot(\n    column=\"class_name\",\n    figsize=(10, 10),\n    alpha=0.2,\n    aspect=None\n)\nneoplastic.plot(\n    ax=ax,\n    column=\"labels_constrained\",\n    aspect=None,\n    legend=True,\n    categorical=True,\n)\n</pre> aggl = AgglomerativeClustering(     linkage=\"ward\",     connectivity=w.sparse,     n_clusters=range(3, 8)[np.argmax(sil_score)] )  aggl.fit(clust_vars) neoplastic[\"labels_constrained\"] = aggl.labels_  # plot the tumor and neoplastic cells ax = tumor.plot(     column=\"class_name\",     figsize=(10, 10),     alpha=0.2,     aspect=None ) neoplastic.plot(     ax=ax,     column=\"labels_constrained\",     aspect=None,     legend=True,     categorical=True, ) Out[13]: <pre>&lt;Axes: &gt;</pre> <p>As you can see from the plot, once we apply a spatial constraint to the clustering algorithm, the clusters are more spatially contiguous and we get clear spatial structure in the clusters. The clusters differ in their morphological and neighborhood features as well as in their spatial location.</p> <p>Let's plot the differences between the clusters for each feature.</p> In\u00a0[14]: Copied! <pre>import seaborn as sns\n\n# tidy up the data\ntidy = neoplastic.set_index(\"labels_constrained\")[clust_vars.columns]\ntidy = tidy.stack()\ntidy = tidy.reset_index()\ntidy = tidy.rename(\n    columns={\"level_1\": \"Attribute\", 0: \"Values\"}\n)\n\nsns.set(font_scale=1.5)\nfacets = sns.FacetGrid(\n    data=tidy,\n    col=\"Attribute\",\n    hue=\"labels_constrained\",\n    sharey=False,\n    sharex=False,\n    aspect=2,\n    col_wrap=3,\n)\n# Build the plot from `sns.kdeplot`\nfacets.map(sns.kdeplot, \"Values\", shade=True).add_legend()\n</pre> import seaborn as sns  # tidy up the data tidy = neoplastic.set_index(\"labels_constrained\")[clust_vars.columns] tidy = tidy.stack() tidy = tidy.reset_index() tidy = tidy.rename(     columns={\"level_1\": \"Attribute\", 0: \"Values\"} )  sns.set(font_scale=1.5) facets = sns.FacetGrid(     data=tidy,     col=\"Attribute\",     hue=\"labels_constrained\",     sharey=False,     sharex=False,     aspect=2,     col_wrap=3, ) # Build the plot from `sns.kdeplot` facets.map(sns.kdeplot, \"Values\", shade=True).add_legend() Out[14]: <pre>&lt;seaborn.axisgrid.FacetGrid at 0x7f307858d600&gt;</pre> <p>The clearest differences can be seen in the area and neighborhood mean distances since we wanted to epmhasize these features by not scaling them to the same scale as the other features.</p>"},{"location":"user_guide/cell_regionalization/#cell-regionalization","title":"Cell Regionalization\u00b6","text":"<p>In geospatial analysis, regions are like clusters, where the members of the region are similar to each other in their attriburtes, but different from the members of other regions. The difference of regions and clusters is that regions are always spatially contiguous, meaning that they are connected to each other. In other words, regions are clusters with a spatial constraint. Regionalization is the process of finding regions in a spatial dataset.</p> <p>A regionalization is a special kind of clustering where the objective is to group observations which are similar in their statistical attributes, but also in their spatial location. In this sense, regionalization embeds the same logic as standard clustering techniques, but also it applies a series of geographical constraints. Often, these constraints relate to connectivity: two candidates can only be grouped together in the same region if there exists a path from one member to another member that never leaves the region. - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf</p> <p>In this notebook, instead of looking at the immune cells like in the previous examples, we'll be taking a look at neoplastic cells inside the tumor areas of a cervical pre-cancerous biopsy. Especially, we will explore the nuclei morphology characteristics and diversities of the cell neighborhoods inside the lesion.</p> <p>This notebook is adjusted and adapted version of this notebook from the great geographic science cookbook by Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf</p>"},{"location":"user_guide/cell_regionalization/#morphological-features","title":"Morphological Features\u00b6","text":"<p>Let's now compute all the morphological features <code>cellseg_gsontools</code> has to offer for every neoplastic cell.</p>"},{"location":"user_guide/cell_regionalization/#neighborhood-features","title":"Neighborhood Features\u00b6","text":"<p>Next, we'll compute the mean of the morphologic features for each cell neighborhood. To get the neighborhood features, we need to compute the spatial weights first.</p>"},{"location":"user_guide/cell_regionalization/#neighborhood-diversity-features","title":"Neighborhood Diversity Features\u00b6","text":"<p>Let's now compute the shannon diversity for each morphological metric to get a metric for the morphological diversities of the cell neighborhoods inside the lesion.</p>"},{"location":"user_guide/cell_regionalization/#neighborhood-distances","title":"Neighborhood Distances\u00b6","text":"<p>Among the neighborhood characters and diversities, we'll also compute the mean neighborhood distances.</p>"},{"location":"user_guide/cell_regionalization/#compute-morans-i-for-the-features","title":"Compute Moran's I for the Features\u00b6","text":"<p>We want to measure whether these variables contain spatial structure. For this we'll compute the Moran's I for each of the features. If the Moran's I value is close to 1, it means that the feature is highly spatially autocorrelated. If the Moran's I value is close to -1, it means that the feature is highly spatially dispersed. If the Moran's I value is close to 0, it means that the feature is randomly distributed in space.</p>"},{"location":"user_guide/cell_regionalization/#hierarchical-agglomerative-clustering-of-the-features","title":"Hierarchical Agglomerative Clustering of the Features\u00b6","text":"<p>Next, we'll cluster the cells based on their morphological and neighborhood features with hierarchical clustering. For now, we don't spatially constrain the algorithm to see whether simple clustering of the cell attributes show visual spatial structure. We'll use the silhouette score to detect the best number of clusters before doing the final clustering. We'll pick only a subset of the features we computed since so many of them are correlated and bring little value in separating clusters from each other.</p> <p>Note: We won't scale the variables, although, some of the features like the area and mean nhood distances are on a different scale than the other features. We do this because we want these features to have a higher weight in the clustering.</p>"},{"location":"user_guide/cell_regionalization/#regionalization","title":"Regionalization\u00b6","text":"<p>Next, we'll apply the same hierarchical clustering algorithm, but this time we will spatially constrain the algorithm. The aim is to find spatially contiguous clusters that have similar morphological and neighborhood feature values.</p>"},{"location":"user_guide/global_spatial_autocorrelation/","title":"Global Spatial Autocorrelation","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nfrom cellseg_gsontools import read_gdf\n\ntissue_path = Path(\"/path/to/tissues.geojson\")\nnuc_path = Path(\"/path/to/nuclei.geojson\")\n\ntissues = read_gdf(tissue_path)[[\"geometry\", \"class_name\"]] # take only relevant columns\nnuclei = read_gdf(nuc_path)[[\"geometry\", \"class_name\"]]\n\ntissues.head(5)\n</pre> from pathlib import Path from cellseg_gsontools import read_gdf  tissue_path = Path(\"/path/to/tissues.geojson\") nuc_path = Path(\"/path/to/nuclei.geojson\")  tissues = read_gdf(tissue_path)[[\"geometry\", \"class_name\"]] # take only relevant columns nuclei = read_gdf(nuc_path)[[\"geometry\", \"class_name\"]]  tissues.head(5) Out[1]: geometry class_name 0 POLYGON ((8726.00000 101404.00000, 8721.71000 ... area_cin 1 POLYGON ((8098.00000 102263.00000, 8095.19000 ... area_cin 2 POLYGON ((17873.00000 115644.00000, 17870.5200... areastroma 3 POLYGON ((16787.00000 100733.00000, 16773.7100... areastroma 4 POLYGON ((16387.00000 96785.00000, 16384.19000... areastroma In\u00a0[2]: Copied! <pre>nuclei.head(5)\n</pre> nuclei.head(5) Out[2]: geometry class_name 0 POLYGON ((6679.00000 103882.02000, 6677.01000 ... neoplastic 1 POLYGON ((6726.00000 103493.02000, 6724.01000 ... neoplastic 2 POLYGON ((6755.01000 103504.01000, 6755.01000 ... connective 3 POLYGON ((6823.99000 103510.01000, 6823.00000 ... connective 4 POLYGON ((6760.00000 103443.02000, 6758.01000 ... connective In\u00a0[3]: Copied! <pre>tissues.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None)\n</pre> tissues.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None) Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>nuclei.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None)\n</pre> nuclei.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None) Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre>stromaltissue = tissues.loc[tissues[\"class_name\"] == \"areastroma\"]\nstromaltissue.head(4)\n</pre> stromaltissue = tissues.loc[tissues[\"class_name\"] == \"areastroma\"] stromaltissue.head(4) Out[5]: geometry class_name 2 POLYGON ((17873.00000 115644.00000, 17870.5200... areastroma 3 POLYGON ((16787.00000 100733.00000, 16773.7100... areastroma 4 POLYGON ((16387.00000 96785.00000, 16384.19000... areastroma 5 POLYGON ((16365.00000 116080.00000, 16360.9800... areastroma In\u00a0[6]: Copied! <pre>from cellseg_gsontools.utils import set_uid\n\nstromalnuclei = nuclei.sjoin(stromaltissue, how=\"inner\", predicate=\"within\")\n\n# we will set a new indexing for the filtered cells for the contiguity graph\n# that is fitted next.\nstromalnuclei = set_uid(stromalnuclei, id_col=\"uid\", drop=False)\n\n# take only relevant columns\nstromalnuclei = stromalnuclei.loc[:, [\"geometry\", \"class_name_left\", \"uid\"]]\nstromalnuclei.rename(columns={\"class_name_left\": \"class_name\"}, inplace=True)\nstromalnuclei\n</pre> from cellseg_gsontools.utils import set_uid  stromalnuclei = nuclei.sjoin(stromaltissue, how=\"inner\", predicate=\"within\")  # we will set a new indexing for the filtered cells for the contiguity graph # that is fitted next. stromalnuclei = set_uid(stromalnuclei, id_col=\"uid\", drop=False)  # take only relevant columns stromalnuclei = stromalnuclei.loc[:, [\"geometry\", \"class_name_left\", \"uid\"]] stromalnuclei.rename(columns={\"class_name_left\": \"class_name\"}, inplace=True) stromalnuclei Out[6]: geometry class_name uid uid 0 POLYGON ((6726.00000 103493.02000, 6724.01000 ... neoplastic 0 1 POLYGON ((6755.01000 103504.01000, 6755.01000 ... connective 1 2 POLYGON ((6823.99000 103510.01000, 6823.00000 ... connective 2 3 POLYGON ((6760.00000 103443.02000, 6758.01000 ... connective 3 4 POLYGON ((6848.01000 103481.02000, 6845.01000 ... connective 4 ... ... ... ... 45605 POLYGON ((7217.01000 106533.02000, 7215.01000 ... neoplastic 45605 45606 POLYGON ((7390.00000 106510.02000, 7387.01000 ... neoplastic 45606 45607 POLYGON ((7133.75000 106514.00000, 7129.01000 ... neoplastic 45607 45608 POLYGON ((7130.01000 106557.02000, 7129.01000 ... inflammatory 45608 45609 POLYGON ((7168.01000 106550.02000, 7168.01000 ... neoplastic 45609 <p>45610 rows \u00d7 3 columns</p> In\u00a0[7]: Copied! <pre>stromalnuclei.plot(\n    figsize=(10, 15),\n    column=\"class_name\",\n    legend=True,\n    aspect=None,\n)\n</pre> stromalnuclei.plot(     figsize=(10, 15),     column=\"class_name\",     legend=True,     aspect=None, ) Out[7]: <pre>&lt;Axes: &gt;</pre> In\u00a0[8]: Copied! <pre>from cellseg_gsontools.graphs import fit_graph\n\nw = fit_graph(\n    stromalnuclei,\n    type=\"distband\",\n    id_col=\"uid\",\n    thresh=100,\n)\n\n# Non-standardized weights\nw.transform = \"R\"\nw\n</pre> from cellseg_gsontools.graphs import fit_graph  w = fit_graph(     stromalnuclei,     type=\"distband\",     id_col=\"uid\",     thresh=100, )  # Non-standardized weights w.transform = \"R\" w Out[8]: <pre>&lt;libpysal.weights.distance.DistanceBand at 0x7fd91de2b4f0&gt;</pre> In\u00a0[9]: Copied! <pre>from cellseg_gsontools.apply import gdf_apply\nfrom cellseg_gsontools.neighbors import neighborhood, nhood_vals, nhood_type_count\nfrom functools import partial\n\n# Get the neihgboring nodes of the graph\nfunc = partial(neighborhood, spatial_weights=w)\nstromalnuclei[\"nhood\"] = gdf_apply(stromalnuclei, func, columns=[\"uid\"])\n\n# Get the classes of the neighboring nodes\nfunc = partial(nhood_vals, values=stromalnuclei[\"class_name\"])\nstromalnuclei[\"nhood_classes\"] = gdf_apply(\n    stromalnuclei,\n    func=func,\n    parallel=True,\n    columns=[\"nhood\"],\n)\n\n# Get the number of inflammatory cells in the neighborhood\nfunc = partial(nhood_type_count, cls=\"inflammatory\", frac=False)\nstromalnuclei[\"immune_cnt\"] = gdf_apply(\n    stromalnuclei,\n    func=func,\n    parallel=True,\n    columns=[\"nhood_classes\"],\n)\n\n# Get the fraction of inflammatory cells in the neighborhood\nfunc = partial(nhood_type_count, cls=\"inflammatory\", frac=True)\nstromalnuclei[\"immune_frac\"] = gdf_apply(\n    stromalnuclei,\n    func=func,\n    parallel=True,\n    columns=[\"nhood_classes\"],\n)\n\n# This will smooth the extremes (e.g. if there is only one inflammatory cell in the \n# neighborhood, the fraction will be 1)\nstromalnuclei[\"immune_index\"] = stromalnuclei[\"immune_frac\"] * stromalnuclei[\"immune_cnt\"]\n\nstromalnuclei\n</pre> from cellseg_gsontools.apply import gdf_apply from cellseg_gsontools.neighbors import neighborhood, nhood_vals, nhood_type_count from functools import partial  # Get the neihgboring nodes of the graph func = partial(neighborhood, spatial_weights=w) stromalnuclei[\"nhood\"] = gdf_apply(stromalnuclei, func, columns=[\"uid\"])  # Get the classes of the neighboring nodes func = partial(nhood_vals, values=stromalnuclei[\"class_name\"]) stromalnuclei[\"nhood_classes\"] = gdf_apply(     stromalnuclei,     func=func,     parallel=True,     columns=[\"nhood\"], )  # Get the number of inflammatory cells in the neighborhood func = partial(nhood_type_count, cls=\"inflammatory\", frac=False) stromalnuclei[\"immune_cnt\"] = gdf_apply(     stromalnuclei,     func=func,     parallel=True,     columns=[\"nhood_classes\"], )  # Get the fraction of inflammatory cells in the neighborhood func = partial(nhood_type_count, cls=\"inflammatory\", frac=True) stromalnuclei[\"immune_frac\"] = gdf_apply(     stromalnuclei,     func=func,     parallel=True,     columns=[\"nhood_classes\"], )  # This will smooth the extremes (e.g. if there is only one inflammatory cell in the  # neighborhood, the fraction will be 1) stromalnuclei[\"immune_index\"] = stromalnuclei[\"immune_frac\"] * stromalnuclei[\"immune_cnt\"]  stromalnuclei Out[9]: geometry class_name uid nhood nhood_classes immune_cnt immune_frac immune_index uid 0 POLYGON ((6726.00000 103493.02000, 6724.01000 ... neoplastic 0 [0, 1, 2, 3] [neoplastic, connective, connective, connective] 0.0 0.000000 0.000000 1 POLYGON ((6755.01000 103504.01000, 6755.01000 ... connective 1 [1, 0, 2, 3, 4] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 2 POLYGON ((6823.99000 103510.01000, 6823.00000 ... connective 2 [2, 0, 1, 3, 4, 5, 6, 7] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 3 POLYGON ((6760.00000 103443.02000, 6758.01000 ... connective 3 [3, 0, 1, 2, 8] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 4 POLYGON ((6848.01000 103481.02000, 6845.01000 ... connective 4 [4, 1, 2, 5, 6, 7, 8] [connective, connective, connective, connectiv... 0.0 0.000000 0.000000 ... ... ... ... ... ... ... ... ... 45605 POLYGON ((7217.01000 106533.02000, 7215.01000 ... neoplastic 45605 [45605, 45602, 45604, 45607, 45608, 45609] [neoplastic, neoplastic, neoplastic, neoplasti... 1.0 0.166667 0.166667 45606 POLYGON ((7390.00000 106510.02000, 7387.01000 ... neoplastic 45606 [45606, 45601, 45602, 45603] [neoplastic, inflammatory, neoplastic, neoplas... 1.0 0.250000 0.250000 45607 POLYGON ((7133.75000 106514.00000, 7129.01000 ... neoplastic 45607 [45607, 45604, 45605, 45608, 45609] [neoplastic, neoplastic, neoplastic, inflammat... 1.0 0.200000 0.200000 45608 POLYGON ((7130.01000 106557.02000, 7129.01000 ... inflammatory 45608 [45608, 45604, 45605, 45607, 45609] [inflammatory, neoplastic, neoplastic, neoplas... 1.0 0.200000 0.200000 45609 POLYGON ((7168.01000 106550.02000, 7168.01000 ... neoplastic 45609 [45609, 45604, 45605, 45607, 45608] [neoplastic, neoplastic, neoplastic, neoplasti... 1.0 0.200000 0.200000 <p>45610 rows \u00d7 8 columns</p> In\u00a0[10]: Copied! <pre>from libpysal.weights import lag_spatial\n\nstromalnuclei[\"immune_index_lag\"] = lag_spatial(w, stromalnuclei[\"immune_index\"].values)\nstromalnuclei[\"immune_index_lag\"]\n</pre> from libpysal.weights import lag_spatial  stromalnuclei[\"immune_index_lag\"] = lag_spatial(w, stromalnuclei[\"immune_index\"].values) stromalnuclei[\"immune_index_lag\"] Out[10]: <pre>uid\n0        0.000000\n1        0.000000\n2        0.000000\n3        0.000000\n4        0.000000\n           ...   \n45605    0.160000\n45606    0.194444\n45607    0.191667\n45608    0.191667\n45609    0.191667\nName: immune_index_lag, Length: 45610, dtype: float64</pre> In\u00a0[11]: Copied! <pre># Standardize the immune_fraction column\nstromalnuclei[\"immune_index_normed\"] = (\n    stromalnuclei[\"immune_index\"] - stromalnuclei[\"immune_index\"].mean()\n)\n\n# Display the updated dataframe\nstromalnuclei\n</pre> # Standardize the immune_fraction column stromalnuclei[\"immune_index_normed\"] = (     stromalnuclei[\"immune_index\"] - stromalnuclei[\"immune_index\"].mean() )  # Display the updated dataframe stromalnuclei Out[11]: geometry class_name uid nhood nhood_classes immune_cnt immune_frac immune_index immune_index_lag immune_index_normed uid 0 POLYGON ((6726.00000 103493.02000, 6724.01000 ... neoplastic 0 [0, 1, 2, 3] [neoplastic, connective, connective, connective] 0.0 0.000000 0.000000 0.000000 -1.550176 1 POLYGON ((6755.01000 103504.01000, 6755.01000 ... connective 1 [1, 0, 2, 3, 4] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 0.000000 -1.550176 2 POLYGON ((6823.99000 103510.01000, 6823.00000 ... connective 2 [2, 0, 1, 3, 4, 5, 6, 7] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 0.000000 -1.550176 3 POLYGON ((6760.00000 103443.02000, 6758.01000 ... connective 3 [3, 0, 1, 2, 8] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 0.000000 -1.550176 4 POLYGON ((6848.01000 103481.02000, 6845.01000 ... connective 4 [4, 1, 2, 5, 6, 7, 8] [connective, connective, connective, connectiv... 0.0 0.000000 0.000000 0.000000 -1.550176 ... ... ... ... ... ... ... ... ... ... ... 45605 POLYGON ((7217.01000 106533.02000, 7215.01000 ... neoplastic 45605 [45605, 45602, 45604, 45607, 45608, 45609] [neoplastic, neoplastic, neoplastic, neoplasti... 1.0 0.166667 0.166667 0.160000 -1.383510 45606 POLYGON ((7390.00000 106510.02000, 7387.01000 ... neoplastic 45606 [45606, 45601, 45602, 45603] [neoplastic, inflammatory, neoplastic, neoplas... 1.0 0.250000 0.250000 0.194444 -1.300176 45607 POLYGON ((7133.75000 106514.00000, 7129.01000 ... neoplastic 45607 [45607, 45604, 45605, 45608, 45609] [neoplastic, neoplastic, neoplastic, inflammat... 1.0 0.200000 0.200000 0.191667 -1.350176 45608 POLYGON ((7130.01000 106557.02000, 7129.01000 ... inflammatory 45608 [45608, 45604, 45605, 45607, 45609] [inflammatory, neoplastic, neoplastic, neoplas... 1.0 0.200000 0.200000 0.191667 -1.350176 45609 POLYGON ((7168.01000 106550.02000, 7168.01000 ... neoplastic 45609 [45609, 45604, 45605, 45607, 45608] [neoplastic, neoplastic, neoplastic, neoplasti... 1.0 0.200000 0.200000 0.191667 -1.350176 <p>45610 rows \u00d7 10 columns</p> <p>Let's plot!</p> In\u00a0[12]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\n\nf, ax = plt.subplots(1, figsize=(6, 6))\nsns.regplot(\n    ax=ax,\n    x=\"immune_index_normed\",\n    y=\"immune_index_lag\",\n    ci=None,\n    data=stromalnuclei,\n    line_kws={\"color\": \"orange\"},\n)\n\nax.set_title(\"Moran Plot - Immune Cell Index\")\n</pre> import matplotlib.pyplot as plt import seaborn as sns  f, ax = plt.subplots(1, figsize=(6, 6)) sns.regplot(     ax=ax,     x=\"immune_index_normed\",     y=\"immune_index_lag\",     ci=None,     data=stromalnuclei,     line_kws={\"color\": \"orange\"}, )  ax.set_title(\"Moran Plot - Immune Cell Index\") Out[12]: <pre>Text(0.5, 1.0, 'Moran Plot - Immune Cell Index')</pre> <p>From the plot above, we can see that the immune cell index is positively correlated with its spatial lag. This means that cells with high immune cell index tend to be surrounded by cells with high immune cell index and low immune index cells are surrounded by low other low immune index cells. This is an indication of positive spatial autocorrelation. The main pattern of this data seems to be that similar immune index values tend to be located close to each other.</p> In\u00a0[13]: Copied! <pre># !pip install esda\n</pre> # !pip install esda In\u00a0[14]: Copied! <pre>import esda\n\nmoran = esda.Moran(stromalnuclei[\"immune_index\"], w)\n</pre> import esda  moran = esda.Moran(stromalnuclei[\"immune_index\"], w) In\u00a0[15]: Copied! <pre>moran.I\n</pre> moran.I Out[15]: <pre>0.8723745127666674</pre> <p>The obtained Moran's I statistic tells us that there is a positive spatial autocorrelation in the immune cell index</p> In\u00a0[16]: Copied! <pre>moran.p_sim\n</pre> moran.p_sim Out[16]: <pre>0.001</pre> <p>P-values for accepting/rejecting the hypothesis that the variable (immune index) is randomly distributed spatially across the cells. This p-value is computed over 999 simulations of spatially randomly distributed variable immune indices, thus, the oddly specific p-value. From these results, we can conclude that the cells in the stroma displays more spatial pattern than we would expect if the immune index of the cells had been randomly allocated to random locations.</p> In\u00a0[17]: Copied! <pre>ax = tissues.plot(\n    figsize=(10, 15),\n    column=\"class_name\",\n    alpha=0.1,\n    legend=True,\n    aspect=None,\n)\n\nax = stromalnuclei.plot(\n    ax=ax,\n    column=\"immune_index\",\n    legend=True,\n    aspect=None,\n    scheme=\"Quantiles\",\n    cmap=\"turbo\"\n)\n\nax.set_title(\"Immune Cell Index of Cells Within Stroma\")\nax.set_axis_off()\n</pre> ax = tissues.plot(     figsize=(10, 15),     column=\"class_name\",     alpha=0.1,     legend=True,     aspect=None, )  ax = stromalnuclei.plot(     ax=ax,     column=\"immune_index\",     legend=True,     aspect=None,     scheme=\"Quantiles\",     cmap=\"turbo\" )  ax.set_title(\"Immune Cell Index of Cells Within Stroma\") ax.set_axis_off() <p>Just by eyeballing the plot, it's quite obvious that the cells with high immune cell index tend to cluster together. These can be seen as the red 'hotspots' in the plot. This is also supported by the Moran's I statistic and Moran plot. Another thing to notice here, is that the hotspots localize close to the pre-cancerous lesions - an indication of immune infiltration. We will dig into this in more detail in the next notebook.</p>"},{"location":"user_guide/global_spatial_autocorrelation/#global-spatial-autocorrelation","title":"Global Spatial Autocorrelation\u00b6","text":"<p>Spatial autocorrelation is the degree to which a variable is correlated with itself across space. It is a measure of how things are related to each other based on their locations. It is a key concept in spatial statistics and has many applications in spatial data analysis.</p> <p>A lot of this notebook is borrowed almost directly from this notebook (just adapted to cell/nuclei/tissue segmentation domain) including the following descriptions of spatial autocorrelation. So please check it out for more details. It is very good.</p> <p>\"Spatial autocorrelation measures the degree to which the similarity in values between observations in a dataset is related to the similarity in locations of such observations. - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf\"</p> <p>\"A key idea in this context is that of spatial randomness: a situation in which the location of an observation gives no information whatsoever about its value. In other words, a variable is spatially random if its distribution follows no discernible spatial pattern. Spatial autocorrelation can thus be defined as the \u201cabsence of spatial randomness\u201d.\" - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf\"</p> <p>\"Spatial autocorrelation is typically categorized along two main dimensions: sign and scale. Similar to the traditional, non-spatial case, spatial autocorrelation can adopt two main forms: positive and negative. The former relates to a situation where similarity and geographical closeness go hand-in-hand. In other words, similar values are located near each other, while different values tend to be scattered and further away. It is important that the sign of these values is not relevant for the presence of spatial autocorrelation: it may be high values close to high values, or low values close to low values. The important bit in this context is the relationship between closeness and statistical similarity is positive.\" - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf\"</p> <p>In this notebook, we will be using the Global Moran's I statistic and the infamous Moran scatter plot to measure spatial autocorrelation. We are especially interested, whether the immune cells appear in each others cell neighborhoods, thus, showing spatial autocorrelation. In other words, we want to basically see whether there is some sort of global trend of immune cell clustering.</p>"},{"location":"user_guide/global_spatial_autocorrelation/#the-data","title":"The Data\u00b6","text":"<p>Like in the Spatial Grids example, the data used in this example is a cervical pre-cancerous biopsy. The data is not publicly available, so this serves only as a demonstration of the functionality <code>cellseg_gsontools</code>.</p>"},{"location":"user_guide/global_spatial_autocorrelation/#filtering-the-cells-in-the-stroma","title":"Filtering the Cells in the Stroma\u00b6","text":"<p>In this example, we will be looking at the spatial autocorrelation of cells within the stroma. Thus, we will filter only the cells within the stroma from the data.</p>"},{"location":"user_guide/global_spatial_autocorrelation/#spatial-weights","title":"Spatial Weights\u00b6","text":"<p>Next, we will fit a contiguity grpah on the cells, to extract the neighborhoods of each cell. We will use the <code>distband</code> contiguity graph, that connects each cell to all cells within a certain distance. We will use a distance of 50 microns (100 pixels since the segmentation was run done 20x magnification).</p>"},{"location":"user_guide/global_spatial_autocorrelation/#neighborhood-immune-index","title":"Neighborhood Immune Index\u00b6","text":"<p>Since we are interested in the global spatial autocorrelation of immune cell localization, we will calculate the count and fraction of the immune cells in each cell neighborhood. We will use these features to calculate an immune index (immune fraction $\\times$ immune count) that we will use as the feature for the global autocorrelation analysis. The reason to use the immune index instead of the immune fraction is that the immune fraction will give high values for neihgborhoods with 1/1 or 2/2 immune cells which is are not very indicative of the actual clustering of immune cells whereas neighborhood of 9/9 immune cells would be indicative of clustering.</p>"},{"location":"user_guide/global_spatial_autocorrelation/#spatial-lag","title":"Spatial Lag\u00b6","text":"<p>To compute the Global Moran's I statistic, the spatial lag of a variable is needed. This applies also to the Moran plot. Our variables of interest is the immune index.</p> <p>\"The spatial lag operator is one of the most common and direct applications of spatial weights matrices (called formally) in spatial analysis. The mathematical definition is the product of and the vector of a given variable. Conceptually, the spatial lag captures the behavior of a variable in the immediate surroundings of each location; in that respect, it is akin to a local smoother of a variable.\" - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf\"</p>"},{"location":"user_guide/global_spatial_autocorrelation/#moran-plot-and-morans-i","title":"Moran Plot and Moran's I\u00b6","text":"<p>Next we will plot the so called Moran scatter plot after which we will compute the Moran's I statistic for the immune index. The Moran's I statistic is a measure of spatial autocorrelation based on attribute similarity. Here, it is a measure of how similar the immune index values are to its spatial lag values.</p>"},{"location":"user_guide/global_spatial_autocorrelation/#the-moran-plot","title":"The Moran Plot\u00b6","text":"<p>The Moran plot is a traditional scatter plot in which the variable of interest is displayed against its spatial lag. In order to be able to interpret values as above or below the mean, the variable of interest is usually standardized by subtracting its mean. - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf</p>"},{"location":"user_guide/global_spatial_autocorrelation/#morans-i-statistic","title":"Moran's I Statistic\u00b6","text":"<p>To compute the Moran's I statistic, we will use the <code>esda</code> package.</p> <p>\"Moran\u2019s I captures much of the essence of the Moran Plot. In fact, there is a close connection between the two: the value of Moran\u2019s I corresponds with the slope of the linear fit overlayed on top of the Moran Plot.\"</p>"},{"location":"user_guide/global_spatial_autocorrelation/#plotting-the-immune-cell-index","title":"Plotting the Immune Cell Index\u00b6","text":"<p>Lastly, let's visualize the immune cell fraction and immune cell count on the tissue to see whether the immune cells tend to form spatial clusters and localize nearby each other.</p>"},{"location":"user_guide/local_spatial_autocorrelation/","title":"Local Spatial Autocorrelation","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nfrom cellseg_gsontools import read_gdf\n\ntissue_path = Path(\"/path/to/tissues.geojson\")\nnuc_path = Path(\"/path/to/nuclei.geojson\")\n\ntissues = read_gdf(tissue_path)[[\"geometry\", \"class_name\"]] # take only relevant columns\nnuclei = read_gdf(nuc_path)[[\"geometry\", \"class_name\"]]\n\ntissues.head(5)\n</pre> from pathlib import Path from cellseg_gsontools import read_gdf  tissue_path = Path(\"/path/to/tissues.geojson\") nuc_path = Path(\"/path/to/nuclei.geojson\")  tissues = read_gdf(tissue_path)[[\"geometry\", \"class_name\"]] # take only relevant columns nuclei = read_gdf(nuc_path)[[\"geometry\", \"class_name\"]]  tissues.head(5) Out[1]: geometry class_name 0 POLYGON ((8726.00000 101404.00000, 8721.71000 ... area_cin 1 POLYGON ((8098.00000 102263.00000, 8095.19000 ... area_cin 2 POLYGON ((17873.00000 115644.00000, 17870.5200... areastroma 3 POLYGON ((16787.00000 100733.00000, 16773.7100... areastroma 4 POLYGON ((16387.00000 96785.00000, 16384.19000... areastroma In\u00a0[2]: Copied! <pre>nuclei.head(5)\n</pre> nuclei.head(5) Out[2]: geometry class_name 0 POLYGON ((6679.00000 103882.02000, 6677.01000 ... neoplastic 1 POLYGON ((6726.00000 103493.02000, 6724.01000 ... neoplastic 2 POLYGON ((6755.01000 103504.01000, 6755.01000 ... connective 3 POLYGON ((6823.99000 103510.01000, 6823.00000 ... connective 4 POLYGON ((6760.00000 103443.02000, 6758.01000 ... connective In\u00a0[3]: Copied! <pre>tissues.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None)\n</pre> tissues.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None) Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>nuclei.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None)\n</pre> nuclei.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None) Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre>stromaltissue = tissues.loc[tissues[\"class_name\"] == \"areastroma\"]\nstromaltissue.head(4)\n</pre> stromaltissue = tissues.loc[tissues[\"class_name\"] == \"areastroma\"] stromaltissue.head(4) Out[5]: geometry class_name 2 POLYGON ((17873.00000 115644.00000, 17870.5200... areastroma 3 POLYGON ((16787.00000 100733.00000, 16773.7100... areastroma 4 POLYGON ((16387.00000 96785.00000, 16384.19000... areastroma 5 POLYGON ((16365.00000 116080.00000, 16360.9800... areastroma In\u00a0[6]: Copied! <pre>from cellseg_gsontools.utils import set_uid\n\nstromalnuclei = nuclei.sjoin(stromaltissue, how=\"inner\", predicate=\"within\")\n\n# we will set a new indexing for the filtered cells for the contiguity graph\n# that is fitted next.\nstromalnuclei = set_uid(stromalnuclei, id_col=\"uid\", drop=False)\n\n# take only relevant columns\nstromalnuclei = stromalnuclei.loc[:, [\"geometry\", \"class_name_left\", \"uid\"]]\nstromalnuclei.rename(columns={\"class_name_left\": \"class_name\"}, inplace=True)\nstromalnuclei\n</pre> from cellseg_gsontools.utils import set_uid  stromalnuclei = nuclei.sjoin(stromaltissue, how=\"inner\", predicate=\"within\")  # we will set a new indexing for the filtered cells for the contiguity graph # that is fitted next. stromalnuclei = set_uid(stromalnuclei, id_col=\"uid\", drop=False)  # take only relevant columns stromalnuclei = stromalnuclei.loc[:, [\"geometry\", \"class_name_left\", \"uid\"]] stromalnuclei.rename(columns={\"class_name_left\": \"class_name\"}, inplace=True) stromalnuclei Out[6]: geometry class_name uid uid 0 POLYGON ((6726.00000 103493.02000, 6724.01000 ... neoplastic 0 1 POLYGON ((6755.01000 103504.01000, 6755.01000 ... connective 1 2 POLYGON ((6823.99000 103510.01000, 6823.00000 ... connective 2 3 POLYGON ((6760.00000 103443.02000, 6758.01000 ... connective 3 4 POLYGON ((6848.01000 103481.02000, 6845.01000 ... connective 4 ... ... ... ... 45605 POLYGON ((7217.01000 106533.02000, 7215.01000 ... neoplastic 45605 45606 POLYGON ((7390.00000 106510.02000, 7387.01000 ... neoplastic 45606 45607 POLYGON ((7133.75000 106514.00000, 7129.01000 ... neoplastic 45607 45608 POLYGON ((7130.01000 106557.02000, 7129.01000 ... inflammatory 45608 45609 POLYGON ((7168.01000 106550.02000, 7168.01000 ... neoplastic 45609 <p>45610 rows \u00d7 3 columns</p> In\u00a0[7]: Copied! <pre>stromalnuclei.plot(\n    figsize=(10, 15),\n    column=\"class_name\",\n    legend=True,\n    aspect=None,\n)\n</pre> stromalnuclei.plot(     figsize=(10, 15),     column=\"class_name\",     legend=True,     aspect=None, ) Out[7]: <pre>&lt;Axes: &gt;</pre> In\u00a0[8]: Copied! <pre>from cellseg_gsontools.graphs import fit_graph\n\nw = fit_graph(\n    stromalnuclei,\n    type=\"distband\",\n    id_col=\"uid\",\n    thresh=100,\n)\n\n# Row-standardized weights\nw.transform = \"R\"\nw\n</pre> from cellseg_gsontools.graphs import fit_graph  w = fit_graph(     stromalnuclei,     type=\"distband\",     id_col=\"uid\",     thresh=100, )  # Row-standardized weights w.transform = \"R\" w Out[8]: <pre>&lt;libpysal.weights.distance.DistanceBand at 0x7f812853ada0&gt;</pre> In\u00a0[9]: Copied! <pre>from cellseg_gsontools.apply import gdf_apply\nfrom cellseg_gsontools.neighbors import neighborhood, nhood_vals, nhood_type_count\nfrom functools import partial\n\n# Get the neihgboring nodes of the graph\nfunc = partial(neighborhood, spatial_weights=w)\nstromalnuclei[\"nhood\"] = gdf_apply(stromalnuclei, func, columns=[\"uid\"])\n\n# Get the classes of the neighboring nodes\nfunc = partial(nhood_vals, values=stromalnuclei[\"class_name\"])\nstromalnuclei[\"nhood_classes\"] = gdf_apply(\n    stromalnuclei,\n    func=func,\n    parallel=True,\n    columns=[\"nhood\"],\n)\n\n# Get the number of inflammatory cells in the neighborhood\nfunc = partial(nhood_type_count, cls=\"inflammatory\", frac=False)\nstromalnuclei[\"immune_cnt\"] = gdf_apply(\n    stromalnuclei,\n    func=func,\n    parallel=True,\n    columns=[\"nhood_classes\"],\n)\n\n# Get the fraction of inflammatory cells in the neighborhood\nfunc = partial(nhood_type_count, cls=\"inflammatory\", frac=True)\nstromalnuclei[\"immune_frac\"] = gdf_apply(\n    stromalnuclei,\n    func=func,\n    parallel=True,\n    columns=[\"nhood_classes\"],\n)\n\n# This will smooth the extremes (e.g. if there is only one inflammatory cell in the \n# neighborhood, the fraction will be 1)\nstromalnuclei[\"immune_index\"] = stromalnuclei[\"immune_frac\"] * stromalnuclei[\"immune_cnt\"]\n\nstromalnuclei\n</pre> from cellseg_gsontools.apply import gdf_apply from cellseg_gsontools.neighbors import neighborhood, nhood_vals, nhood_type_count from functools import partial  # Get the neihgboring nodes of the graph func = partial(neighborhood, spatial_weights=w) stromalnuclei[\"nhood\"] = gdf_apply(stromalnuclei, func, columns=[\"uid\"])  # Get the classes of the neighboring nodes func = partial(nhood_vals, values=stromalnuclei[\"class_name\"]) stromalnuclei[\"nhood_classes\"] = gdf_apply(     stromalnuclei,     func=func,     parallel=True,     columns=[\"nhood\"], )  # Get the number of inflammatory cells in the neighborhood func = partial(nhood_type_count, cls=\"inflammatory\", frac=False) stromalnuclei[\"immune_cnt\"] = gdf_apply(     stromalnuclei,     func=func,     parallel=True,     columns=[\"nhood_classes\"], )  # Get the fraction of inflammatory cells in the neighborhood func = partial(nhood_type_count, cls=\"inflammatory\", frac=True) stromalnuclei[\"immune_frac\"] = gdf_apply(     stromalnuclei,     func=func,     parallel=True,     columns=[\"nhood_classes\"], )  # This will smooth the extremes (e.g. if there is only one inflammatory cell in the  # neighborhood, the fraction will be 1) stromalnuclei[\"immune_index\"] = stromalnuclei[\"immune_frac\"] * stromalnuclei[\"immune_cnt\"]  stromalnuclei Out[9]: geometry class_name uid nhood nhood_classes immune_cnt immune_frac immune_index uid 0 POLYGON ((6726.00000 103493.02000, 6724.01000 ... neoplastic 0 [0, 1, 2, 3] [neoplastic, connective, connective, connective] 0.0 0.000000 0.000000 1 POLYGON ((6755.01000 103504.01000, 6755.01000 ... connective 1 [1, 0, 2, 3, 4] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 2 POLYGON ((6823.99000 103510.01000, 6823.00000 ... connective 2 [2, 0, 1, 3, 4, 5, 6, 7] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 3 POLYGON ((6760.00000 103443.02000, 6758.01000 ... connective 3 [3, 0, 1, 2, 8] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 4 POLYGON ((6848.01000 103481.02000, 6845.01000 ... connective 4 [4, 1, 2, 5, 6, 7, 8] [connective, connective, connective, connectiv... 0.0 0.000000 0.000000 ... ... ... ... ... ... ... ... ... 45605 POLYGON ((7217.01000 106533.02000, 7215.01000 ... neoplastic 45605 [45605, 45602, 45604, 45607, 45608, 45609] [neoplastic, neoplastic, neoplastic, neoplasti... 1.0 0.166667 0.166667 45606 POLYGON ((7390.00000 106510.02000, 7387.01000 ... neoplastic 45606 [45606, 45601, 45602, 45603] [neoplastic, inflammatory, neoplastic, neoplas... 1.0 0.250000 0.250000 45607 POLYGON ((7133.75000 106514.00000, 7129.01000 ... neoplastic 45607 [45607, 45604, 45605, 45608, 45609] [neoplastic, neoplastic, neoplastic, inflammat... 1.0 0.200000 0.200000 45608 POLYGON ((7130.01000 106557.02000, 7129.01000 ... inflammatory 45608 [45608, 45604, 45605, 45607, 45609] [inflammatory, neoplastic, neoplastic, neoplas... 1.0 0.200000 0.200000 45609 POLYGON ((7168.01000 106550.02000, 7168.01000 ... neoplastic 45609 [45609, 45604, 45605, 45607, 45608] [neoplastic, neoplastic, neoplastic, neoplasti... 1.0 0.200000 0.200000 <p>45610 rows \u00d7 8 columns</p> <p>Let's first center the immune index variable.</p> In\u00a0[10]: Copied! <pre># Standardize the immune_fraction column\nstromalnuclei[\"immune_index_normed\"] = (\n    stromalnuclei[\"immune_index\"] - stromalnuclei[\"immune_index\"].mean()\n)\n\n# Let's look at the distribution of the immune cell counts when normalized immune index is &gt; 0\nstromalnuclei[stromalnuclei[\"immune_index_normed\"] &gt; 0][\"immune_cnt\"].value_counts(sort=False)\n</pre> # Standardize the immune_fraction column stromalnuclei[\"immune_index_normed\"] = (     stromalnuclei[\"immune_index\"] - stromalnuclei[\"immune_index\"].mean() )  # Let's look at the distribution of the immune cell counts when normalized immune index is &gt; 0 stromalnuclei[stromalnuclei[\"immune_index_normed\"] &gt; 0][\"immune_cnt\"].value_counts(sort=False) Out[10]: <pre>immune_cnt\n4.0      872\n6.0     2200\n5.0     2017\n3.0      153\n10.0     856\n7.0     1803\n8.0     1287\n2.0       20\n9.0     1056\n12.0     606\n11.0     736\n14.0     412\n21.0      41\n15.0     336\n13.0     526\n18.0     107\n20.0      58\n17.0     180\n19.0      81\n16.0     242\n23.0      15\n29.0       3\n22.0      20\n24.0      14\n25.0       7\n28.0       2\n26.0       3\n27.0       1\nName: count, dtype: int64</pre> <p>We can see that when we look at the immune counts at the cell neighborhoods for cells with normalized immune index greater than zero, they are all more or equal to 4. This means that the cells with HH immune index have at least 4 immune cells as neighbors.</p> <p>Let's next plot the Moran's plot</p> In\u00a0[11]: Copied! <pre>import matplotlib.pyplot as plt\nimport seaborn as sns\nfrom libpysal.weights import lag_spatial\n\n\ndef plot_moran(ax, val_col, lag_col, offset):\n    # Plot values\n    ax = sns.regplot(\n        ax=ax,\n        x=val_col,\n        y=lag_col,\n        data=stromalnuclei,\n        ci=None,\n        scatter_kws=dict(s=1),\n        line_kws=dict(color=\"orange\"),\n    )\n\n    ax.axvline(0, alpha=0.5, color=\"k\", linestyle=\"--\")\n    ax.axhline(0, alpha=0.5, color=\"k\", linestyle=\"--\")\n    \n    xmin, xmax = ax.get_xlim()\n    ymin, ymax = ax.get_ylim()\n    \n    # Add text labels for each quadrant\n    ax.text(xmax - offset, ymax - offset, \"HH\", fontsize=25, c=\"r\")\n    ax.text(xmax - offset, ymin + offset, \"HL\", fontsize=25, c=\"r\")\n    ax.text(xmin + offset, ymax - offset, \"LH\", fontsize=25, c=\"r\")\n    ax.text(xmin + offset, ymin + offset, \"LL\", fontsize=25, c=\"r\")\n\n    return ax\n\n# Let's first compute the spatial lags\nstromalnuclei[\"immune_index_lag\"] = lag_spatial(w, stromalnuclei[\"immune_index_normed\"].values)\n\n\n# Set up the figure and axis\nf, ax = plt.subplots(1, figsize=(6, 6))\nax = plot_moran(ax, \"immune_index_normed\", \"immune_index_lag\", offset=0.7)\nax.set_title(\"Moran Plot Local\", fontsize=20)\n</pre> import matplotlib.pyplot as plt import seaborn as sns from libpysal.weights import lag_spatial   def plot_moran(ax, val_col, lag_col, offset):     # Plot values     ax = sns.regplot(         ax=ax,         x=val_col,         y=lag_col,         data=stromalnuclei,         ci=None,         scatter_kws=dict(s=1),         line_kws=dict(color=\"orange\"),     )      ax.axvline(0, alpha=0.5, color=\"k\", linestyle=\"--\")     ax.axhline(0, alpha=0.5, color=\"k\", linestyle=\"--\")          xmin, xmax = ax.get_xlim()     ymin, ymax = ax.get_ylim()          # Add text labels for each quadrant     ax.text(xmax - offset, ymax - offset, \"HH\", fontsize=25, c=\"r\")     ax.text(xmax - offset, ymin + offset, \"HL\", fontsize=25, c=\"r\")     ax.text(xmin + offset, ymax - offset, \"LH\", fontsize=25, c=\"r\")     ax.text(xmin + offset, ymin + offset, \"LL\", fontsize=25, c=\"r\")      return ax  # Let's first compute the spatial lags stromalnuclei[\"immune_index_lag\"] = lag_spatial(w, stromalnuclei[\"immune_index_normed\"].values)   # Set up the figure and axis f, ax = plt.subplots(1, figsize=(6, 6)) ax = plot_moran(ax, \"immune_index_normed\", \"immune_index_lag\", offset=0.7) ax.set_title(\"Moran Plot Local\", fontsize=20) Out[11]: <pre>Text(0.5, 1.0, 'Moran Plot Local')</pre> <p>Quite hard to get the text labels to fit in to the quadrants but you get the picture... These quadrants can be used to classify the nuclei residing in the stroma into four classes: HH-immune-index, LL-immune-index, HL-immune-index, and LH-immune-index. This will be done next with the help of the <code>esda</code> package.</p> In\u00a0[12]: Copied! <pre># !pip install esda\n</pre> # !pip install esda In\u00a0[13]: Copied! <pre>import esda\nimport numpy as np\nimport warnings\n\n# suppress couple annoying warnings\nwarnings.filterwarnings('ignore')\n\n# This is borrowed from:\n# https://github.com/pysal/splot/blob/main/splot/_viz_utils.py\ndef moran_hot_cold_spots(moran_loc, p=0.05):\n    sig = 1 * (moran_loc.p_sim &lt; p)\n    HH = 1 * (sig * moran_loc.q == 1)\n    LL = 3 * (sig * moran_loc.q == 3)\n    LH = 2 * (sig * moran_loc.q == 2)\n    HL = 4 * (sig * moran_loc.q == 4)\n    cluster = HH + LL + LH + HL\n    return cluster\n\n\nlisa = esda.Moran_Local(\n    stromalnuclei[\"immune_index_normed\"], w, island_weight=np.nan\n)\n\n# Let's classify the cells to HH, LL, LH, HL based on their immune_frac/cnt props\nclusters = moran_hot_cold_spots(lisa)\n\ncluster_labels = [\"ns\", \"HH\", \"LH\", \"LL\", \"HL\"]\nlabels = [cluster_labels[i] for i in clusters]\n\nstromalnuclei[\"immune_index_labels\"] = labels\nstromalnuclei\n</pre> import esda import numpy as np import warnings  # suppress couple annoying warnings warnings.filterwarnings('ignore')  # This is borrowed from: # https://github.com/pysal/splot/blob/main/splot/_viz_utils.py def moran_hot_cold_spots(moran_loc, p=0.05):     sig = 1 * (moran_loc.p_sim &lt; p)     HH = 1 * (sig * moran_loc.q == 1)     LL = 3 * (sig * moran_loc.q == 3)     LH = 2 * (sig * moran_loc.q == 2)     HL = 4 * (sig * moran_loc.q == 4)     cluster = HH + LL + LH + HL     return cluster   lisa = esda.Moran_Local(     stromalnuclei[\"immune_index_normed\"], w, island_weight=np.nan )  # Let's classify the cells to HH, LL, LH, HL based on their immune_frac/cnt props clusters = moran_hot_cold_spots(lisa)  cluster_labels = [\"ns\", \"HH\", \"LH\", \"LL\", \"HL\"] labels = [cluster_labels[i] for i in clusters]  stromalnuclei[\"immune_index_labels\"] = labels stromalnuclei Out[13]: geometry class_name uid nhood nhood_classes immune_cnt immune_frac immune_index immune_index_normed immune_index_lag immune_index_labels uid 0 POLYGON ((6726.00000 103493.02000, 6724.01000 ... neoplastic 0 [0, 1, 2, 3] [neoplastic, connective, connective, connective] 0.0 0.000000 0.000000 -1.550176 -1.550176 LL 1 POLYGON ((6755.01000 103504.01000, 6755.01000 ... connective 1 [1, 0, 2, 3, 4] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 -1.550176 -1.550176 LL 2 POLYGON ((6823.99000 103510.01000, 6823.00000 ... connective 2 [2, 0, 1, 3, 4, 5, 6, 7] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 -1.550176 -1.550176 LL 3 POLYGON ((6760.00000 103443.02000, 6758.01000 ... connective 3 [3, 0, 1, 2, 8] [connective, neoplastic, connective, connectiv... 0.0 0.000000 0.000000 -1.550176 -1.550176 LL 4 POLYGON ((6848.01000 103481.02000, 6845.01000 ... connective 4 [4, 1, 2, 5, 6, 7, 8] [connective, connective, connective, connectiv... 0.0 0.000000 0.000000 -1.550176 -1.550176 LL ... ... ... ... ... ... ... ... ... ... ... ... 45605 POLYGON ((7217.01000 106533.02000, 7215.01000 ... neoplastic 45605 [45605, 45602, 45604, 45607, 45608, 45609] [neoplastic, neoplastic, neoplastic, neoplasti... 1.0 0.166667 0.166667 -1.383510 -1.390176 LL 45606 POLYGON ((7390.00000 106510.02000, 7387.01000 ... neoplastic 45606 [45606, 45601, 45602, 45603] [neoplastic, inflammatory, neoplastic, neoplas... 1.0 0.250000 0.250000 -1.300176 -1.355732 ns 45607 POLYGON ((7133.75000 106514.00000, 7129.01000 ... neoplastic 45607 [45607, 45604, 45605, 45608, 45609] [neoplastic, neoplastic, neoplastic, inflammat... 1.0 0.200000 0.200000 -1.350176 -1.358510 ns 45608 POLYGON ((7130.01000 106557.02000, 7129.01000 ... inflammatory 45608 [45608, 45604, 45605, 45607, 45609] [inflammatory, neoplastic, neoplastic, neoplas... 1.0 0.200000 0.200000 -1.350176 -1.358510 ns 45609 POLYGON ((7168.01000 106550.02000, 7168.01000 ... neoplastic 45609 [45609, 45604, 45605, 45607, 45608] [neoplastic, neoplastic, neoplastic, neoplasti... 1.0 0.200000 0.200000 -1.350176 -1.358510 ns <p>45610 rows \u00d7 11 columns</p> In\u00a0[14]: Copied! <pre>from matplotlib import colors\n\ncolors5= {\n    \"HH\": \"red\",\n    \"LH\": \"green\",\n    \"LL\": \"blue\",\n    \"HL\": \"yellow\",\n    \"ns\": \"black\",\n}\ncolormap = [colors5[i] for i in np.unique(labels)] \n\nhmap = colors.ListedColormap(colormap)\n\nax = tissues.plot(\n    figsize=(10, 15),\n    column=\"class_name\",\n    alpha=0.1,\n    legend=True,\n    aspect=None,\n)\n\n# add legend artist so it does not get overwritten\nleg1 = ax.legend_\nax.add_artist(leg1)\n\nax = stromalnuclei.plot(\n    ax=ax,\n    column=\"immune_index_labels\",\n    categorical=True,\n    legend=True,\n    aspect=None,\n    cmap=hmap,\n    legend_kwds={\"loc\": \"center left\", \"bbox_to_anchor\": (0.7, 0.95)},\n)\nax.set_title(\"Immune Index Labels in Cells Within Stroma\")\nax.set_axis_off()\n</pre> from matplotlib import colors  colors5= {     \"HH\": \"red\",     \"LH\": \"green\",     \"LL\": \"blue\",     \"HL\": \"yellow\",     \"ns\": \"black\", } colormap = [colors5[i] for i in np.unique(labels)]   hmap = colors.ListedColormap(colormap)  ax = tissues.plot(     figsize=(10, 15),     column=\"class_name\",     alpha=0.1,     legend=True,     aspect=None, )  # add legend artist so it does not get overwritten leg1 = ax.legend_ ax.add_artist(leg1)  ax = stromalnuclei.plot(     ax=ax,     column=\"immune_index_labels\",     categorical=True,     legend=True,     aspect=None,     cmap=hmap,     legend_kwds={\"loc\": \"center left\", \"bbox_to_anchor\": (0.7, 0.95)}, ) ax.set_title(\"Immune Index Labels in Cells Within Stroma\") ax.set_axis_off() <p>We can fairly confidently say that the red cells in the plot are statistically significant hotspots of cells surrounded by immune cells i.e. immune clusters. The blue cells, on the other hand, are statistically significant coldspots of cells with no immune cells in the surroundings.</p> In\u00a0[15]: Copied! <pre># Filter out the cells that are inflammatory and have HH an LL immune index label.\nhhll_immune = stromalnuclei.loc[\n    (stromalnuclei[\"class_name\"] == \"inflammatory\") &amp; \n    (stromalnuclei[\"immune_index_labels\"].isin([\"HH\", \"LL\"]))\n]\n\n\n# Let's look at the proportion of HH and LL cells in the stroma.\n(\n    hhll_immune[\"immune_index_labels\"].value_counts(),\n    hhll_immune[\"immune_index_labels\"].value_counts(normalize=True)\n)\n</pre> # Filter out the cells that are inflammatory and have HH an LL immune index label. hhll_immune = stromalnuclei.loc[     (stromalnuclei[\"class_name\"] == \"inflammatory\") &amp;      (stromalnuclei[\"immune_index_labels\"].isin([\"HH\", \"LL\"])) ]   # Let's look at the proportion of HH and LL cells in the stroma. (     hhll_immune[\"immune_index_labels\"].value_counts(),     hhll_immune[\"immune_index_labels\"].value_counts(normalize=True) ) Out[15]: <pre>(immune_index_labels\n HH    4628\n LL     896\n Name: count, dtype: int64,\n immune_index_labels\n HH    0.837799\n LL    0.162201\n Name: proportion, dtype: float64)</pre> <p>We can see that the groups aren't very balanced in terms of the number of cells. Over 84 percent of all the immune cells in the stroma have a tendency to cluster together. This alone indicates that the immune cells in this sample are very clustered.</p> In\u00a0[16]: Copied! <pre>import pandas as pd\n\n# Helper function to get the distances of the cells to a given tissue class\ndef get_distances_to_tissue(nuclei, tissues, tissue_class):\n    tissue = tissues.loc[tissues[\"class_name\"] == tissue_class]\n    \n    distances = {}\n    for i, poly in tissue.reset_index().iterrows():\n        dist = nuclei.distance(poly.geometry)\n        distances[i] = dist\n\n    min_dists = pd.DataFrame(distances).min(axis=1)\n    min_dists.name = f\"min_dist_{tissue_class}\"\n\n    return nuclei.join(other=min_dists, how=\"left\")\n\nhhll_immune = get_distances_to_tissue(hhll_immune, tissues, \"area_cin\")\nhhll_immune\n</pre> import pandas as pd  # Helper function to get the distances of the cells to a given tissue class def get_distances_to_tissue(nuclei, tissues, tissue_class):     tissue = tissues.loc[tissues[\"class_name\"] == tissue_class]          distances = {}     for i, poly in tissue.reset_index().iterrows():         dist = nuclei.distance(poly.geometry)         distances[i] = dist      min_dists = pd.DataFrame(distances).min(axis=1)     min_dists.name = f\"min_dist_{tissue_class}\"      return nuclei.join(other=min_dists, how=\"left\")  hhll_immune = get_distances_to_tissue(hhll_immune, tissues, \"area_cin\") hhll_immune Out[16]: geometry class_name uid nhood nhood_classes immune_cnt immune_frac immune_index immune_index_normed immune_index_lag immune_index_labels min_dist_area_cin uid 21 POLYGON ((7582.01000 98745.02000, 7581.01000 9... inflammatory 21 [21, 9, 10, 12, 13, 15, 18, 19, 20, 23, 24] [inflammatory, connective, neoplastic, connect... 2.0 0.181818 0.363636 -1.186540 -1.084671 LL 57.938920 25 POLYGON ((7295.00000 105945.02000, 7292.01000 ... inflammatory 25 [25, 40, 44, 45, 50, 51, 53] [inflammatory, connective, connective, connect... 1.0 0.142857 0.142857 -1.407319 -1.372398 LL 19.958143 54 POLYGON ((6888.01000 105776.02000, 6887.01000 ... inflammatory 54 [54, 29, 31, 33, 34, 36, 48, 55] [inflammatory, neoplastic, neoplastic, neoplas... 2.0 0.250000 0.500000 -1.050176 -1.275098 LL 13.069129 87 POLYGON ((9291.01000 100582.02000, 9288.01000 ... inflammatory 87 [87, 73, 77, 82, 83, 97, 99, 101, 110, 114, 115] [inflammatory, connective, connective, connect... 6.0 0.545455 3.272727 1.722551 1.735480 HH 904.382513 92 POLYGON ((9255.00000 100714.02000, 9248.01000 ... inflammatory 92 [92, 80, 81, 82, 90, 94, 95, 96, 97, 98, 100, ... [inflammatory, connective, connective, connect... 7.0 0.583333 4.083333 2.533157 1.662764 HH 793.457037 ... ... ... ... ... ... ... ... ... ... ... ... ... 45580 POLYGON ((14531.01000 95263.02000, 14529.01000... inflammatory 45580 [45580, 45495, 45538, 45542, 45555, 45561, 455... [inflammatory, inflammatory, connective, infla... 10.0 0.526316 5.263158 3.712982 2.244790 HH 6822.508018 45581 POLYGON ((14198.01000 95238.02000, 14197.01000... inflammatory 45581 [45581, 45529, 45540, 45554, 45557, 45583, 455... [inflammatory, connective, connective, connect... 1.0 0.125000 0.125000 -1.425176 -1.384647 LL 6521.387985 45590 POLYGON ((14601.01000 95256.02000, 14599.01000... inflammatory 45590 [45590, 45499, 45538, 45542, 45546, 45549, 455... [inflammatory, connective, connective, inflamm... 8.0 0.400000 3.200000 1.649824 1.627255 HH 6890.367988 45597 POLYGON ((14499.01000 95255.02000, 14498.01000... inflammatory 45597 [45597, 45495, 45505, 45538, 45542, 45555, 455... [inflammatory, inflammatory, connective, conne... 8.0 0.421053 3.368421 1.818245 2.618629 HH 6796.483901 45600 POLYGON ((14530.00000 95214.02000, 14528.01000... inflammatory 45600 [45600, 45495, 45499, 45505, 45519, 45532, 455... [inflammatory, inflammatory, connective, conne... 9.0 0.500000 4.500000 2.949824 2.872921 HH 6838.221223 <p>5524 rows \u00d7 12 columns</p> <p>Let's visualize the distance distributions.</p> In\u00a0[17]: Copied! <pre># Let's tidy up the data first\ntidy = hhll_immune.reset_index(drop=True).set_index(\"immune_index_labels\")\ntidy = tidy[[\"min_dist_area_cin\"]]\ntidy = tidy.stack()\ntidy = tidy.reset_index()\ntidy = tidy.rename(\n    columns={\n        \"immune_index_labels\": \"Immune Index Cells\",\n        \"level_1\": \"Attribute\",\n        0: \"Distance to Lesion\"\n    }\n)\ntidy\n</pre> # Let's tidy up the data first tidy = hhll_immune.reset_index(drop=True).set_index(\"immune_index_labels\") tidy = tidy[[\"min_dist_area_cin\"]] tidy = tidy.stack() tidy = tidy.reset_index() tidy = tidy.rename(     columns={         \"immune_index_labels\": \"Immune Index Cells\",         \"level_1\": \"Attribute\",         0: \"Distance to Lesion\"     } ) tidy Out[17]: Immune Index Cells Attribute Distance to Lesion 0 LL min_dist_area_cin 57.938920 1 LL min_dist_area_cin 19.958143 2 LL min_dist_area_cin 13.069129 3 HH min_dist_area_cin 904.382513 4 HH min_dist_area_cin 793.457037 ... ... ... ... 5519 HH min_dist_area_cin 6822.508018 5520 LL min_dist_area_cin 6521.387985 5521 HH min_dist_area_cin 6890.367988 5522 HH min_dist_area_cin 6796.483901 5523 HH min_dist_area_cin 6838.221223 <p>5524 rows \u00d7 3 columns</p> In\u00a0[18]: Copied! <pre>ax = sns.swarmplot(\n    data=tidy,\n    y=\"Distance to Lesion\",\n    x=\"Immune Index Cells\",\n    hue=\"Immune Index Cells\",\n    size=1.5,\n    orient=\"v\",\n    legend=False,\n    warn_thresh=0.5,\n)\nax.set_title(\"Distance of HH and LL Inflammatory Cells to Lesion\")\n</pre> ax = sns.swarmplot(     data=tidy,     y=\"Distance to Lesion\",     x=\"Immune Index Cells\",     hue=\"Immune Index Cells\",     size=1.5,     orient=\"v\",     legend=False,     warn_thresh=0.5, ) ax.set_title(\"Distance of HH and LL Inflammatory Cells to Lesion\") Out[18]: <pre>Text(0.5, 1.0, 'Distance of HH and LL Inflammatory Cells to Lesion')</pre> <p>From the plot above we can see that the LL-immune-index cells have more evenly distributed distances to lesion than the HH cells. This indicates that the HH cells tend to cluster closer to the lesion</p> <p>Let's do a t-test on two independent samples to see if the difference in the mean distances is statistically significant. We'll use the <code>scipy.stats.ttest_ind</code> function for this.</p> In\u00a0[19]: Copied! <pre>from scipy.stats import ttest_ind\n\n# Filter the immune hh and ll cells\nimmune_hot = hhll_immune.loc[hhll_immune[\"immune_index_labels\"] == \"HH\"]\nimmune_cold = hhll_immune.loc[hhll_immune[\"immune_index_labels\"] == \"LL\"]\n\n# standardize the distances\nimmune_hot[\"min_dist_area_cin\"] = (\n    immune_hot[\"min_dist_area_cin\"] / immune_hot[\"min_dist_area_cin\"].mean()\n) / immune_hot[\"min_dist_area_cin\"].std()\nimmune_cold[\"min_dist_area_cin\"] = (\n    immune_cold[\"min_dist_area_cin\"] / immune_cold[\"min_dist_area_cin\"].mean()\n) / immune_cold[\"min_dist_area_cin\"].std()\n\n# Get the distances for immune hot and cold hexes\ndist_hot = immune_hot[\"min_dist_area_cin\"]\ndist_cold = immune_cold[\"min_dist_area_cin\"]\n\n# Perform the t-test test\nstatistic, p_value = ttest_ind(dist_hot, dist_cold)\n\n# Print the results\nif p_value &lt; 0.05:\n    print(\"The HH cells are significantly closer to the lesion than the LL cells.\")\nelse:\n    print(\"There is no significant difference in distance between the LL and HH cells.\")\n\nprint(\"p-value: \", p_value)\n</pre> from scipy.stats import ttest_ind  # Filter the immune hh and ll cells immune_hot = hhll_immune.loc[hhll_immune[\"immune_index_labels\"] == \"HH\"] immune_cold = hhll_immune.loc[hhll_immune[\"immune_index_labels\"] == \"LL\"]  # standardize the distances immune_hot[\"min_dist_area_cin\"] = (     immune_hot[\"min_dist_area_cin\"] / immune_hot[\"min_dist_area_cin\"].mean() ) / immune_hot[\"min_dist_area_cin\"].std() immune_cold[\"min_dist_area_cin\"] = (     immune_cold[\"min_dist_area_cin\"] / immune_cold[\"min_dist_area_cin\"].mean() ) / immune_cold[\"min_dist_area_cin\"].std()  # Get the distances for immune hot and cold hexes dist_hot = immune_hot[\"min_dist_area_cin\"] dist_cold = immune_cold[\"min_dist_area_cin\"]  # Perform the t-test test statistic, p_value = ttest_ind(dist_hot, dist_cold)  # Print the results if p_value &lt; 0.05:     print(\"The HH cells are significantly closer to the lesion than the LL cells.\") else:     print(\"There is no significant difference in distance between the LL and HH cells.\")  print(\"p-value: \", p_value) <pre>The HH cells are significantly closer to the lesion than the LL cells.\np-value:  6.796636548380461e-14\n</pre> <p>Let's plot the standardized distance distributions of the HH and LL cells.</p> In\u00a0[20]: Copied! <pre>ax = sns.kdeplot(\n    immune_hot[\"min_dist_area_cin\"],\n    label=\"HH\",\n    shade=True,\n    color=\"pink\"\n)\nax = sns.kdeplot(\n    immune_cold[\"min_dist_area_cin\"],\n    label=\"LL\",\n    shade=True,\n    color=\"lightblue\",\n    ax=ax\n)\nax.axvline(\n    immune_cold[\"min_dist_area_cin\"].mean(),\n    color=\"b\",\n    linestyle=\"--\",\n    alpha=0.5\n)\nax.axvline(\n    immune_hot[\"min_dist_area_cin\"].mean(),\n    color=\"r\",\n    linestyle=\"--\",\n    alpha=0.5\n)\n\nax.set_title(\"HH (Red), LL (Blue), Distance to Lesion with Means (Dashed)\")\nax\n</pre> ax = sns.kdeplot(     immune_hot[\"min_dist_area_cin\"],     label=\"HH\",     shade=True,     color=\"pink\" ) ax = sns.kdeplot(     immune_cold[\"min_dist_area_cin\"],     label=\"LL\",     shade=True,     color=\"lightblue\",     ax=ax ) ax.axvline(     immune_cold[\"min_dist_area_cin\"].mean(),     color=\"b\",     linestyle=\"--\",     alpha=0.5 ) ax.axvline(     immune_hot[\"min_dist_area_cin\"].mean(),     color=\"r\",     linestyle=\"--\",     alpha=0.5 )  ax.set_title(\"HH (Red), LL (Blue), Distance to Lesion with Means (Dashed)\") ax Out[20]: <pre>&lt;Axes: title={'center': 'HH (Red), LL (Blue), Distance to Lesion with Means (Dashed)'}, xlabel='min_dist_area_cin', ylabel='Density'&gt;</pre> <p>From these analyses, it is fair to say that the immune cells in the HH clusters are more likely to be closer to the lesion than the immune cells in the LL clusters. This is a very interesting finding since it indicates that the immune cells in the HH clusters are more likely to be in the vicinity of the lesion and thus more likely to be in the vicinity of the cancer cells.</p> In\u00a0[21]: Copied! <pre>hh_immune = hhll_immune.loc[hhll_immune[\"immune_index_labels\"] == \"HH\"]\nhh_immune = get_distances_to_tissue(hh_immune, tissues, \"areasquam\")\nhh_immune = get_distances_to_tissue(hh_immune, tissues, \"areagland\")\nhh_immune\n</pre> hh_immune = hhll_immune.loc[hhll_immune[\"immune_index_labels\"] == \"HH\"] hh_immune = get_distances_to_tissue(hh_immune, tissues, \"areasquam\") hh_immune = get_distances_to_tissue(hh_immune, tissues, \"areagland\") hh_immune Out[21]: geometry class_name uid nhood nhood_classes immune_cnt immune_frac immune_index immune_index_normed immune_index_lag immune_index_labels min_dist_area_cin min_dist_areasquam min_dist_areagland uid 87 POLYGON ((9291.01000 100582.02000, 9288.01000 ... inflammatory 87 [87, 73, 77, 82, 83, 97, 99, 101, 110, 114, 115] [inflammatory, connective, connective, connect... 6.0 0.545455 3.272727 1.722551 1.735480 HH 904.382513 5565.533920 16.098727 92 POLYGON ((9255.00000 100714.02000, 9248.01000 ... inflammatory 92 [92, 80, 81, 82, 90, 94, 95, 96, 97, 98, 100, ... [inflammatory, connective, connective, connect... 7.0 0.583333 4.083333 2.533157 1.662764 HH 793.457037 5699.122822 43.310743 94 POLYGON ((9293.01000 100711.02000, 9291.01000 ... inflammatory 94 [94, 74, 80, 81, 82, 90, 92, 95, 100, 105, 106... [inflammatory, connective, connective, connect... 5.0 0.384615 1.923077 0.372901 1.725660 HH 833.468542 5677.527121 53.255238 95 POLYGON ((9310.00000 100685.02000, 9307.01000 ... inflammatory 95 [95, 74, 80, 81, 82, 92, 94, 100, 102, 105, 10... [inflammatory, connective, connective, connect... 6.0 0.428571 2.571429 1.021252 1.471052 HH 860.662565 5647.113536 80.326462 99 POLYGON ((9230.01000 100579.02000, 9229.01000 ... inflammatory 99 [99, 77, 82, 83, 87, 97, 101, 110, 115] [inflammatory, connective, connective, inflamm... 5.0 0.555556 2.777778 1.227602 2.022172 HH 877.060665 5588.749607 10.020000 ... ... ... ... ... ... ... ... ... ... ... ... ... ... ... 45572 POLYGON ((14445.01000 95259.02000, 14444.01000... inflammatory 45572 [45572, 45505, 45525, 45542, 45548, 45555, 455... [inflammatory, connective, inflammatory, infla... 9.0 0.473684 4.263158 2.712982 1.865569 HH 6742.895678 399.331642 243.050000 45580 POLYGON ((14531.01000 95263.02000, 14529.01000... inflammatory 45580 [45580, 45495, 45538, 45542, 45555, 45561, 455... [inflammatory, inflammatory, connective, infla... 10.0 0.526316 5.263158 3.712982 2.244790 HH 6822.508018 484.494815 252.985907 45590 POLYGON ((14601.01000 95256.02000, 14599.01000... inflammatory 45590 [45590, 45499, 45538, 45542, 45546, 45549, 455... [inflammatory, connective, connective, inflamm... 8.0 0.400000 3.200000 1.649824 1.627255 HH 6890.367988 553.539773 198.006415 45597 POLYGON ((14499.01000 95255.02000, 14498.01000... inflammatory 45597 [45597, 45495, 45505, 45538, 45542, 45555, 455... [inflammatory, inflammatory, connective, conne... 8.0 0.421053 3.368421 1.818245 2.618629 HH 6796.483901 452.698929 258.142094 45600 POLYGON ((14530.00000 95214.02000, 14528.01000... inflammatory 45600 [45600, 45495, 45499, 45505, 45519, 45532, 455... [inflammatory, inflammatory, connective, conne... 9.0 0.500000 4.500000 2.949824 2.872921 HH 6838.221223 480.040000 221.423658 <p>4628 rows \u00d7 14 columns</p> In\u00a0[22]: Copied! <pre># get the closest tissue class\nhh_immune[\"closest_tissue\"] = hh_immune[\n    [\"min_dist_area_cin\", \"min_dist_areasquam\", \"min_dist_areagland\"]\n].idxmin(axis=1).str.replace(\"min_dist_\", \"closest_to_\")\n\n# get the distance to the closest tissue class\nhh_immune[\"min_dist_to_tissue\"] = hh_immune[\n    [\"min_dist_area_cin\", \"min_dist_areasquam\", \"min_dist_areagland\"]\n].min(axis=1)\n\n(\n    hh_immune[\"closest_tissue\"].value_counts(),\n    hh_immune[\"closest_tissue\"].value_counts(normalize=True)\n)\n</pre> # get the closest tissue class hh_immune[\"closest_tissue\"] = hh_immune[     [\"min_dist_area_cin\", \"min_dist_areasquam\", \"min_dist_areagland\"] ].idxmin(axis=1).str.replace(\"min_dist_\", \"closest_to_\")  # get the distance to the closest tissue class hh_immune[\"min_dist_to_tissue\"] = hh_immune[     [\"min_dist_area_cin\", \"min_dist_areasquam\", \"min_dist_areagland\"] ].min(axis=1)  (     hh_immune[\"closest_tissue\"].value_counts(),     hh_immune[\"closest_tissue\"].value_counts(normalize=True) ) Out[22]: <pre>(closest_tissue\n closest_to_areagland    3007\n closest_to_area_cin     1216\n closest_to_areasquam     405\n Name: count, dtype: int64,\n closest_tissue\n closest_to_areagland    0.649741\n closest_to_area_cin     0.262748\n closest_to_areasquam    0.087511\n Name: proportion, dtype: float64)</pre> <p>From the above results we can see the proportion of HH cells to different epithelial tissues. We can see that the majority of the HH cells are actually closer to the glandular epithelium than the lesion. Glands in cervical tissue are often sources of immune cells so it is natural that most of the immune cells are closer to the glands than the lesion.</p> <p>Let's next plot the distributions of the distances of the HH cells to these tissues.</p> In\u00a0[23]: Copied! <pre># Let's tidy up the data first\ntidy = hh_immune.reset_index(drop=True).set_index(\"closest_tissue\")\ntidy = tidy[[\"min_dist_to_tissue\"]]\ntidy = tidy.stack()\ntidy = tidy.reset_index()\ntidy = tidy.rename(\n    columns={\n        \"closest_tissue\": \"Closest Tissue\",\n        \"level_1\": \"Attribute\",\n        0: \"Distance to Tissue\"\n    }\n)\ntidy\n</pre> # Let's tidy up the data first tidy = hh_immune.reset_index(drop=True).set_index(\"closest_tissue\") tidy = tidy[[\"min_dist_to_tissue\"]] tidy = tidy.stack() tidy = tidy.reset_index() tidy = tidy.rename(     columns={         \"closest_tissue\": \"Closest Tissue\",         \"level_1\": \"Attribute\",         0: \"Distance to Tissue\"     } ) tidy Out[23]: Closest Tissue Attribute Distance to Tissue 0 closest_to_areagland min_dist_to_tissue 16.098727 1 closest_to_areagland min_dist_to_tissue 43.310743 2 closest_to_areagland min_dist_to_tissue 53.255238 3 closest_to_areagland min_dist_to_tissue 80.326462 4 closest_to_areagland min_dist_to_tissue 10.020000 ... ... ... ... 4623 closest_to_areagland min_dist_to_tissue 243.050000 4624 closest_to_areagland min_dist_to_tissue 252.985907 4625 closest_to_areagland min_dist_to_tissue 198.006415 4626 closest_to_areagland min_dist_to_tissue 258.142094 4627 closest_to_areagland min_dist_to_tissue 221.423658 <p>4628 rows \u00d7 3 columns</p> In\u00a0[24]: Copied! <pre>fig, ax = plt.subplots(1, 2, figsize=(14, 6))\n\nsns.swarmplot(\n    ax=ax[0],\n    data=tidy,\n    y=\"Distance to Tissue\",\n    x=\"Closest Tissue\",\n    hue=\"Closest Tissue\",\n    size=1.5,\n    orient=\"v\",\n    legend=False,\n    warn_thresh=0.5,\n)\n\nsns.kdeplot(\n    ax=ax[1],\n    data=tidy,\n    x=\"Distance to Tissue\",\n    hue=\"Closest Tissue\",\n    fill=True,\n    alpha=0.5,\n)\n\nax[0].set_title(\"Swarm - Distance to Closest Tissue\")\nax[1].set_title(\"KDE - Distance to Closest Tissue\")\n</pre> fig, ax = plt.subplots(1, 2, figsize=(14, 6))  sns.swarmplot(     ax=ax[0],     data=tidy,     y=\"Distance to Tissue\",     x=\"Closest Tissue\",     hue=\"Closest Tissue\",     size=1.5,     orient=\"v\",     legend=False,     warn_thresh=0.5, )  sns.kdeplot(     ax=ax[1],     data=tidy,     x=\"Distance to Tissue\",     hue=\"Closest Tissue\",     fill=True,     alpha=0.5, )  ax[0].set_title(\"Swarm - Distance to Closest Tissue\") ax[1].set_title(\"KDE - Distance to Closest Tissue\") Out[24]: <pre>Text(0.5, 1.0, 'KDE - Distance to Closest Tissue')</pre> <p>Let's plot how the HH immune cells are distributed in the tissue and color them based on the <code>closest_tissue</code> variable.</p> In\u00a0[25]: Copied! <pre>from matplotlib import colors\n\npal = sns.color_palette(\"tab10\").as_hex()\n\ncolors5= {\n    \"closest_to_areagland\": pal[0],\n    \"closest_to_areasquam\": pal[1],\n    \"closest_to_area_cin\": pal[2],\n}\ncolormap = [colors5[i] for i in np.unique(hh_immune[\"closest_tissue\"])] \n\nhmap = colors.ListedColormap(colormap)\n\nax = tissues.plot(\n    figsize=(10, 15),\n    column=\"class_name\",\n    alpha=0.1,\n    legend=True,\n    aspect=None,\n)\n\n# add legend artist so it does not get overwritten\nleg1 = ax.legend_\nax.add_artist(leg1)\n\nax = hh_immune.plot(\n    ax=ax,\n    column=\"closest_tissue\",\n    categorical=True,\n    legend=True,\n    aspect=None,\n    cmap=hmap,\n    legend_kwds={\"loc\": \"center left\", \"bbox_to_anchor\": (0.55, 0.965)},\n)\n\nax.set_title(\"HH Immune Cells Colored by Closest Tissue\")\nax.set_axis_off()\n</pre> from matplotlib import colors  pal = sns.color_palette(\"tab10\").as_hex()  colors5= {     \"closest_to_areagland\": pal[0],     \"closest_to_areasquam\": pal[1],     \"closest_to_area_cin\": pal[2], } colormap = [colors5[i] for i in np.unique(hh_immune[\"closest_tissue\"])]   hmap = colors.ListedColormap(colormap)  ax = tissues.plot(     figsize=(10, 15),     column=\"class_name\",     alpha=0.1,     legend=True,     aspect=None, )  # add legend artist so it does not get overwritten leg1 = ax.legend_ ax.add_artist(leg1)  ax = hh_immune.plot(     ax=ax,     column=\"closest_tissue\",     categorical=True,     legend=True,     aspect=None,     cmap=hmap,     legend_kwds={\"loc\": \"center left\", \"bbox_to_anchor\": (0.55, 0.965)}, )  ax.set_title(\"HH Immune Cells Colored by Closest Tissue\") ax.set_axis_off() <p>From the reuslts above it's quite clear that not all of the HH immune cells in the tissue reside in the vicinity of the lesion. In fact, the majority of the HH immune cells are in the vicinity of the glandular epithelium. This should be taken into account too when interpreting the results of the local autocorrelation analysis.</p>"},{"location":"user_guide/local_spatial_autocorrelation/#local-spatial-autocorrelation","title":"Local Spatial Autocorrelation\u00b6","text":"<p>Local spatial autocorrelation is a way to measure the degree of clustering or dispersion of a variable in a map. It is a local measure of spatial autocorrelation and it gives us more resolution than global spatial autocorrelation. It can be used 'as way to identify statistically meaningful local hot and cold spots spots of a variable in a segmentation map.</p> <p>In this notebook, we will again be borrowing a lot from the great geographic datascience book by Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf. It is a great resource for learning about spatial data science and although it is focused on the analysis of geographical maps, the analysis can be applied to any kind of segmentation maps as well.</p> <p>Global measures of spatial autocorrelation are \u201cwhole map\u201d statistics. They provide a single summary for an entire data set. For example, Moran\u2019s is a good tool to summarize a dataset into a single value that captures the degree of geographical clustering (or dispersion, if negative). However, Moran\u2019s does not indicate areas within the map where specific types of values (e.g., high, low) are clustered, or instances of explicit dispersion. In other words, Moran\u2019s I can tell us whether values in our map cluster together (or disperse) overall, but it will not inform us about where specific clusters (or outliers) are. - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf</p> <p>Local measures of spatial autocorrelation focus on the relationships between each observation and its surroundings, rather than providing a single summary of these relationships across the map. In this sense, they are not summary statistics but scores that allow us to learn more about the spatial structure in our data. The general intuition behind the metrics however is similar to that of global ones. Some of them are even mathematically connected, where the global version can be decomposed into a collection of local ones. - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf</p> <p>We will again be looking at the immune cell index that we coined in the Global Autocorrelation example but this time we will be looking at the local spatial autocorrelation of this variable through the local Moran's I satistic. We will be using the same data as in the global autocorrelation notebook so this example starts identically until we will start computing the local autocorrelations.</p>"},{"location":"user_guide/local_spatial_autocorrelation/#the-data","title":"The Data\u00b6","text":"<p>We will be using the same data as in the previous Global Autocorrelation example. The data is a cervical pre-cancerous biopsy and it is not publicly available, so this serves only as a demonstration of the functionality of <code>cellseg_gsontools</code>.</p>"},{"location":"user_guide/local_spatial_autocorrelation/#filtering-the-cells-in-the-stroma","title":"Filtering the Cells in the Stroma\u00b6","text":"<p>In this example, we will be looking at the spatial autocorrelation of cells within the stroma. Thus, we will filter only the cells within the stroma from the data.</p>"},{"location":"user_guide/local_spatial_autocorrelation/#spatial-weights","title":"Spatial Weights\u00b6","text":"<p>Next, we will fit a contiguity grpah on the cells, to extract the neighborhoods of each cell. We will use the <code>distband</code> contiguity graph, that connects each cell to all cells within a certain distance. We will use a distance of 50 microns (100 pixels since the segmentation was run done 20x magnification).</p>"},{"location":"user_guide/local_spatial_autocorrelation/#neighborhood-immune-index","title":"Neighborhood Immune Index.\u00b6","text":"<p>Like in the Global autocorrelation example, we will again compute the count and fraction of the immune cells in each cell neighborhood and use these features to calculate the immune index (immune fraction $\\times$ immune count). The reason here to use the immune index is the same as last time: immune fraction would give high values for small neihgborhoods with 1/1 or 2/2 immune cells which.</p>"},{"location":"user_guide/local_spatial_autocorrelation/#spatial-lag-and-the-morans-plot","title":"Spatial Lag and the Moran's Plot\u00b6","text":"<p>Like in the Global autocorrelation example, we will again compute the spatial lag here explicitly so that we can plot the Moran plot. Only this time, we will divide the plot in to quadrants. By doing this, we can divide cells in four groups based on their immune index variable. The quadrants meanings are: The cells at hand that have mostly immune cells as neighbors (high immune cell index) while the neighboring cells being the same i.e. also having neighbors that have high immune index (positive normalized values in Moran's plot). The second quadrant is the opposite: Cells that have few to none immune cells as neighbors (below-average immune index) while their neighbors also have low immune cell index (negative normalized values). Then the other two quadrants are those cells that have high immune index but their neighbors don't and vice versa. These four quadrants are named followingly: high-high (HH) (the top-right in Moran's plot), low-high (LH) (the top-left in Moran's plot), low-low (LL) (the bottom-left in Moran's plot), and high-low (HL) (the bottom-right in Moran's plot).</p>"},{"location":"user_guide/local_spatial_autocorrelation/#local-morans-i","title":"Local Moran's I\u00b6","text":"<p>Next we will compute the local Moran's I statistics for each observation of immune index in our data.</p> <p>\"The core idea of a local Moran\u2019s is to identify cases in which the value of an observation and the average of its surroundings is either more similar i.e. high-high or low-low (HH or LL) or dissimilar high-low or low-high (HL, LH) than we would expect from pure chance. The mechanism to do this is similar to the one in the global Moran\u2019s I, but it is applied in this case to each observation.\" - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf</p> <p>Local Moran's I uses Local Indicators of Spatial Association (LISAs).</p> <p>\"LISAs are widely used in many fields to identify geographical clusters of values or find geographical outliers. They are a useful tool that can quickly return areas in which values are concentrated and provide suggestive evidence about the processes that might be at work. For these reasons, they have a prime place in the geographic data science toolbox.\" - Sergio J. Rey, Dani Arribas-Bel, Levi J. Wolf</p> <p>LISAs can be computed with the <code>esda</code> package very easily. We will compute the LISAs for the immune index next.</p>"},{"location":"user_guide/local_spatial_autocorrelation/#tendency-of-immune-cells-to-form-clusters","title":"Tendency of Immune Cells to Form Clusters\u00b6","text":"<p>Let's now take a bit closer look on the immune cells that belong in the red (HH) clusters and blues clusters (LL). We'll take a look at the proportion of immune cells belonging in both of the clusters to see whether there is an imbalance between LL and HH cells.</p>"},{"location":"user_guide/local_spatial_autocorrelation/#distance-to-lesion","title":"Distance to Lesion\u00b6","text":"<p>Let's further analyse how these cells spatially map in the tissue, especially in relation to the pre-cancerous lesion. Specifically, we will compute the distance of each cell to the lesion and plot the distance distributions of the cells in the HH and LL clusters.</p> <p>We computed the minimum distance to the lesion in the Spatial Grids-example, so we'll do the same here. Only this time we'll do it for the HH- and LL-immune-index cells instead of hexagonal grid cells.</p>"},{"location":"user_guide/local_spatial_autocorrelation/#distance-to-other-tissues","title":"Distance to Other Tissues\u00b6","text":"<p>Now we will subset only the HH-immune-index cells and examine the distance distributions of these cells to the other tissues in the sample. We want to see what is the proportion of HH cells that are in the vicinity of the lesion and what is the proportion of HH cells that are in the vicinity of the other tissues.</p>"},{"location":"user_guide/spatial_grids/","title":"Spatial Grids","text":"In\u00a0[1]: Copied! <pre>from pathlib import Path\nfrom cellseg_gsontools import read_gdf\n\ntissue_path = Path(\"/path/to/tissues.geojson\")\nnuc_path = Path(\"/path/to/nuclei.geojson\")\n\ntissues = read_gdf(tissue_path)[[\"geometry\", \"class_name\"]] # take only relevant columns\nnuclei = read_gdf(nuc_path)[[\"geometry\", \"class_name\"]]\n\ntissues.head(5)\n</pre> from pathlib import Path from cellseg_gsontools import read_gdf  tissue_path = Path(\"/path/to/tissues.geojson\") nuc_path = Path(\"/path/to/nuclei.geojson\")  tissues = read_gdf(tissue_path)[[\"geometry\", \"class_name\"]] # take only relevant columns nuclei = read_gdf(nuc_path)[[\"geometry\", \"class_name\"]]  tissues.head(5) Out[1]: geometry class_name 0 POLYGON ((12366.89000 107883.00000, 12296.5200... areastroma 1 POLYGON ((8390.00000 117552.00000, 8388.98000 ... areastroma 2 POLYGON ((7598.00000 117284.00000, 7596.04000 ... areastroma 3 POLYGON ((7564.11000 115883.00000, 7563.15000 ... areastroma 4 POLYGON ((6473.29000 112408.03000, 6465.52000 ... areastroma In\u00a0[2]: Copied! <pre>nuclei.head(5)\n</pre> nuclei.head(5) Out[2]: geometry class_name 0 POLYGON ((6502.01000 112825.02000, 6501.01000 ... connective 1 POLYGON ((6468.01000 112605.02000, 6468.01000 ... connective 2 POLYGON ((6428.00000 112392.02000, 6424.77000 ... squamous_epithel 3 POLYGON ((6494.00000 112032.02000, 6490.00000 ... glandular_epithel 4 POLYGON ((6466.00000 112432.02000, 6464.01000 ... connective In\u00a0[3]: Copied! <pre>tissues.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None)\n</pre> tissues.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None) Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>nuclei.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None)\n</pre> nuclei.plot(figsize=(10, 15), column=\"class_name\", legend=True, aspect=None) Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[20]: Copied! <pre>from cellseg_gsontools.grid import grid_overlay\n\n# set the coordinate reference system to avoid annoying warnings\ntissues.set_crs(epsg=4328, inplace=True, allow_override=True)\n\n# fit the square grid\ngrid = grid_overlay(tissues, patch_size=(256, 256), stride=(256, 256))\n\n# plot\nax = tissues.plot(\n    figsize=(15, 15),\n    column=\"class_name\",\n    legend=True,\n    aspect=None,\n)\ngrid.boundary.plot(ax=ax, color=\"red\", linewidth=0.5)\nax.set_title(\"Square Grid Overlay\")\nax.set_axis_off()\n</pre> from cellseg_gsontools.grid import grid_overlay  # set the coordinate reference system to avoid annoying warnings tissues.set_crs(epsg=4328, inplace=True, allow_override=True)  # fit the square grid grid = grid_overlay(tissues, patch_size=(256, 256), stride=(256, 256))  # plot ax = tissues.plot(     figsize=(15, 15),     column=\"class_name\",     legend=True,     aspect=None, ) grid.boundary.plot(ax=ax, color=\"red\", linewidth=0.5) ax.set_title(\"Square Grid Overlay\") ax.set_axis_off() In\u00a0[21]: Copied! <pre>grid\n</pre> grid Out[21]: geometry index_right class_name 23 POLYGON ((11430.00000 107235.00000, 11686.0000... 14 slime 24 POLYGON ((11686.00000 107235.00000, 11942.0000... 14 slime 25 POLYGON ((11942.00000 107235.00000, 12198.0000... 14 slime 48 POLYGON ((10406.00000 107491.00000, 10662.0000... 14 slime 49 POLYGON ((10662.00000 107491.00000, 10918.0000... 14 slime ... ... ... ... 1163 POLYGON ((6310.00000 117475.00000, 6566.00000 ... 32 blood 1190 POLYGON ((5798.00000 117731.00000, 6054.00000 ... 32 blood 1191 POLYGON ((6054.00000 117731.00000, 6310.00000 ... 32 blood 1105 POLYGON ((6310.00000 116963.00000, 6566.00000 ... 20 slime 1173 POLYGON ((8870.00000 117475.00000, 9126.00000 ... 26 blood <p>801 rows \u00d7 3 columns</p> In\u00a0[22]: Copied! <pre>from cellseg_gsontools.grid import hexgrid_overlay\n\ngrid = hexgrid_overlay(tissues, resolution=10)\nax = tissues.plot(\n    figsize=(15, 15),\n    column=\"class_name\",\n    legend=True,\n    aspect=None,\n)\n\ngrid.boundary.plot(ax=ax, color=\"red\", linewidth=0.5)\nax.set_title(\"Hexagonal Grid Overlay\")\nax.set_axis_off()\n</pre> from cellseg_gsontools.grid import hexgrid_overlay  grid = hexgrid_overlay(tissues, resolution=10) ax = tissues.plot(     figsize=(15, 15),     column=\"class_name\",     legend=True,     aspect=None, )  grid.boundary.plot(ax=ax, color=\"red\", linewidth=0.5) ax.set_title(\"Hexagonal Grid Overlay\") ax.set_axis_off() In\u00a0[23]: Copied! <pre>import geopandas as gpd\nimport mapclassify\nimport matplotlib.pyplot as plt\n\nfrom cellseg_gsontools.grid import grid_classify\nfrom cellseg_gsontools.plotting import plot_all\n\n\n# helper function to replace legend items\ndef replace_legend_items(legend, mapping):\n    for txt in legend.texts:\n        for k, v in mapping.items():\n            if txt.get_text() == str(k):\n                txt.set_text(v)\n\n\n# Immune cell cnt heuristic to classify the grid cells into two classes\ndef get_immune_cell_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; int:\n    try:\n        cnt = gdf.class_name.value_counts()[\"inflammatory\"]\n    except KeyError:\n        cnt = 0\n\n    return int(cnt)\n\n\n# Count the immune cells within the grid cells with the cell cnt heuristic\ngrid = grid_classify(\n    grid=grid,\n    objs=nuclei,\n    metric_func=get_immune_cell_cnt,\n    predicate=\"intersects\",\n    new_col_names=\"immune_cnt\",\n    parallel=False,\n)\n\n# bin the grid cells into 4 quantiles\ncol = \"immune_cnt\"\nbins = mapclassify.Quantiles(grid[col], k=4)\ngrid[\"immune_density_level\"] = bins.yb\n\n# plot\nax = tissues.plot(\n    figsize=(15, 15),\n    column=\"class_name\",\n    legend=True,\n    alpha=0.5,\n    legend_kwds={\n        \"loc\": \"center left\",\n        \"bbox_to_anchor\": (0.75, 0.93)\n    }\n)\n# add the legend to artist, otherwise it will be overwritten\nleg1 = ax.legend_\nax.add_artist(leg1)\n\nax = nuclei.plot(\n    ax=ax,\n    column=\"class_name\",\n    legend=True,\n    aspect=None,\n    legend_kwds={\n        \"loc\": \"center left\",\n        \"bbox_to_anchor\": (0.75, 0.83)\n    }\n)\nleg2 = ax.legend_\nax.add_artist(leg2)\n\n# copy the grid for plotting just the boundary\ngridboundary = grid.copy()\ngridboundary.geometry = grid.geometry.boundary\nax = gridboundary.plot(\n    ax=ax,\n    column=\"immune_density_level\",\n    cmap=\"viridis\",\n    legend=True,\n    categorical=True,\n    linewidth=0.5,\n    legend_kwds={\n        \"loc\": \"center left\",\n        \"bbox_to_anchor\": (0.75, 0.73)\n    }\n)\nleg3 = ax.legend_\nax.add_artist(leg3)\n\nmapping = dict([(i, s) for i, s in enumerate(bins.get_legend_classes())])\nreplace_legend_items(ax.get_legend(), mapping)\n\nax.set_title(\"Hex Grid Overlay with Immune Cell Density Levels\")\nax.set_axis_off()\nplt.subplots_adjust(right=0.7)\n</pre> import geopandas as gpd import mapclassify import matplotlib.pyplot as plt  from cellseg_gsontools.grid import grid_classify from cellseg_gsontools.plotting import plot_all   # helper function to replace legend items def replace_legend_items(legend, mapping):     for txt in legend.texts:         for k, v in mapping.items():             if txt.get_text() == str(k):                 txt.set_text(v)   # Immune cell cnt heuristic to classify the grid cells into two classes def get_immune_cell_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; int:     try:         cnt = gdf.class_name.value_counts()[\"inflammatory\"]     except KeyError:         cnt = 0      return int(cnt)   # Count the immune cells within the grid cells with the cell cnt heuristic grid = grid_classify(     grid=grid,     objs=nuclei,     metric_func=get_immune_cell_cnt,     predicate=\"intersects\",     new_col_names=\"immune_cnt\",     parallel=False, )  # bin the grid cells into 4 quantiles col = \"immune_cnt\" bins = mapclassify.Quantiles(grid[col], k=4) grid[\"immune_density_level\"] = bins.yb  # plot ax = tissues.plot(     figsize=(15, 15),     column=\"class_name\",     legend=True,     alpha=0.5,     legend_kwds={         \"loc\": \"center left\",         \"bbox_to_anchor\": (0.75, 0.93)     } ) # add the legend to artist, otherwise it will be overwritten leg1 = ax.legend_ ax.add_artist(leg1)  ax = nuclei.plot(     ax=ax,     column=\"class_name\",     legend=True,     aspect=None,     legend_kwds={         \"loc\": \"center left\",         \"bbox_to_anchor\": (0.75, 0.83)     } ) leg2 = ax.legend_ ax.add_artist(leg2)  # copy the grid for plotting just the boundary gridboundary = grid.copy() gridboundary.geometry = grid.geometry.boundary ax = gridboundary.plot(     ax=ax,     column=\"immune_density_level\",     cmap=\"viridis\",     legend=True,     categorical=True,     linewidth=0.5,     legend_kwds={         \"loc\": \"center left\",         \"bbox_to_anchor\": (0.75, 0.73)     } ) leg3 = ax.legend_ ax.add_artist(leg3)  mapping = dict([(i, s) for i, s in enumerate(bins.get_legend_classes())]) replace_legend_items(ax.get_legend(), mapping)  ax.set_title(\"Hex Grid Overlay with Immune Cell Density Levels\") ax.set_axis_off() plt.subplots_adjust(right=0.7) <p>From the plot above we can clearly see that the immune dense areas are clustered close to the pre-cancerous lesion. This is a sign of immune infiltration to the lesion.</p> In\u00a0[9]: Copied! <pre># Let's first get the pre-cancerous lesion areas from the tissue gdf\nlesions = tissues.loc[tissues.class_name == \"area_cin\"]\nlesions\n</pre> # Let's first get the pre-cancerous lesion areas from the tissue gdf lesions = tissues.loc[tissues.class_name == \"area_cin\"] lesions Out[9]: geometry class_name 5 POLYGON ((8868.11000 117361.00000, 8867.52000 ... area_cin 6 POLYGON ((7371.11000 111883.00000, 7370.33000 ... area_cin 46 POLYGON ((6562.15000 116294.55000, 6562.00000 ... area_cin 48 POLYGON ((7562.07000 111319.52000, 7562.00000 ... area_cin In\u00a0[10]: Copied! <pre>#  Let's now get the distances of the hexes to the unique lesion areas. \n# The final distance will be set to the minimum distance to any lesion area.\nimport pandas as pd\n\ndistances = {}\nfor i, lesion in lesions.reset_index().iterrows():\n    dist = grid.distance(lesion.geometry)\n    distances[i] = dist\n\nmin_dists = pd.DataFrame(distances).min(axis=1)\nmin_dists.name = \"min_dist\"\nmin_dists\n</pre> #  Let's now get the distances of the hexes to the unique lesion areas.  # The final distance will be set to the minimum distance to any lesion area. import pandas as pd  distances = {} for i, lesion in lesions.reset_index().iterrows():     dist = grid.distance(lesion.geometry)     distances[i] = dist  min_dists = pd.DataFrame(distances).min(axis=1) min_dists.name = \"min_dist\" min_dists Out[10]: <pre>8a82f6472b4ffff       0.000000\n8a82f642b8c7fff    3320.611135\n8a82f64280affff    4230.460275\n8a82f65534c7fff    3490.247847\n8a82f64722a7fff       0.000000\n                      ...     \n8a82f645434ffff     582.169614\n8a82f6455507fff    1007.525533\n8a82f6455caffff     739.013138\n8a82f645426ffff     785.040893\n8a82f6455cb7fff     585.208383\nName: min_dist, Length: 3205, dtype: float64</pre> In\u00a0[11]: Copied! <pre># Let's join the grid df and the min_dists series together\ngrid = grid.join(other=min_dists, how=\"left\")\ngrid\n</pre> # Let's join the grid df and the min_dists series together grid = grid.join(other=min_dists, how=\"left\") grid Out[11]: geometry immune_cnt immune_density_level min_dist 8a82f6472b4ffff POLYGON ((7356.13395 114373.55572, 7388.89845 ... 0 0 0.000000 8a82f642b8c7fff POLYGON ((11580.96929 112350.14187, 11613.7354... 0 0 3320.611135 8a82f64280affff POLYGON ((12659.53015 111028.21670, 12692.2971... 1 1 4230.460275 8a82f65534c7fff POLYGON ((12649.21585 107557.04820, 12681.9847... 0 0 3490.247847 8a82f64722a7fff POLYGON ((7832.15525 115662.20995, 7864.91911 ... 2 2 0.000000 ... ... ... ... ... 8a82f645434ffff POLYGON ((6398.07752 117381.00075, 6430.84027 ... 0 0 582.169614 8a82f6455507fff POLYGON ((6049.25882 117651.55231, 6082.02138 ... 0 0 1007.525533 8a82f6455caffff POLYGON ((6072.37958 117269.76002, 6105.14235 ... 0 0 739.013138 8a82f645426ffff POLYGON ((6276.66362 117556.02922, 6309.42626 ... 0 0 785.040893 8a82f6455cb7fff POLYGON ((6292.08030 117301.49803, 6324.84308 ... 0 0 585.208383 <p>3205 rows \u00d7 4 columns</p> In\u00a0[12]: Copied! <pre>stroma = tissues.loc[tissues.class_name == \"areastroma\"]\nstromal_grid = stroma.sjoin(grid, how=\"inner\", predicate=\"intersects\")\nstromal_grid\n</pre> stroma = tissues.loc[tissues.class_name == \"areastroma\"] stromal_grid = stroma.sjoin(grid, how=\"inner\", predicate=\"intersects\") stromal_grid Out[12]: geometry class_name index_right immune_cnt immune_density_level min_dist 0 POLYGON ((12366.89000 107883.00000, 12296.5200... areastroma 8a82f642cb6ffff 0 0 3216.916321 0 POLYGON ((12366.89000 107883.00000, 12296.5200... areastroma 8a82f642cb4ffff 0 0 3190.945121 1 POLYGON ((8390.00000 117552.00000, 8388.98000 ... areastroma 8a82f6454537fff 7 3 0.000000 1 POLYGON ((8390.00000 117552.00000, 8388.98000 ... areastroma 8a82f6454507fff 12 3 0.000000 1 POLYGON ((8390.00000 117552.00000, 8388.98000 ... areastroma 8a82f645450ffff 2 2 0.000000 ... ... ... ... ... ... ... 55 POLYGON ((6553.06000 114438.00000, 6552.38000 ... areastroma 8a82f6409347fff 2 2 16.394966 55 POLYGON ((6553.06000 114438.00000, 6552.38000 ... areastroma 8a82f6409357fff 1 1 0.000000 55 POLYGON ((6553.06000 114438.00000, 6552.38000 ... areastroma 8a82f640935ffff 0 0 0.000000 55 POLYGON ((6553.06000 114438.00000, 6552.38000 ... areastroma 8a82f6454cb7fff 0 0 0.000000 55 POLYGON ((6553.06000 114438.00000, 6552.38000 ... areastroma 8a82f640934ffff 3 2 0.000000 <p>2591 rows \u00d7 6 columns</p> In\u00a0[13]: Copied! <pre># Let's tidy up the gird data for plotting the distance distributions\n\ntidy = stromal_grid.reset_index().set_index(\"immune_density_level\")\ntidy = tidy[[\"min_dist\"]]\ntidy = tidy.stack()\ntidy = tidy.reset_index()\ntidy = tidy.rename(\n    columns={\n        \"immune_density_level\": \"Stromal Immune Density Level\",\n        \"level_1\": \"Attribute\",\n        0: \"Distance to Lesion\"\n    }\n)\ntidy\n</pre> # Let's tidy up the gird data for plotting the distance distributions  tidy = stromal_grid.reset_index().set_index(\"immune_density_level\") tidy = tidy[[\"min_dist\"]] tidy = tidy.stack() tidy = tidy.reset_index() tidy = tidy.rename(     columns={         \"immune_density_level\": \"Stromal Immune Density Level\",         \"level_1\": \"Attribute\",         0: \"Distance to Lesion\"     } ) tidy Out[13]: Stromal Immune Density Level Attribute Distance to Lesion 0 0 min_dist 3216.916321 1 0 min_dist 3190.945121 2 3 min_dist 0.000000 3 3 min_dist 0.000000 4 2 min_dist 0.000000 ... ... ... ... 2586 2 min_dist 16.394966 2587 1 min_dist 0.000000 2588 0 min_dist 0.000000 2589 0 min_dist 0.000000 2590 2 min_dist 0.000000 <p>2591 rows \u00d7 3 columns</p> <p>Let's plot the kernel density estimate and a swarmplot for the different immune density levels to see the differences between the immune density level distributions in the stroma.</p> In\u00a0[14]: Copied! <pre># !pip install seaborn\n</pre> # !pip install seaborn In\u00a0[25]: Copied! <pre>import seaborn as sns\n\nfig, ax = plt.subplots(1, 2, figsize=(14, 6))\n\nax[0] = sns.kdeplot(\n    ax=ax[0],\n    data=tidy,\n    x=\"Distance to Lesion\",\n    hue=\"Stromal Immune Density Level\",\n    fill=True,\n    alpha=0.5,\n)\nax[0].set_title(\"KDE of Distances to Lesion\")\n\nax[1] = sns.swarmplot(\n    ax=ax[1],\n    data=tidy,\n    y=\"Distance to Lesion\",\n    x=\"Stromal Immune Density Level\",\n    hue=\"Stromal Immune Density Level\",\n    size=1.5,\n    orient=\"v\",\n    legend=False,\n    warn_thresh=0.5,\n)\nax[1].set_title(\"Swarm - Distances to Lesion\")\n</pre> import seaborn as sns  fig, ax = plt.subplots(1, 2, figsize=(14, 6))  ax[0] = sns.kdeplot(     ax=ax[0],     data=tidy,     x=\"Distance to Lesion\",     hue=\"Stromal Immune Density Level\",     fill=True,     alpha=0.5, ) ax[0].set_title(\"KDE of Distances to Lesion\")  ax[1] = sns.swarmplot(     ax=ax[1],     data=tidy,     y=\"Distance to Lesion\",     x=\"Stromal Immune Density Level\",     hue=\"Stromal Immune Density Level\",     size=1.5,     orient=\"v\",     legend=False,     warn_thresh=0.5, ) ax[1].set_title(\"Swarm - Distances to Lesion\") Out[25]: <pre>Text(0.5, 1.0, 'Swarm - Distances to Lesion')</pre> <p>From the plots, it's quite clear that the immune dense hexes are closer to the lesion than the immune cold hexes. This is a clear sign of immune infiltration from stroma to the lesion.</p> <p>Finally, let's compute whether the distance distributions are statistically significantly different between the immune density levels. We will do a t-test on two independent samples to see if the difference in the mean distances is statistically significant. We'll use the <code>scipy.stats.ttest_ind</code> function for this.</p> In\u00a0[32]: Copied! <pre># !pip install scipy\n</pre> # !pip install scipy In\u00a0[33]: Copied! <pre>from scipy.stats import ttest_ind\n\n# Filter the immune hot and cold hexes\nimmune_hot = stromal_grid.loc[stromal_grid[\"immune_density_level\"] == 3]\nimmune_cold = stromal_grid.loc[stromal_grid[\"immune_density_level\"] == 0]\n\n# Get the distances for immune hot and cold hexes\n# standardize the distances\nimmune_hot.loc[:, \"min_dist\"] = (\n    immune_hot[\"min_dist\"] / immune_hot[\"min_dist\"].mean()\n) / immune_hot[\"min_dist\"].std()\nimmune_cold.loc[:, \"min_dist\"] = (\n    immune_cold[\"min_dist\"] / immune_cold[\"min_dist\"].mean()\n) / immune_cold[\"min_dist\"].std()\n\ndist_hot = immune_hot[\"min_dist\"]\ndist_cold = immune_cold[\"min_dist\"]\n\n# Perform the t-test\nstatistic, p_value = ttest_ind(dist_hot, dist_cold)\n\n# Print the results\nif p_value &lt; 0.05:\n    print(\"The immune hot hexes are significantly closer to the lesion than the immune cold hexes.\")\nelse:\n    print(\"There is no significant difference in distance between the immune hot and cold hexes.\")\n\nprint(\"p-value: \", p_value)\n</pre> from scipy.stats import ttest_ind  # Filter the immune hot and cold hexes immune_hot = stromal_grid.loc[stromal_grid[\"immune_density_level\"] == 3] immune_cold = stromal_grid.loc[stromal_grid[\"immune_density_level\"] == 0]  # Get the distances for immune hot and cold hexes # standardize the distances immune_hot.loc[:, \"min_dist\"] = (     immune_hot[\"min_dist\"] / immune_hot[\"min_dist\"].mean() ) / immune_hot[\"min_dist\"].std() immune_cold.loc[:, \"min_dist\"] = (     immune_cold[\"min_dist\"] / immune_cold[\"min_dist\"].mean() ) / immune_cold[\"min_dist\"].std()  dist_hot = immune_hot[\"min_dist\"] dist_cold = immune_cold[\"min_dist\"]  # Perform the t-test statistic, p_value = ttest_ind(dist_hot, dist_cold)  # Print the results if p_value &lt; 0.05:     print(\"The immune hot hexes are significantly closer to the lesion than the immune cold hexes.\") else:     print(\"There is no significant difference in distance between the immune hot and cold hexes.\")  print(\"p-value: \", p_value) <pre>The immune hot hexes are significantly closer to the lesion than the immune cold hexes.\np-value:  3.282143798145504e-33\n</pre> <p>From this, we can conclude that the immune dense hexes are very very significantly closer to the lesion than the immune cold hexes. This is a clear sign of immune infiltration from stroma to the lesion, although, it is also clear just by eyeballing. However, it's always good to get a number to it.</p> In\u00a0[34]: Copied! <pre># sizes of the groups\nlen(dist_hot), len(dist_cold)\n</pre> # sizes of the groups len(dist_hot), len(dist_cold) Out[34]: <pre>(659, 1025)</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/spatial_grids/#spatial-grids","title":"Spatial Grids\u00b6","text":"<p>Spatial grid or sometimes spatial index is a spatial indexing system that can be useful when you want to pool or aggregate information from very large spatial maps, such as WSI-level tissue segmentations. <code>cellseg_gsontools</code> provides tools to fit spatial index/grid on top of segmentation masks. The grid cells can be further classified based on what's inside of them with any kind of heuristic. For example, cell densities such as lymphocyte densities can be computed by counting the number of cells in each grid cell.</p> <p>In this notebook, we will demonstrate how to fit a spatial grid on top of a tissue segmentation mask and how to compute cell densities from the nuclei segmentation mask with the spatial index.</p>"},{"location":"user_guide/spatial_grids/#the-data","title":"The Data\u00b6","text":"<p>The data used in this example is a cervical pre-cancerous biopsy. The data is not publicly available, so this serves only as a demonstration of the functionality.</p>"},{"location":"user_guide/spatial_grids/#fitting-a-square-grid","title":"Fitting a Square Grid\u00b6","text":"<p>We'll start by demonstrating how to fit a square grid on the tissue mask. The grid can be fitted by using the <code>grid_overlay</code>. The <code>patch_size</code> and <code>stride</code> (patch overlap) needs to be set in pixels to the function. We will use 256x256 patches with no overlap which is basically 128x128 micron tiles in this case.</p>"},{"location":"user_guide/spatial_grids/#fitting-a-hexagonal-grid","title":"Fitting a Hexagonal Grid\u00b6","text":"<p>Next, we will show how to fit a hexagonal spatial index. The hexagonal grid is fitted by using the <code>hexgrid_overlay</code> function. The actual grid is fitted with Uber's <code>h3</code>-package. The size of the hexes are determined by the <code>resolution</code> parameter. We will be using resolution 10. In the rest of the notebook, we will be using the hexagonal grid to compute the density metrics.</p>"},{"location":"user_guide/spatial_grids/#immune-cell-densities","title":"Immune Cell Densities\u00b6","text":"<p>Let's now use the grid to compute immune cell densities. We will be using the <code>grid_classify</code> function to first compute the immune cell count per hex and then use <code>mapclassify</code>-package to bin the count values into bins for visualizing the different levels of immune density.</p>"},{"location":"user_guide/spatial_grids/#distance-to-the-lesion","title":"Distance to the Lesion\u00b6","text":"<p>Next, we will quantify the distances of the hexes to the lesion. We want to show that the immune dense hexes are closer to the lesion than the immune cold hexes to get a number on it.</p>"},{"location":"user_guide/spatial_grids/#compute-the-minimum-distance-to-the-lesion","title":"Compute the Minimum Distance to the Lesion\u00b6","text":""},{"location":"user_guide/spatial_grids/#filter-stromal-hexes","title":"Filter Stromal Hexes\u00b6","text":"<p>Let's focus only on the hexes that intersect with the stromal tissue so we can quantify that the stromal immune density is higher close to the lesion. The other tissue regions are not that interesting in this case since we want to quantify whether there is immune infiltration from stroma to the lesion.</p>"},{"location":"user_guide/spatial_grids/#plot-distance-distributions","title":"Plot Distance Distributions\u00b6","text":""},{"location":"user_guide/merging/","title":"Merging Segmentation Maps","text":"In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import cell_merge_dir\n\n# The cell_merge_dir() is a path to a dir that contains adjacent segmentation tiles\ntiles = sorted(cell_merge_dir().glob(\"*\"))\nfor f in tiles:\n    print(f.name)\n</pre> from cellseg_gsontools.data import cell_merge_dir  # The cell_merge_dir() is a path to a dir that contains adjacent segmentation tiles tiles = sorted(cell_merge_dir().glob(\"*\")) for f in tiles:     print(f.name) <pre>x-41000_y-87000_cells.feather\nx-41000_y-88000_cells.feather\nx-41000_y-89000_cells.feather\nx-42000_y-86000_cells.feather\nx-42000_y-87000_cells.feather\nx-42000_y-88000_cells.feather\nx-43000_y-86000_cells.feather\nx-43000_y-87000_cells.feather\nx-43000_y-88000_cells.feather\n</pre> <p>As you can see, the starting x- and y-coordinates are encoded into the filenames of the tiles. The starting x- and y-coordinates are necessary if we want them to be merged.</p> <p>Let's visualize what two of the segmentation maps look like when we naively just concatenate them together.</p> In\u00a0[2]: Copied! <pre>import pandas as pd\n\nfrom cellseg_gsontools.utils import read_gdf\n\n# Let's look what the data would look like if we don't merge\ngdfs = []\nfor f in tiles[::3][-2:]:  # read only two tiles for demo\n    gdf = read_gdf(f)\n    gdfs.append(gdf)\n\ngdf_not_merged = pd.concat(gdfs)\ngdf_not_merged.head()\n</pre> import pandas as pd  from cellseg_gsontools.utils import read_gdf  # Let's look what the data would look like if we don't merge gdfs = [] for f in tiles[::3][-2:]:  # read only two tiles for demo     gdf = read_gdf(f)     gdfs.append(gdf)  gdf_not_merged = pd.concat(gdfs) gdf_not_merged.head() Out[2]: type geometry class_name 0 Feature POLYGON ((42769.000 86000.000, 42769.000 86005... glandular_epithel 1 Feature POLYGON ((42944.000 86000.000, 42944.000 86002... connective 2 Feature POLYGON ((42877.000 86003.000, 42876.000 86004... connective 3 Feature POLYGON ((42818.000 86005.000, 42815.000 86008... inflammatory 4 Feature POLYGON ((42913.000 86008.000, 42911.000 86010... inflammatory In\u00a0[3]: Copied! <pre>gdf_not_merged.plot(\n    figsize=(14, 8),\n    column=\"class_name\",\n    legend=True,\n    edgecolor=\"red\",\n)\n</pre> gdf_not_merged.plot(     figsize=(14, 8),     column=\"class_name\",     legend=True,     edgecolor=\"red\", ) Out[3]: <pre>&lt;Axes: &gt;</pre> <p>If you look closely up from the x coordinate 4300, you can see that some of the nuclei that are split in two (Zoom in).</p> In\u00a0[4]: Copied! <pre>from cellseg_gsontools.merging import CellMerger\n\n# tile size needs to be specified when merging cell segmentation patches\nmerger = CellMerger(cell_merge_dir(), tile_size=(1000, 1000))\n\n# MERGE CELLS\nmerger.merge_dir(verbose=True)\n</pre> from cellseg_gsontools.merging import CellMerger  # tile size needs to be specified when merging cell segmentation patches merger = CellMerger(cell_merge_dir(), tile_size=(1000, 1000))  # MERGE CELLS merger.merge_dir(verbose=True) <pre>Processing file: x-43000_y-88000_cells.feather: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 9/9 [00:03&lt;00:00,  2.54it/s]</pre> <pre>Saving the merged geojson file: None to `self.annots`\n</pre> <pre>\n</pre> <p>Let's visualize the merged segmentation map. All of the cells that were split in two or more parts are now merged.</p> In\u00a0[5]: Copied! <pre>merger.annots.plot(figsize=(10, 12), column=\"class_name\", legend=True)\n</pre> merger.annots.plot(figsize=(10, 12), column=\"class_name\", legend=True) Out[5]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/merging/#merging-segmentation-maps","title":"Merging Segmentation Maps\u00b6","text":"<p>Segmentation maps are usually split into multiple tiles to keep the file sizes manageable. The downside is that when the segmentation maps are split into multiple tiles the cells that are located on the edges of the tiles are split into two or more parts. This is not ideal for WSI-level downstream analysis, thus, merging the nuclei or tissue segmentation maps from multiple images into a single map is often necessary. In this tutorial, we will look at how to merge adjacent segmentation tiles into a single segmentation map.</p>"},{"location":"user_guide/merging/#adjacet-nuclei-segmentation-tiles","title":"Adjacet Nuclei Segmentation Tiles\u00b6","text":"<p>Let's look at some nuclei segmentations files that are provided by the <code>cellseg_gsontools</code> package. These segmentation maps are adjacent to each other.</p>"},{"location":"user_guide/merging/#merging-the-tiles","title":"Merging the Tiles\u00b6","text":"<p><code>cellseg_gsontools</code> provides tools for merging adjacent tiles of either instance segmentation (cells/nuclei) or semantic segmentation (tissue) maps. The merging is handled by the classes <code>CellMerger</code> and <code>AreaMerger</code>. These are are initialized with a path to a directory containing the segmentation maps of the tiles. The filenames of the tiles are assumed to contain the starting <code>x</code> and <code>y</code> coordinates and the tiles are assumed to be of the same size. The merger classes have a <code>merge_dir()</code> method that merges the tiles, caches the result in a <code>geopandas.GeoDataFrame</code> and saves to either <code>.geojson</code>, <code>.feather</code> or <code>.parquet</code> format.</p>"},{"location":"user_guide/merging/WSI_merge/","title":"Merging WSI-level Segmentation","text":"<p>Let's first look at the data. The underlying WSI was first tiled before segmentation so the segmentations masks are also tiles. Basically, we have one folder with 1000x1000px nuclei segmentation masks that are adjascent to each other and another folder with 1000x1000px tissue segmentation masks of the same tiles.</p> In\u00a0[1]: Copied! <pre>from pathlib import Path\nfrom cellseg_gsontools.merging import CellMerger\n\ng = Path(\"/my/path/to/wsi_seg/geojson/cells\")\n\nin_files = sorted(g.glob(\"*\"))\nprint(\"Number of input files:\", len(in_files), \"\\n\")\n\n# first 10 files\nfor f in list(g.glob(\"*\"))[:10]:\n    print(f.name)\n</pre> from pathlib import Path from cellseg_gsontools.merging import CellMerger  g = Path(\"/my/path/to/wsi_seg/geojson/cells\")  in_files = sorted(g.glob(\"*\")) print(\"Number of input files:\", len(in_files), \"\\n\")  # first 10 files for f in list(g.glob(\"*\"))[:10]:     print(f.name) <pre>Number of input files: 861 \n\nx-22000_y-92000_cells.json\nx-22000_y-93000_cells.json\nx-22000_y-94000_cells.json\nx-23000_y-91000_cells.json\nx-23000_y-92000_cells.json\nx-23000_y-93000_cells.json\nx-23000_y-94000_cells.json\nx-23000_y-95000_cells.json\nx-23000_y-96000_cells.json\nx-24000_y-90000_cells.json\n</pre> <p>NOTE: The segmentation files need to contain a <code>class_name</code> column</p> In\u00a0[9]: Copied! <pre>from cellseg_gsontools import read_gdf\n\nread_gdf(in_files[0]).head(4)\n</pre> from cellseg_gsontools import read_gdf  read_gdf(in_files[0]).head(4) Out[9]: type id geometry properties class_name 0 Feature PathCellDetection POLYGON ((22992.000 92584.000, 22991.000 92585... {'isLocked': 'false', 'measurements': [], 'cla... neoplastic 1 Feature PathCellDetection POLYGON ((22957.000 92595.000, 22956.000 92596... {'isLocked': 'false', 'measurements': [], 'cla... neoplastic 2 Feature PathCellDetection POLYGON ((22900.000 92622.000, 22897.000 92625... {'isLocked': 'false', 'measurements': [], 'cla... connective 3 Feature PathCellDetection POLYGON ((22894.000 92651.000, 22893.000 92652... {'isLocked': 'false', 'measurements': [], 'cla... connective In\u00a0[2]: Copied! <pre>merger = CellMerger(g, tile_size=(1000, 1000))\nmerger.merge_dir(\n    out_fn=None, # do not save the output to a file\n    format=None, # one of \"geojson\", \"parquet\", \"feather\", None\n    verbose=True,\n)\n</pre> merger = CellMerger(g, tile_size=(1000, 1000)) merger.merge_dir(     out_fn=None, # do not save the output to a file     format=None, # one of \"geojson\", \"parquet\", \"feather\", None     verbose=True, ) <pre>Processing file: x-22000_y-92000_cells.json:   0%|          | 0/861 [00:00&lt;?, ?it/s]</pre> <pre>Processing file: x-49000_y-83000_cells.json: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 861/861 [14:53&lt;00:00,  1.04s/it] \n</pre> <pre>Saving the merged geojson file: None to `self.annots`\n</pre> In\u00a0[11]: Copied! <pre>merger.annots.plot(\n    figsize=(15, 15),\n    column=\"class_name\",\n    legend=True,\n    aspect=None,\n)\n</pre> merger.annots.plot(     figsize=(15, 15),     column=\"class_name\",     legend=True,     aspect=None, ) Out[11]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>from cellseg_gsontools.merging import AreaMerger\n\n# Note that the AreaMerger does not require the tile_size argument\ng = Path(\"/my/path/to/wsi_seg/geojson/areas\")\narea_merger = AreaMerger(g)\n\narea_merger.merge_dir(\n    out_fn=None, # do not save the output to a file\n    format=None, # one of \"geojson\", \"parquet\", \"feather\", None\n    verbose=True,\n    parallel=True, # AreaMerger can be run in parallel\n)\n</pre> from cellseg_gsontools.merging import AreaMerger  # Note that the AreaMerger does not require the tile_size argument g = Path(\"/my/path/to/wsi_seg/geojson/areas\") area_merger = AreaMerger(g)  area_merger.merge_dir(     out_fn=None, # do not save the output to a file     format=None, # one of \"geojson\", \"parquet\", \"feather\", None     verbose=True,     parallel=True, # AreaMerger can be run in parallel ) <pre>100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 861/861 [04:25&lt;00:00,  3.25it/s]\n100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [01:27&lt;00:00, 21.86s/it]</pre> <pre>Saving the merged geojson file: None to `self.annots`\n</pre> <pre>\n</pre> In\u00a0[10]: Copied! <pre>area_merger.annots.plot(\n    figsize=(15, 15),\n    column=\"class_name\",\n    legend=True,\n    aspect=None,\n)\n</pre> area_merger.annots.plot(     figsize=(15, 15),     column=\"class_name\",     legend=True,     aspect=None, ) Out[10]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/merging/WSI_merge/#merging-wsi-level-segmentation","title":"Merging WSI-level Segmentation\u00b6","text":"<p>In this example, we will show how to merge WSI-level segmentation masks into a single mask. Both tissue and nuclei segmentation masks will be merged. The data used in this example is not publicly available, so this serves only as a demonstration of the functionality.</p>"},{"location":"user_guide/merging/WSI_merge/#merging-the-nuclei","title":"Merging the Nuclei\u00b6","text":"<p>Let's now merge the nuclei segmentation maps with the <code>CellMerger</code> class. The merging is simple but can take a few minutes.</p>"},{"location":"user_guide/merging/WSI_merge/#merging-the-tissue-segmentations","title":"Merging the Tissue Segmentations\u00b6","text":"<p>The tissue segmentation masks are merged with the <code>AreaMerger</code> class.</p>"},{"location":"user_guide/spatial_contexts/","title":"Spatial Context Classes","text":"<p>Usually tissue slides contain several interesting areas or regions of interest (ROI). However, at a whole-slide level, there are usually even more regions that are not of interest at all. Typically, the interesting regions are some tissue specific locations on the slide, like the tumor or stroma, or the interface between the tumor and stroma. If a cell appears in an interesting region, it is likely an interesting one and we want to be able to efficiently subset only interesting cells.</p> <p>Bring in the spatial context classes!</p> <p><code>cellseg_gsontools</code> provides tools to extract and analyze cells from different spatial contexts with the spatial context classes. The spatial context classes can be used to categorize cells based on their spatial context. For example, a lymphocyte within a tumor can be considered as a tumor infiltrating lymphocyte (TIL) whereas a lymphocyte cell in the stroma can be considered as a stromal lymphocyte. Although, both are lymphocytes, they appear in a different spatial context and thus they should be treated differently. These classes provide tools to focus only on the cells that are of interest in a specific spatial context.</p> <p>All the context-classes include the following methods:</p> <ul> <li><code>.fit()</code> - fits the ROIs</li> <li><code>.plot()</code> - plots the ROIs</li> <li><code>.context2gdf(key=\"some_context\")</code> - converts the distinct ROIs (if there are many) in   to one single <code>gpd.GeoDataFrame</code>.</li> <li><code>.context2weights(key=\"some_network\")</code> - converts the distinct spatial   weights objects of the ROIs into one <code>libpysal</code> graph.</li> </ul> <p>When the spatial context classes are fit, the following is done:</p> <ul> <li>Extraction of the unique ROIs of a given tissue type or types such as stroma, or tumor etc.</li> <li>Extraction of cells from within the ROIs.</li> <li>Fitting of a graph on the cells within each ROI so that the cell neighborhoods can be investigated.</li> <li>Fitting of a grid on the ROIs so that different density heuristics can be computed on the ROIs. For example, the immune cell density can be computed on the ROIs with by applying the grid to the ROIs.</li> </ul> <p>The resulting ROIs are saved in a class attribute called <code>.context</code>. This is a nested dictionary containg each unique ROI and the associated cells, graph and grid.</p>"},{"location":"user_guide/spatial_contexts/interface_context/","title":"Interface Context","text":"In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import cervix_cells\n\n# sneak peak to the data that will be used in the notebook\ncervix_cells().head()\n</pre> from cellseg_gsontools.data import cervix_cells  # sneak peak to the data that will be used in the notebook cervix_cells().head() Out[1]: type geometry class_name uid 1 Feature POLYGON ((-10.988 48446.005, -10.988 48453.996... inflammatory 2 Feature POLYGON ((-20.988 48477.996, -19.990 48479.993... connective 3 Feature POLYGON ((-14.988 48767.995, -11.993 48770.990... inflammatory 4 Feature POLYGON ((-3.988 49537.995, -2.995 49538.988, ... connective 5 Feature POLYGON ((-7.988 49562.995, -5.995 49564.988, ... connective In\u00a0[2]: Copied! <pre>from cellseg_gsontools.data import cervix_tissue\n\ncervix_tissue().head()\n</pre> from cellseg_gsontools.data import cervix_tissue  cervix_tissue().head() Out[2]: type geometry class_name uid 1 Feature POLYGON ((1852.953 51003.603, 1853.023 51009.1... areastroma 2 Feature POLYGON ((4122.334 48001.899, 4122.994 48014.8... areagland 3 Feature POLYGON ((3075.002 48189.068, 3075.001 48218.8... areagland 4 Feature POLYGON ((51.106 50822.418, 57.151 50834.504, ... areagland 5 Feature POLYGON ((3150.958 52999.764, 3147.245 52996.5... areastroma In\u00a0[3]: Copied! <pre>from cellseg_gsontools.spatial_context import InterfaceContext\n\nicsp = InterfaceContext(\n    area_gdf=cervix_tissue(),\n    cell_gdf=cervix_cells(),\n    top_labels=\"area_cin\",  # tissue classes that are buffered on top of bottom_labels\n    bottom_labels=\"areastroma\",  # tissue classes that are being buffered on\n    buffer_dist=250.0,  # the distance to buffer top_labels on top of bottom_labels\n    min_area_size=100000,  # minimum area size of the top_labels (in pixels**2)\n    silence_warnings=True,\n    parallel=False,  # Whether to run in parallel\n    num_processes=1,  # Number of processes to use\n    graph_type=\"distband\",  # Use a distance band graph (distance thresholded KNN-graph)\n    dist_thresh=90,  # Distance threshold for the graph\n    grid_type=\"hex\",  # Use a hexagonal grid\n    resolution=10,  # Resolution of the grid\n)\nicsp.fit(fit_graph=True, fit_grid=True)\n</pre> from cellseg_gsontools.spatial_context import InterfaceContext  icsp = InterfaceContext(     area_gdf=cervix_tissue(),     cell_gdf=cervix_cells(),     top_labels=\"area_cin\",  # tissue classes that are buffered on top of bottom_labels     bottom_labels=\"areastroma\",  # tissue classes that are being buffered on     buffer_dist=250.0,  # the distance to buffer top_labels on top of bottom_labels     min_area_size=100000,  # minimum area size of the top_labels (in pixels**2)     silence_warnings=True,     parallel=False,  # Whether to run in parallel     num_processes=1,  # Number of processes to use     graph_type=\"distband\",  # Use a distance band graph (distance thresholded KNN-graph)     dist_thresh=90,  # Distance threshold for the graph     grid_type=\"hex\",  # Use a hexagonal grid     resolution=10,  # Resolution of the grid ) icsp.fit(fit_graph=True, fit_grid=True) <pre>Processing roi area: 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00,  7.04it/s]\n</pre> In\u00a0[4]: Copied! <pre># Cells of the first interface\nicsp.context[0][\"interface_cells\"].head()\n</pre> # Cells of the first interface icsp.context[0][\"interface_cells\"].head() Out[4]: type geometry class_name global_id global_id 12407 Feature POLYGON ((10569.01182 48660.00490, 10569.01188... connective 12407 12416 Feature POLYGON ((10542.01188 48671.00360, 10542.01188... inflammatory 12416 12421 Feature POLYGON ((10549.01182 48697.99510, 10553.00585... inflammatory 12421 12438 Feature POLYGON ((10764.01188 48750.99640, 10765.00780... inflammatory 12438 12445 Feature POLYGON ((10506.01182 48760.00490, 10506.01182... connective 12445 In\u00a0[5]: Copied! <pre>icsp.plot(\"interface_area\", figsize=(12, 6))\n</pre> icsp.plot(\"interface_area\", figsize=(12, 6)) Out[5]: <pre>&lt;Axes: &gt;</pre> <p>We can also plot the graphs that are fitted to the cells in different contexts. Here, we will plot the graphs fitted to the cells that cross the interface i.e. the <code>border_network</code>. With the <code>border_network</code>, we can count the cell-cell connections that cross the border of the two tissues to see whether, for example, there is any immune infiltration from stroma to tumor.</p> In\u00a0[6]: Copied! <pre>icsp.plot(\n    \"interface_area\",\n    network_key=\"border_network\",\n    figsize=(12, 6),\n    edge_kws={\"linewidth\": 0.5}\n)\n</pre> icsp.plot(     \"interface_area\",     network_key=\"border_network\",     figsize=(12, 6),     edge_kws={\"linewidth\": 0.5} ) Out[6]: <pre>&lt;Axes: &gt;</pre> In\u00a0[7]: Copied! <pre>icsp.plot(\"interface_area\", grid_key=\"interface_grid\", figsize=(12, 6))\n</pre> icsp.plot(\"interface_area\", grid_key=\"interface_grid\", figsize=(12, 6)) Out[7]: <pre>&lt;Axes: &gt;</pre> In\u00a0[8]: Copied! <pre>import geopandas as gpd\nimport mapclassify\nimport numpy as np\nimport pandas as pd\n\nfrom cellseg_gsontools.grid import grid_classify\nfrom cellseg_gsontools.links import weights2gdf\nfrom cellseg_gsontools.plotting import plot_all\n\n\n# helper function to replace legend items\ndef replace_legend_items(legend, mapping):\n    for txt in legend.texts:\n        for k, v in mapping.items():\n            if txt.get_text() == str(k):\n                txt.set_text(v)\n\n\n# Immune-neoplastic link cnt heuristic to classify the grid cells into two classes\ndef get_infiltration_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; float:\n    dd = np.array([\"inflammatory-neoplastic\", \"neoplastic-inflammatory\"])\n\n    try:\n        class_name = dd[\n            np.array([cl in gdf.class_name.unique().tolist() for cl in dd])\n        ][0]\n        cnt = gdf.class_name.value_counts()[class_name]\n    except Exception:\n        cnt = 0\n\n    return int(cnt)\n\n\n# get the border network and convert it to a gdf\nw = icsp.context[0][\"border_network\"]\nlink_gdf = weights2gdf(icsp.cell_gdf, w)\n\n# Count the immune cells within the grid cells with the cell cnt heuristic\niface_grid = grid_classify(\n    grid=icsp.context[0][\"interface_grid\"],\n    objs=link_gdf,\n    metric_func=get_infiltration_cnt,\n    predicate=\"intersects\",\n    new_col_names=\"infiltrate_cnt\",\n    parallel=False,\n)\n\n# bin the grid cells into two classes (\"has infiltration\" and \"no infiltration\")\ncol = \"infiltrate_cnt\"\nbins = mapclassify.Quantiles(iface_grid[col], k=2)\niface_grid[\"infiltrate_density_level\"] = bins.yb\n\nimmune_density_plot = plot_all(\n    icsp.context[0][\"interface_area\"],\n    pd.concat([icsp.context[0][\"roi_cells\"], icsp.context[0][\"interface_cells\"]]),\n    grid_gdf=iface_grid.copy(),\n    network_gdf=link_gdf.copy(),\n    figsize=(10, 10),\n    grid_col=\"infiltrate_density_level\",\n    grid_cmap=\"jet\",\n    grid_n_bins=bins.k,\n    show_legends=True,\n    edge_kws={\"linewidth\": 0.5},\n)\nmapping = dict([(i, s) for i, s in enumerate(bins.get_legend_classes())])\nreplace_legend_items(immune_density_plot.get_legend(), mapping)\nimmune_density_plot\n</pre> import geopandas as gpd import mapclassify import numpy as np import pandas as pd  from cellseg_gsontools.grid import grid_classify from cellseg_gsontools.links import weights2gdf from cellseg_gsontools.plotting import plot_all   # helper function to replace legend items def replace_legend_items(legend, mapping):     for txt in legend.texts:         for k, v in mapping.items():             if txt.get_text() == str(k):                 txt.set_text(v)   # Immune-neoplastic link cnt heuristic to classify the grid cells into two classes def get_infiltration_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; float:     dd = np.array([\"inflammatory-neoplastic\", \"neoplastic-inflammatory\"])      try:         class_name = dd[             np.array([cl in gdf.class_name.unique().tolist() for cl in dd])         ][0]         cnt = gdf.class_name.value_counts()[class_name]     except Exception:         cnt = 0      return int(cnt)   # get the border network and convert it to a gdf w = icsp.context[0][\"border_network\"] link_gdf = weights2gdf(icsp.cell_gdf, w)  # Count the immune cells within the grid cells with the cell cnt heuristic iface_grid = grid_classify(     grid=icsp.context[0][\"interface_grid\"],     objs=link_gdf,     metric_func=get_infiltration_cnt,     predicate=\"intersects\",     new_col_names=\"infiltrate_cnt\",     parallel=False, )  # bin the grid cells into two classes (\"has infiltration\" and \"no infiltration\") col = \"infiltrate_cnt\" bins = mapclassify.Quantiles(iface_grid[col], k=2) iface_grid[\"infiltrate_density_level\"] = bins.yb  immune_density_plot = plot_all(     icsp.context[0][\"interface_area\"],     pd.concat([icsp.context[0][\"roi_cells\"], icsp.context[0][\"interface_cells\"]]),     grid_gdf=iface_grid.copy(),     network_gdf=link_gdf.copy(),     figsize=(10, 10),     grid_col=\"infiltrate_density_level\",     grid_cmap=\"jet\",     grid_n_bins=bins.k,     show_legends=True,     edge_kws={\"linewidth\": 0.5}, ) mapping = dict([(i, s) for i, s in enumerate(bins.get_legend_classes())]) replace_legend_items(immune_density_plot.get_legend(), mapping) immune_density_plot Out[8]: <pre>&lt;Axes: &gt;</pre> In\u00a0[9]: Copied! <pre>from cellseg_gsontools.links import weights2gdf\n\nw = icsp.context[0][\"border_network\"]\nw_gdf = weights2gdf(icsp.cell_gdf, w)\nw_gdf.head()\n</pre> from cellseg_gsontools.links import weights2gdf  w = icsp.context[0][\"border_network\"] w_gdf = weights2gdf(icsp.cell_gdf, w) w_gdf.head() Out[9]: index focal neighbor weight focal_centroid neighbor_centroid focal_class_name neighbor_class_name class_name geometry 0 0 9315 10482 1.0 POINT (7999.222138714856 49789.40336456389) POINT (8033.742411090165 49850.15890484998) glandular_epithel neoplastic glandular_epithel-neoplastic LINESTRING (7999.222 49789.403, 8033.742 49850... 1 1 9356 9395 1.0 POINT (7937.002202793094 50113.275934318786) POINT (7896.607546050848 50178.72364538605) neoplastic connective connective-neoplastic LINESTRING (7937.002 50113.276, 7896.608 50178... 2 2 9372 9395 1.0 POINT (7958.532206571154 50144.25476695621) POINT (7896.607546050848 50178.72364538605) neoplastic connective connective-neoplastic LINESTRING (7958.532 50144.255, 7896.608 50178... 3 3 9372 9408 1.0 POINT (7958.532206571154 50144.25476695621) POINT (7914.7260717517165 50204.87002012703) neoplastic connective connective-neoplastic LINESTRING (7958.532 50144.255, 7914.726 50204... 4 6 9395 9404 1.0 POINT (7896.607546050848 50178.72364538605) POINT (7954.544809238641 50192.02208046518) connective neoplastic connective-neoplastic LINESTRING (7896.608 50178.724, 7954.545 50192... In\u00a0[10]: Copied! <pre># cell-cell link counts\nw_gdf.value_counts(\"class_name\")\n</pre> # cell-cell link counts w_gdf.value_counts(\"class_name\") Out[10]: <pre>class_name\nconnective-neoplastic             565\ninflammatory-neoplastic           147\nneoplastic-neoplastic              74\nconnective-inflammatory            60\ninflammatory-inflammatory          31\nconnective-connective              25\nconnective-glandular_epithel        4\nglandular_epithel-inflammatory      3\nglandular_epithel-neoplastic        2\nName: count, dtype: int64</pre> In\u00a0[11]: Copied! <pre>from cellseg_gsontools.diversity import local_diversity\n\nw = icsp.context[0][\"full_network\"]\ncells = pd.concat([icsp.context[0][\"roi_cells\"], icsp.context[0][\"interface_cells\"]])\ncells = cells[\n    [\n        \"geometry\",\n        \"global_id\",\n        \"class_name\",\n    ]\n]\n# compute the heterogeneity of the neighborhood areas\ncells = local_diversity(\n    cells,\n    spatial_weights=w,\n    val_col=\"class_name\",\n    id_col=\"global_id\",\n    metrics=[\"simpson_index\"],\n    rm_nhood_cols=False,\n)\n\ncols = cols = [\n    \"geometry\",\n    \"class_name\",\n    \"nhood\",\n    \"class_name_nhood_counts\",\n    \"class_name_simpson_index\",\n]\ncells[cols].head()\n</pre> from cellseg_gsontools.diversity import local_diversity  w = icsp.context[0][\"full_network\"] cells = pd.concat([icsp.context[0][\"roi_cells\"], icsp.context[0][\"interface_cells\"]]) cells = cells[     [         \"geometry\",         \"global_id\",         \"class_name\",     ] ] # compute the heterogeneity of the neighborhood areas cells = local_diversity(     cells,     spatial_weights=w,     val_col=\"class_name\",     id_col=\"global_id\",     metrics=[\"simpson_index\"],     rm_nhood_cols=False, )  cols = cols = [     \"geometry\",     \"class_name\",     \"nhood\",     \"class_name_nhood_counts\",     \"class_name_simpson_index\", ] cells[cols].head() Out[11]: geometry class_name nhood class_name_nhood_counts class_name_simpson_index global_id 12525 POLYGON ((10992.01188 48227.00360, 10992.01191... neoplastic [12525] [1] 0.000000 12526 POLYGON ((10967.01188 48340.00360, 10967.01188... neoplastic [12526, 12352, 12353, 12354, 12527] [4, 1] 0.320000 12352 POLYGON ((10929.01168 48343.00780, 10929.01182... neoplastic [12352, 12526, 12353, 12354, 12355, 12527, 12358] [6, 1] 0.244898 12353 POLYGON ((10904.01182 48357.00490, 10904.01191... inflammatory [12353, 12526, 12352, 12354, 12355, 12527, 123... [7, 1, 1] 0.370370 12354 POLYGON ((10925.01168 48361.00780, 10925.01182... neoplastic [12354, 12526, 12352, 12353, 12355, 12527, 123... [7, 1] 0.218750 In\u00a0[12]: Copied! <pre># !pip install legendgram\n</pre> # !pip install legendgram In\u00a0[13]: Copied! <pre>import matplotlib.pyplot as plt\nimport palettable as palet\nfrom legendgram import legendgram\n\n\n# Helper function to plot cells with a feature value highlighted\ndef plot_cells(cells: gpd.GeoDataFrame, col: str):\n    # bin the values with the Fisher-Jenks method\n    bins = mapclassify.FisherJenks(cells[col], k=5)\n    cells[\"bin_vals\"] = bins.yb\n\n    # Let's plot the cells with the eccentricity metric\n    f, ax = plt.subplots(figsize=(10, 10))\n\n    ax = cells.plot(\n        ax=ax,\n        column=\"bin_vals\",\n        cmap=\"viridis\",\n        categorical=True,\n        legend=True,\n        legend_kwds={\n            \"fontsize\": 8,\n            \"loc\": \"center left\",\n            \"bbox_to_anchor\": (1.0, 0.94),\n        },\n    )\n\n    bin_legends = bins.get_legend_classes()\n    mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n    replace_legend_items(ax.get_legend(), mapping)\n\n    ax = legendgram(\n        f,\n        ax,\n        cells[col],\n        bins=100,\n        breaks=bins.bins,\n        pal=palet.matplotlib.Viridis_5,\n        loc=\"lower left\",\n    )\n\n    return ax\n\n\n# Let's plot the cells with the eccentricity metric\nplot_cells(cells, col=\"class_name_simpson_index\")\n</pre> import matplotlib.pyplot as plt import palettable as palet from legendgram import legendgram   # Helper function to plot cells with a feature value highlighted def plot_cells(cells: gpd.GeoDataFrame, col: str):     # bin the values with the Fisher-Jenks method     bins = mapclassify.FisherJenks(cells[col], k=5)     cells[\"bin_vals\"] = bins.yb      # Let's plot the cells with the eccentricity metric     f, ax = plt.subplots(figsize=(10, 10))      ax = cells.plot(         ax=ax,         column=\"bin_vals\",         cmap=\"viridis\",         categorical=True,         legend=True,         legend_kwds={             \"fontsize\": 8,             \"loc\": \"center left\",             \"bbox_to_anchor\": (1.0, 0.94),         },     )      bin_legends = bins.get_legend_classes()     mapping = dict([(i, s) for i, s in enumerate(bin_legends)])     replace_legend_items(ax.get_legend(), mapping)      ax = legendgram(         f,         ax,         cells[col],         bins=100,         breaks=bins.bins,         pal=palet.matplotlib.Viridis_5,         loc=\"lower left\",     )      return ax   # Let's plot the cells with the eccentricity metric plot_cells(cells, col=\"class_name_simpson_index\") Out[13]: <pre>&lt;Axes: &gt;</pre> <p>We can clearly see that the most diverse neighborhoods are located at the interface border. This is expected since the interface border is where the two tissues meet and on the other side there are tumor cells and on the other side stromal and immune cells, meaning that the cells at the border are likely to have more heterogenous neighboring cells. Also, we see that the tumor cell neighborhoods are more homogenous than the cell neighborhoods in the stroma. This is also expected since tumors are normally homogenous mass of tumor cells with some tumor-infiltrating-lymphocytes here and there whereas in the stroma there are several different cell types present in a heterogenous mix.</p> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/spatial_contexts/interface_context/#interface-context","title":"Interface Context\u00b6","text":"<p>The <code>InterfaceContext</code> class is used to extract cells within the interface of two or more given tissues. Here we will use it to extract the tumor-stroma interfaces and the cells within them.</p> <p>After fititng the context, The <code>InterfaceContext.context</code> attribute will contain a nested dict where each value is a dict contain the following key-value pairs:</p> <ul> <li><code>roi_area</code> - the roi areas of type <code>top_labels</code> (<code>gpd.GeoDataFrame</code>)</li> <li><code>roi_cells</code> - the cells inside the roi areas. (<code>gpd.GeoDataFrame</code>)</li> <li><code>roi_grid</code> - the grids fitted on top of the roi areas of type <code>top_labels</code>. (<code>gpd.GeoDataFrame</code>)</li> <li><code>interface_area</code> - returns the interface areas between <code>top_labels</code> and <code>bottom_labels</code> areas (<code>gpd.GeoDataFrame</code>)</li> <li><code>interface_cells</code> - returns the cells inside the <code>interface_area</code>. (<code>gpd.GeoDataFrame</code>)</li> <li><code>interface_grid</code> - returns the grids fitted on top of the interface areas. (<code>gpd.GeoDataFrame</code>)</li> <li><code>full_network</code> - the network fitted on the union of <code>interface_cells</code> and <code>roi_cells</code>. (<code>libpysal.weights.W</code>)</li> <li><code>roi_network</code> - the network fitted on the <code>roi_cells</code>. (<code>libpysal.weights.W</code>)</li> <li><code>interface_network</code> - returns the network fitted on top of the <code>interface_cells</code>. (<code>libpysal.weights.W</code>)</li> <li><code>border_network</code> - returns the network fitted on top of the cells that cross the interface border. (<code>libpysal.weights.W</code>)</li> </ul>"},{"location":"user_guide/spatial_contexts/interface_context/#the-data","title":"The Data\u00b6","text":"<p>A quick sneak peak into the data.</p>"},{"location":"user_guide/spatial_contexts/interface_context/#fitting-the-context","title":"Fitting the Context\u00b6","text":""},{"location":"user_guide/spatial_contexts/interface_context/#plotting-the-interfaces","title":"Plotting the Interfaces\u00b6","text":"<p>Let's plot the extracted interfaces and cells.</p>"},{"location":"user_guide/spatial_contexts/interface_context/#downstream-analysis","title":"Downstream Analysis\u00b6","text":"<p>Now that we\u2019ve fitted the context, we can use the interfaces in the <code>context</code> class attribute to compute more features. Here, we will showcase some lightweight downstream analyses for the extracted interfaces.</p>"},{"location":"user_guide/spatial_contexts/interface_context/#example-1-immune-infiltration-density","title":"Example 1: Immune Infiltration Density\u00b6","text":"<p>Here we compute the density of the inflammatory cells at the interface that have links to neoplastic cells at the tumor. We will use the <code>interface_grid</code> of the context and compute the link count of the inflammatory-neoplastic links within the grid cells to do this.</p>"},{"location":"user_guide/spatial_contexts/interface_context/#example-2-cell-cell-interactions","title":"Example 2: Cell-Cell Interactions\u00b6","text":"<p>We can also directly count the cell-cell interactions between the cells crossing the tissue border. We can do this by using the <code>border_network</code> key of the context.</p>"},{"location":"user_guide/spatial_contexts/interface_context/#example-3-computing-neighborhood-statistics","title":"Example 3: Computing Neighborhood Statistics\u00b6","text":"<p>Next we will compute some neighborhood statistics for the cells within the ROI and the interface. We will compute the simpson index over the different cell types in each cell neighborhood. The higher the simpson index of a cell neighborhood is, the more diverse it is in terms of cell types.</p>"},{"location":"user_guide/spatial_contexts/point_cluster_context/","title":"Point Cluster Context","text":"In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import cervix_cells\nfrom cellseg_gsontools.spatial_context import PointClusterContext\n\n# Create a WithinContext object\npcsp = PointClusterContext(\n    cell_gdf=cervix_cells(),\n    labels=\"inflammatory\",  # Cluster the inflammatory cells\n    cluster_method=\"dbscan\",  # Use DBSCAN for clustering\n    min_area_size=50000,  # Discard clusters that are smaller than this\n    parallel=False,  # Whether to run in parallel\n    num_processes=1,  # Number of processes to use\n    graph_type=\"distband\",  # Use a distance band graph (distance thresholded KNN-graph)\n    dist_thresh=75,  # Distance threshold for the graph (in pixels)\n    backend=\"geopandas\",  # Use geopandas for fitting\n    grid_type=\"hex\",  # Use a hexagonal grid\n    resolution=10,  # Resolution of the grid,\n    min_samples=60,  # Minimum number of samples for DBSCAN\n)\npcsp.fit(fit_grid=True, fit_graph=True)\n</pre> from cellseg_gsontools.data import cervix_cells from cellseg_gsontools.spatial_context import PointClusterContext  # Create a WithinContext object pcsp = PointClusterContext(     cell_gdf=cervix_cells(),     labels=\"inflammatory\",  # Cluster the inflammatory cells     cluster_method=\"dbscan\",  # Use DBSCAN for clustering     min_area_size=50000,  # Discard clusters that are smaller than this     parallel=False,  # Whether to run in parallel     num_processes=1,  # Number of processes to use     graph_type=\"distband\",  # Use a distance band graph (distance thresholded KNN-graph)     dist_thresh=75,  # Distance threshold for the graph (in pixels)     backend=\"geopandas\",  # Use geopandas for fitting     grid_type=\"hex\",  # Use a hexagonal grid     resolution=10,  # Resolution of the grid,     min_samples=60,  # Minimum number of samples for DBSCAN ) pcsp.fit(fit_grid=True, fit_graph=True) <pre>Processing roi area: 2: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 3/3 [00:00&lt;00:00,  6.89it/s]\n</pre> In\u00a0[2]: Copied! <pre># Cells of the first cluster\npcsp.context[0][\"roi_cells\"].head()\n</pre> # Cells of the first cluster pcsp.context[0][\"roi_cells\"].head() Out[2]: type geometry class_name global_id global_id 6631 Feature POLYGON ((6924.01182 48092.00490, 6924.01182 4... connective 6631 6630 Feature POLYGON ((6943.01182 48092.00490, 6943.01182 4... connective 6630 6638 Feature POLYGON ((6910.01182 48130.99510, 6912.00490 4... connective 6638 6651 Feature POLYGON ((6875.01182 48148.00490, 6875.01188 4... inflammatory 6651 8364 Feature POLYGON ((7031.01182 48176.99510, 7032.00490 4... connective 8364 In\u00a0[3]: Copied! <pre>pcsp.plot(\"roi_area\", figsize=(12, 6))\n</pre> pcsp.plot(\"roi_area\", figsize=(12, 6)) Out[3]: <pre>&lt;Axes: &gt;</pre> In\u00a0[4]: Copied! <pre>pcsp.plot(\n    \"roi_area\",\n    network_key=\"roi_network\",\n    figsize=(12, 6),\n    edge_kws={\"linewidth\": 0.5}\n)\n</pre> pcsp.plot(     \"roi_area\",     network_key=\"roi_network\",     figsize=(12, 6),     edge_kws={\"linewidth\": 0.5} ) Out[4]: <pre>&lt;Axes: &gt;</pre> In\u00a0[5]: Copied! <pre>pcsp.plot(\"roi_area\", grid_key=\"roi_grid\", figsize=(12, 6))\n</pre> pcsp.plot(\"roi_area\", grid_key=\"roi_grid\", figsize=(12, 6)) Out[5]: <pre>&lt;Axes: &gt;</pre> In\u00a0[6]: Copied! <pre>import geopandas as gpd\nimport mapclassify\n\nfrom cellseg_gsontools.grid import grid_classify\nfrom cellseg_gsontools.plotting import plot_all\n\n\n# helper function to replace legend items\ndef replace_legend_items(legend, mapping):\n    for txt in legend.texts:\n        for k, v in mapping.items():\n            if txt.get_text() == str(k):\n                txt.set_text(v)\n\n\n# Immune cell cnt heuristic to classify the grid cells into two classes\ndef get_immune_cell_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; int:\n    try:\n        cnt = gdf.class_name.value_counts()[\"inflammatory\"]\n    except KeyError:\n        cnt = 0\n\n    return int(cnt)\n\n\n# Count the immune cells within the grid cells with the cell cnt heuristic\ntumor_grid = grid_classify(\n    grid=pcsp.context[0][\"roi_grid\"],\n    objs=pcsp.context[0][\"roi_cells\"],\n    metric_func=get_immune_cell_cnt,\n    predicate=\"intersects\",\n    new_col_names=\"immune_cnt\",\n    parallel=False,\n)\n\n# bin the grid cells into two classes (\"has immune cells\" and \"no immune cells\")\ncol = \"immune_cnt\"\nbins = mapclassify.Quantiles(tumor_grid[col], k=10)\ntumor_grid[\"immune_density_level\"] = bins.yb\n\nimmune_density_plot = plot_all(\n    pcsp.context[0][\"roi_area\"],\n    pcsp.context[0][\"roi_cells\"],\n    grid_gdf=tumor_grid.copy(),\n    figsize=(10, 10),\n    grid_col=\"immune_density_level\",\n    grid_cmap=\"turbo\",\n    grid_n_bins=bins.k,\n    show_legends=True,\n)\nmapping = dict([(i, s) for i, s in enumerate(bins.get_legend_classes())])\nreplace_legend_items(immune_density_plot.get_legend(), mapping)\nimmune_density_plot\n</pre> import geopandas as gpd import mapclassify  from cellseg_gsontools.grid import grid_classify from cellseg_gsontools.plotting import plot_all   # helper function to replace legend items def replace_legend_items(legend, mapping):     for txt in legend.texts:         for k, v in mapping.items():             if txt.get_text() == str(k):                 txt.set_text(v)   # Immune cell cnt heuristic to classify the grid cells into two classes def get_immune_cell_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; int:     try:         cnt = gdf.class_name.value_counts()[\"inflammatory\"]     except KeyError:         cnt = 0      return int(cnt)   # Count the immune cells within the grid cells with the cell cnt heuristic tumor_grid = grid_classify(     grid=pcsp.context[0][\"roi_grid\"],     objs=pcsp.context[0][\"roi_cells\"],     metric_func=get_immune_cell_cnt,     predicate=\"intersects\",     new_col_names=\"immune_cnt\",     parallel=False, )  # bin the grid cells into two classes (\"has immune cells\" and \"no immune cells\") col = \"immune_cnt\" bins = mapclassify.Quantiles(tumor_grid[col], k=10) tumor_grid[\"immune_density_level\"] = bins.yb  immune_density_plot = plot_all(     pcsp.context[0][\"roi_area\"],     pcsp.context[0][\"roi_cells\"],     grid_gdf=tumor_grid.copy(),     figsize=(10, 10),     grid_col=\"immune_density_level\",     grid_cmap=\"turbo\",     grid_n_bins=bins.k,     show_legends=True, ) mapping = dict([(i, s) for i, s in enumerate(bins.get_legend_classes())]) replace_legend_items(immune_density_plot.get_legend(), mapping) immune_density_plot Out[6]: <pre>&lt;Axes: &gt;</pre> <p>We can see that the density of the inflammatory cells is higher in the upper part of the cluster. This could be avoided by adjusting the dbscan parameters (especially <code>min_samples</code>).</p> In\u00a0[7]: Copied! <pre>from cellseg_gsontools.geometry import shape_metric\n\n# first join the cluster labels to the cells\ngdf = pcsp.context2gdf(\"roi_cells\")\ngdf = gdf.sjoin(\n    pcsp.context2gdf(\"roi_area\"), how=\"inner\", predicate=\"intersects\"\n)\ngdf.rename(columns={\n    \"class_name_left\": \"class_name\", \n    \"label_right\": \"label\",\n    \"global_id_right\": \"global_id\"\n    }, \n    inplace=True\n)\n\nimmune_cells = gdf.loc[gdf.class_name == \"inflammatory\"]  # only neoplastic cells\n\n# morphological metrics to compute\nmetrics = [\n    \"area\",\n    \"eccentricity\",\n    \"solidity\",\n    \"circularity\",\n    \"sphericity\",\n    \"compactness\",\n    \"elongation\",\n    \"fractal_dimension\",\n    \"shape_index\",\n]\nimmune_cells = shape_metric(\n    immune_cells,\n    metrics=metrics,\n    parallel=True,\n)\n\ncols = [\n    \"geometry\",\n    \"global_id\",\n    \"class_name\",\n    \"area\",\n    \"eccentricity\",\n    \"solidity\",\n    \"circularity\",\n    \"sphericity\",\n    \"compactness\",\n    \"elongation\",\n    \"fractal_dimension\",\n    \"shape_index\",\n    \"label\" # cluster label\n]\nimmune_cells = immune_cells[cols]\nimmune_cells.head()\n</pre> from cellseg_gsontools.geometry import shape_metric  # first join the cluster labels to the cells gdf = pcsp.context2gdf(\"roi_cells\") gdf = gdf.sjoin(     pcsp.context2gdf(\"roi_area\"), how=\"inner\", predicate=\"intersects\" ) gdf.rename(columns={     \"class_name_left\": \"class_name\",      \"label_right\": \"label\",     \"global_id_right\": \"global_id\"     },      inplace=True )  immune_cells = gdf.loc[gdf.class_name == \"inflammatory\"]  # only neoplastic cells  # morphological metrics to compute metrics = [     \"area\",     \"eccentricity\",     \"solidity\",     \"circularity\",     \"sphericity\",     \"compactness\",     \"elongation\",     \"fractal_dimension\",     \"shape_index\", ] immune_cells = shape_metric(     immune_cells,     metrics=metrics,     parallel=True, )  cols = [     \"geometry\",     \"global_id\",     \"class_name\",     \"area\",     \"eccentricity\",     \"solidity\",     \"circularity\",     \"sphericity\",     \"compactness\",     \"elongation\",     \"fractal_dimension\",     \"shape_index\",     \"label\" # cluster label ] immune_cells = immune_cells[cols] immune_cells.head() Out[7]: geometry global_id class_name area eccentricity solidity circularity sphericity compactness elongation fractal_dimension shape_index label 3 POLYGON ((6875.01182 48148.00490, 6875.01188 4... 0 inflammatory 301.427924 0.575238 0.995752 0.876845 0.559229 0.876266 0.817986 0.575238 0.782543 0 5 POLYGON ((7097.01182 48173.00490, 7097.01182 4... 0 inflammatory 364.240603 0.298218 0.994756 0.938544 0.672787 0.936714 0.954498 0.298218 0.853750 0 13 POLYGON ((6743.01182 48255.00490, 6743.01182 4... 0 inflammatory 525.026189 0.754449 0.983428 0.835840 0.503512 0.830843 0.656357 0.754449 0.723241 0 20 POLYGON ((6974.01182 48228.00490, 6974.01188 4... 0 inflammatory 311.929175 0.635046 0.997471 0.930487 0.612086 0.929395 0.772477 0.635046 0.871300 0 24 POLYGON ((6983.01182 48284.00490, 6983.01182 4... 0 inflammatory 314.988442 0.303277 0.971783 0.867348 0.560565 0.858898 0.952894 0.303277 0.801863 0 <p>Let's Now tidy up the data (convert from wide format to long format) to compare the morphological features between the clusters.</p> In\u00a0[8]: Copied! <pre>m = list(metrics)\ntidy = immune_cells.reset_index().set_index(\"label\")\ntidy = tidy[m]\ntidy = tidy.stack()\ntidy = tidy.reset_index()\ntidy = tidy.rename(\n    columns={\"label\": \"Label\", \"level_1\": \"Attribute\", 0: \"Values\"}\n)\ntidy\n</pre> m = list(metrics) tidy = immune_cells.reset_index().set_index(\"label\") tidy = tidy[m] tidy = tidy.stack() tidy = tidy.reset_index() tidy = tidy.rename(     columns={\"label\": \"Label\", \"level_1\": \"Attribute\", 0: \"Values\"} ) tidy Out[8]: Label Attribute Values 0 0 area 301.427924 1 0 eccentricity 0.575238 2 0 solidity 0.995752 3 0 circularity 0.876845 4 0 sphericity 0.559229 ... ... ... ... 19588 2 sphericity 0.549432 19589 2 compactness 0.811198 19590 2 elongation 0.821277 19591 2 fractal_dimension 0.356534 19592 2 shape_index 0.811585 <p>19593 rows \u00d7 3 columns</p> In\u00a0[9]: Copied! <pre># Install seaborn for plotting in the next cell\n# !pip install seaborn\n</pre> # Install seaborn for plotting in the next cell # !pip install seaborn In\u00a0[10]: Copied! <pre>import seaborn\n\nseaborn.set_style(\"whitegrid\")\nseaborn.set(font_scale=1.5)\n\n# Setup the facets\nfacets = seaborn.FacetGrid(\n    data=tidy,\n    col=\"Attribute\",\n    hue=\"Label\",\n    sharey=False,\n    sharex=False,\n    aspect=2,\n    col_wrap=3,\n)\n\n# Build the plot from `sns.kdeplot`\nkde_ax = facets.map(seaborn.kdeplot, \"Values\", fill=True).add_legend()\n</pre> import seaborn  seaborn.set_style(\"whitegrid\") seaborn.set(font_scale=1.5)  # Setup the facets facets = seaborn.FacetGrid(     data=tidy,     col=\"Attribute\",     hue=\"Label\",     sharey=False,     sharex=False,     aspect=2,     col_wrap=3, )  # Build the plot from `sns.kdeplot` kde_ax = facets.map(seaborn.kdeplot, \"Values\", fill=True).add_legend() <p>We can see that the morphological features are distributed quite similarly between the clusters. The only feature that seems to be different is the <code>area</code> feature. This is likely due to the different sizes and the number of immune cells contained in the clusters.</p>"},{"location":"user_guide/spatial_contexts/point_cluster_context/#point-cluster-context","title":"Point Cluster Context\u00b6","text":"<p>The <code>PointClusterContext</code> class is used to cluster cells of a given type and delineating the cells belonging to the clusters. Here we will use it to cluster immune cells to get a hang of how the immune cells are clustered within the stroma.</p> <p>After fititng the context, The <code>PointClusterContext.context</code> attribute will contain a nested dict where each value is a dict contain the following key-value pairs:</p> <ul> <li><code>roi_area</code> - the alpha shape of the cluster (<code>gpd.GeoDataFrame</code>)</li> <li><code>roi_cells</code> - the cells inside the the alpha shape of the cluster. (<code>gpd.GeoDataFrame</code>)</li> <li><code>roi_grid</code> - the grids fitted on top of the cluster areas. (<code>gpd.GeoDataFrame</code>)</li> <li><code>roi_network</code> - the network fitted on the <code>roi_cells</code>. (<code>libpysal.weights.W</code>)</li> </ul>"},{"location":"user_guide/spatial_contexts/point_cluster_context/#fitting-the-context","title":"Fitting the Context\u00b6","text":""},{"location":"user_guide/spatial_contexts/point_cluster_context/#plotting-the-clusters","title":"Plotting the clusters\u00b6","text":"<p>Let's plot the immune cell clusters.</p>"},{"location":"user_guide/spatial_contexts/point_cluster_context/#downstream-analysis","title":"Downstream Analysis\u00b6","text":"<p>Now that we've fitted the context, we can use the clusters in the <code>context</code> class attribute to compute more cell level features for the clustered cells. Here, we will showcase some lightweight downstream analyses for the clustered cells.</p>"},{"location":"user_guide/spatial_contexts/point_cluster_context/#example-1-immune-cell-density","title":"Example 1: Immune Cell Density\u00b6","text":"<p>Now, if we wanted to compute the density of the inflammatory cells within one of the clusters, we could use the <code>roi_grid</code> key of the context and compute the cell count of the inflammatory cells within the grid cells.</p>"},{"location":"user_guide/spatial_contexts/point_cluster_context/#example-2-comparing-morphological-features-of-the-immune-cells-between-clusters","title":"Example 2: Comparing Morphological Features of the Immune Cells Between Clusters\u00b6","text":"<p>Next, we will compute some basic morphological metrics for the inflammatory cell shapes in all of the clusters.</p>"},{"location":"user_guide/spatial_contexts/within_context/","title":"Within Context","text":"In\u00a0[1]: Copied! <pre>from cellseg_gsontools.data import cervix_cells\n\n# sneak peak to the data that will be used in the notebook\ncervix_cells().head()\n</pre> from cellseg_gsontools.data import cervix_cells  # sneak peak to the data that will be used in the notebook cervix_cells().head() Out[1]: type geometry class_name uid 1 Feature POLYGON ((-10.988 48446.005, -10.988 48453.996... inflammatory 2 Feature POLYGON ((-20.988 48477.996, -19.990 48479.993... connective 3 Feature POLYGON ((-14.988 48767.995, -11.993 48770.990... inflammatory 4 Feature POLYGON ((-3.988 49537.995, -2.995 49538.988, ... connective 5 Feature POLYGON ((-7.988 49562.995, -5.995 49564.988, ... connective In\u00a0[2]: Copied! <pre>from cellseg_gsontools.data import cervix_tissue\n\ncervix_tissue().head()\n</pre> from cellseg_gsontools.data import cervix_tissue  cervix_tissue().head() Out[2]: type geometry class_name uid 1 Feature POLYGON ((1852.953 51003.603, 1853.023 51009.1... areastroma 2 Feature POLYGON ((4122.334 48001.899, 4122.994 48014.8... areagland 3 Feature POLYGON ((3075.002 48189.068, 3075.001 48218.8... areagland 4 Feature POLYGON ((51.106 50822.418, 57.151 50834.504, ... areagland 5 Feature POLYGON ((3150.958 52999.764, 3147.245 52996.5... areastroma In\u00a0[3]: Copied! <pre>from cellseg_gsontools.spatial_context import WithinContext\n\n# Create a WithinContext object\nwcsp = WithinContext(\n    area_gdf=cervix_tissue(),\n    cell_gdf=cervix_cells(),\n    labels=\"area_cin\",  # Extract the cells that are within tissue areas of this type\n    min_area_size=50000,  # Discard areas smaller than this\n    parallel=False,  # Whether to run in parallel\n    num_processes=1,  # Number of processes to use\n    graph_type=\"distband\",  # Use a distance band graph (distance thresholded KNN-graph)\n    dist_thresh=75,  # Distance threshold for the graph\n    backend=\"geopandas\",  # Use geopandas for fitting\n    grid_type=\"hex\",  # Use a hexagonal grid\n    resolution=10,  # Resolution of the grid\n)\nwcsp.fit(fit_grid=True, fit_graph=True)\n</pre> from cellseg_gsontools.spatial_context import WithinContext  # Create a WithinContext object wcsp = WithinContext(     area_gdf=cervix_tissue(),     cell_gdf=cervix_cells(),     labels=\"area_cin\",  # Extract the cells that are within tissue areas of this type     min_area_size=50000,  # Discard areas smaller than this     parallel=False,  # Whether to run in parallel     num_processes=1,  # Number of processes to use     graph_type=\"distband\",  # Use a distance band graph (distance thresholded KNN-graph)     dist_thresh=75,  # Distance threshold for the graph     backend=\"geopandas\",  # Use geopandas for fitting     grid_type=\"hex\",  # Use a hexagonal grid     resolution=10,  # Resolution of the grid ) wcsp.fit(fit_grid=True, fit_graph=True) <pre>Processing roi area: 3: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 4/4 [00:00&lt;00:00, 11.62it/s]\n</pre> In\u00a0[4]: Copied! <pre># Cells of the first ROI\nwcsp.context[0][\"roi_cells\"].head()\n</pre> # Cells of the first ROI wcsp.context[0][\"roi_cells\"].head() Out[4]: type geometry class_name global_id global_id 9316 Feature POLYGON ((7992.01191 49918.00298, 7992.01191 4... neoplastic 9316 9323 Feature POLYGON ((7968.01182 50003.00490, 7968.01191 5... neoplastic 9323 9329 Feature POLYGON ((7910.01182 50037.99510, 7911.00490 5... neoplastic 9329 9356 Feature POLYGON ((7928.01188 50114.00360, 7928.01188 5... neoplastic 9356 9357 Feature POLYGON ((7960.01182 50118.99510, 7962.82642 5... neoplastic 9357 In\u00a0[5]: Copied! <pre>wcsp.plot(\"roi_area\", figsize=(10, 6))\n</pre> wcsp.plot(\"roi_area\", figsize=(10, 6)) Out[5]: <pre>&lt;Axes: &gt;</pre> <p>We can also plot the graph and the grid fitted on the cells and the ROIs.</p> In\u00a0[6]: Copied! <pre>wcsp.plot(\n    \"roi_area\",\n    network_key=\"roi_network\",\n    figsize=(10, 6),\n    edge_kws={\"linewidth\": 0.5},\n)\n</pre> wcsp.plot(     \"roi_area\",     network_key=\"roi_network\",     figsize=(10, 6),     edge_kws={\"linewidth\": 0.5}, ) Out[6]: <pre>&lt;Axes: &gt;</pre> In\u00a0[7]: Copied! <pre>wcsp.plot(\"roi_area\", grid_key=\"roi_grid\", figsize=(10, 6))\n</pre> wcsp.plot(\"roi_area\", grid_key=\"roi_grid\", figsize=(10, 6)) Out[7]: <pre>&lt;Axes: &gt;</pre> In\u00a0[8]: Copied! <pre>import geopandas as gpd\nimport mapclassify\n\nfrom cellseg_gsontools.grid import grid_classify\nfrom cellseg_gsontools.plotting import plot_all\n\n\n# helper function to replace legend items\ndef replace_legend_items(legend, mapping):\n    for txt in legend.texts:\n        for k, v in mapping.items():\n            if txt.get_text() == str(k):\n                txt.set_text(v)\n\n\n# Immune cell cnt heuristic to classify the grid cells into two classes\ndef get_immune_cell_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; int:\n    try:\n        cnt = gdf.class_name.value_counts()[\"inflammatory\"]\n    except KeyError:\n        cnt = 0\n\n    return int(cnt)\n\n\n# Count the immune cells within the grid cells with the cell cnt heuristic\ntumor_grid = grid_classify(\n    grid=wcsp.context[0][\"roi_grid\"],\n    objs=wcsp.context[0][\"roi_cells\"],\n    metric_func=get_immune_cell_cnt,\n    predicate=\"intersects\",\n    new_col_names=\"immune_cnt\",\n    parallel=False,\n)\n\n# bin the grid cells into two classes (\"has immune cells\" and \"no immune cells\")\ncol = \"immune_cnt\"\nbins = mapclassify.Quantiles(tumor_grid[col], k=2)\ntumor_grid[\"immune_density_level\"] = bins.yb\n\nimmune_density_plot = plot_all(\n    wcsp.context[0][\"roi_area\"],\n    wcsp.context[0][\"roi_cells\"],\n    grid_gdf=tumor_grid.copy(),\n    figsize=(10, 10),\n    grid_col=\"immune_density_level\",\n    grid_cmap=\"viridis\",\n    grid_n_bins=bins.k,\n    show_legends=True,\n)\nmapping = dict([(i, s) for i, s in enumerate(bins.get_legend_classes())])\nreplace_legend_items(immune_density_plot.get_legend(), mapping)\nimmune_density_plot\n</pre> import geopandas as gpd import mapclassify  from cellseg_gsontools.grid import grid_classify from cellseg_gsontools.plotting import plot_all   # helper function to replace legend items def replace_legend_items(legend, mapping):     for txt in legend.texts:         for k, v in mapping.items():             if txt.get_text() == str(k):                 txt.set_text(v)   # Immune cell cnt heuristic to classify the grid cells into two classes def get_immune_cell_cnt(gdf: gpd.GeoDataFrame, **kwargs) -&gt; int:     try:         cnt = gdf.class_name.value_counts()[\"inflammatory\"]     except KeyError:         cnt = 0      return int(cnt)   # Count the immune cells within the grid cells with the cell cnt heuristic tumor_grid = grid_classify(     grid=wcsp.context[0][\"roi_grid\"],     objs=wcsp.context[0][\"roi_cells\"],     metric_func=get_immune_cell_cnt,     predicate=\"intersects\",     new_col_names=\"immune_cnt\",     parallel=False, )  # bin the grid cells into two classes (\"has immune cells\" and \"no immune cells\") col = \"immune_cnt\" bins = mapclassify.Quantiles(tumor_grid[col], k=2) tumor_grid[\"immune_density_level\"] = bins.yb  immune_density_plot = plot_all(     wcsp.context[0][\"roi_area\"],     wcsp.context[0][\"roi_cells\"],     grid_gdf=tumor_grid.copy(),     figsize=(10, 10),     grid_col=\"immune_density_level\",     grid_cmap=\"viridis\",     grid_n_bins=bins.k,     show_legends=True, ) mapping = dict([(i, s) for i, s in enumerate(bins.get_legend_classes())]) replace_legend_items(immune_density_plot.get_legend(), mapping) immune_density_plot Out[8]: <pre>&lt;Axes: &gt;</pre> <p>The plot above pin-points the immune cell hotspots of the ROI.</p> In\u00a0[9]: Copied! <pre># The number of grid cells classified to either \"has no immune cells\" vs \"has immune cells\"\nbins\n</pre> # The number of grid cells classified to either \"has no immune cells\" vs \"has immune cells\" bins Out[9]: <pre>Quantiles\n\n  Interval     Count\n--------------------\n[0.00, 0.00] |   267\n(0.00, 5.00] |    48</pre> In\u00a0[10]: Copied! <pre>from cellseg_gsontools.links import weights2gdf\n\nw = wcsp.context[0][\"roi_network\"]\nw_gdf = weights2gdf(wcsp.context[0][\"roi_cells\"], w)\nw_gdf.head()\n</pre> from cellseg_gsontools.links import weights2gdf  w = wcsp.context[0][\"roi_network\"] w_gdf = weights2gdf(wcsp.context[0][\"roi_cells\"], w) w_gdf.head() Out[10]: index focal neighbor weight focal_centroid neighbor_centroid focal_class_name neighbor_class_name class_name geometry 0 0 9316 10508 1.0 POINT (8002.844604435322 49918.60883637922) POINT (8071.324684594446 49919.55613239763) neoplastic neoplastic neoplastic-neoplastic LINESTRING (8002.845 49918.609, 8071.325 49919... 1 1 9316 10516 1.0 POINT (8002.844604435322 49918.60883637922) POINT (8023.883159119259 49933.338397103355) neoplastic neoplastic neoplastic-neoplastic LINESTRING (8002.845 49918.609, 8023.883 49933... 2 2 9316 10528 1.0 POINT (8002.844604435322 49918.60883637922) POINT (8038.75509749847 49978.25936289958) neoplastic neoplastic neoplastic-neoplastic LINESTRING (8002.845 49918.609, 8038.755 49978... 3 3 9323 9329 1.0 POINT (7983.698850394024 50017.418546162015) POINT (7917.155129364679 50030.30033051582) neoplastic neoplastic neoplastic-neoplastic LINESTRING (7983.699 50017.419, 7917.155 50030... 4 4 9323 9689 1.0 POINT (7983.698850394024 50017.418546162015) POINT (8017.906268884537 50073.52273399252) neoplastic neoplastic neoplastic-neoplastic LINESTRING (7983.699 50017.419, 8017.906 50073... In\u00a0[11]: Copied! <pre># cell-cell link counts\nw_gdf.value_counts(\"class_name\")\n</pre> # cell-cell link counts w_gdf.value_counts(\"class_name\") Out[11]: <pre>class_name\nneoplastic-neoplastic                  5601\ninflammatory-neoplastic                 322\nconnective-neoplastic                    73\nconnective-inflammatory                  47\ninflammatory-inflammatory                36\nglandular_epithel-neoplastic             14\nconnective-connective                    10\nglandular_epithel-glandular_epithel       3\nName: count, dtype: int64</pre> <p>There are some misclassification of the cell types since some of these cell types should not exist within the tumor area. However, we can see that the cell-cell interactions between the neoplastic cells are the most frequent as expected. The second most frequent connection is between the neoplastic and the immune cells signalling that there are some TILs within the tumor.</p> In\u00a0[12]: Copied! <pre># Let's plot the cell-cell links\n\nplot_all(\n    wcsp.context[0][\"roi_area\"],\n    wcsp.context[0][\"roi_cells\"],\n    network_gdf=w_gdf,\n    figsize=(10, 10),\n    show_legends=True,\n    edge_kws={\"linewidth\": 0.5},\n)\n</pre> # Let's plot the cell-cell links  plot_all(     wcsp.context[0][\"roi_area\"],     wcsp.context[0][\"roi_cells\"],     network_gdf=w_gdf,     figsize=(10, 10),     show_legends=True,     edge_kws={\"linewidth\": 0.5}, ) Out[12]: <pre>&lt;Axes: &gt;</pre> In\u00a0[13]: Copied! <pre>from cellseg_gsontools.geometry import shape_metric\n\ngdf = wcsp.context[0][\"roi_cells\"].copy()\ntumor_cells = gdf.loc[gdf.class_name == \"neoplastic\"]  # only neoplastic cells\n\n# morphological metrics to compute\nmetrics = [\"area\", \"eccentricity\", \"circularity\", \"fractal_dimension\"]\ntumor_cells = shape_metric(\n    tumor_cells,\n    metrics=metrics,\n    parallel=True,\n)\n\ntumor_cells[\n    [\"geometry\", \"area\", \"eccentricity\", \"circularity\", \"fractal_dimension\"]\n].head()\n</pre> from cellseg_gsontools.geometry import shape_metric  gdf = wcsp.context[0][\"roi_cells\"].copy() tumor_cells = gdf.loc[gdf.class_name == \"neoplastic\"]  # only neoplastic cells  # morphological metrics to compute metrics = [\"area\", \"eccentricity\", \"circularity\", \"fractal_dimension\"] tumor_cells = shape_metric(     tumor_cells,     metrics=metrics,     parallel=True, )  tumor_cells[     [\"geometry\", \"area\", \"eccentricity\", \"circularity\", \"fractal_dimension\"] ].head() Out[13]: geometry area eccentricity circularity fractal_dimension global_id 9316 POLYGON ((7992.01191 49918.00298, 7992.01191 4... 516.835643 0.758648 0.858014 0.758648 9323 POLYGON ((7968.01182 50003.00490, 7968.01191 5... 715.206484 0.348132 0.849744 0.348132 9329 POLYGON ((7910.01182 50037.99510, 7911.00490 5... 210.601857 0.469570 0.911534 0.469570 9356 POLYGON ((7928.01188 50114.00360, 7928.01188 5... 377.421903 0.858783 0.810163 0.858783 9357 POLYGON ((7960.01182 50118.99510, 7962.82642 5... 1165.683777 0.229062 0.900734 0.229062 In\u00a0[14]: Copied! <pre># take the mean and std\ntumor_cells[metrics].mean(axis=0), tumor_cells[metrics].std(axis=0)\n</pre> # take the mean and std tumor_cells[metrics].mean(axis=0), tumor_cells[metrics].std(axis=0) Out[14]: <pre>(area                 713.706993\n eccentricity           0.767298\n circularity            0.813745\n fractal_dimension      0.767298\n dtype: float64,\n area                 363.248195\n eccentricity           0.178114\n circularity            0.107053\n fractal_dimension      0.178114\n dtype: float64)</pre> <p>Let's look a little closer at the eccentricity values.</p> In\u00a0[15]: Copied! <pre># bin the eccentricity values into 5 classes\ncol = \"eccentricity\"\n\n# bin the values with the Fisher-Jenks method\nbins = mapclassify.FisherJenks(tumor_cells[col], k=5)\ntumor_cells[\"ecc_level\"] = bins.yb\nbins\n</pre> # bin the eccentricity values into 5 classes col = \"eccentricity\"  # bin the values with the Fisher-Jenks method bins = mapclassify.FisherJenks(tumor_cells[col], k=5) tumor_cells[\"ecc_level\"] = bins.yb bins Out[15]: <pre>FisherJenks\n\n  Interval     Count\n--------------------\n[0.00, 0.35] |    74\n(0.35, 0.56] |   153\n(0.56, 0.72] |   258\n(0.72, 0.85] |   529\n(0.85, 0.98] |   732</pre> <p>Again, we see that the majority of the cells are in the high eccentricity bins. Let's plot the cells to see the spatial distribution of the high and low eccentricity cells.</p> In\u00a0[16]: Copied! <pre># !pip install legendgram\n</pre> # !pip install legendgram In\u00a0[17]: Copied! <pre>import matplotlib.pyplot as plt\nimport palettable as palet\nfrom legendgram import legendgram\n\n\n# Helper function to plot cells with a feature value highlighted\ndef plot_cells(cells: gpd.GeoDataFrame, col: str):\n    # bin the values with the Fisher-Jenks method\n    bins = mapclassify.FisherJenks(cells[col], k=5)\n    cells[\"bin_vals\"] = bins.yb\n\n    # Let's plot the cells with the eccentricity metric\n    f, ax = plt.subplots(figsize=(10, 10))\n\n    ax = cells.plot(\n        ax=ax,\n        column=\"bin_vals\",\n        cmap=\"viridis\",\n        categorical=True,\n        legend=True,\n        legend_kwds={\n            \"fontsize\": 8,\n            \"loc\": \"center left\",\n            \"bbox_to_anchor\": (1.0, 0.94),\n        },\n    )\n\n    bin_legends = bins.get_legend_classes()\n    mapping = dict([(i, s) for i, s in enumerate(bin_legends)])\n    replace_legend_items(ax.get_legend(), mapping)\n\n    ax = legendgram(\n        f,\n        ax,\n        cells[col],\n        bins=100,\n        breaks=bins.bins,\n        pal=palet.matplotlib.Viridis_5,\n        loc=\"lower left\",\n    )\n\n    return ax\n\n\n# Let's plot the cells with the eccentricity metric\nplot_cells(tumor_cells, col=\"eccentricity\")\n</pre> import matplotlib.pyplot as plt import palettable as palet from legendgram import legendgram   # Helper function to plot cells with a feature value highlighted def plot_cells(cells: gpd.GeoDataFrame, col: str):     # bin the values with the Fisher-Jenks method     bins = mapclassify.FisherJenks(cells[col], k=5)     cells[\"bin_vals\"] = bins.yb      # Let's plot the cells with the eccentricity metric     f, ax = plt.subplots(figsize=(10, 10))      ax = cells.plot(         ax=ax,         column=\"bin_vals\",         cmap=\"viridis\",         categorical=True,         legend=True,         legend_kwds={             \"fontsize\": 8,             \"loc\": \"center left\",             \"bbox_to_anchor\": (1.0, 0.94),         },     )      bin_legends = bins.get_legend_classes()     mapping = dict([(i, s) for i, s in enumerate(bin_legends)])     replace_legend_items(ax.get_legend(), mapping)      ax = legendgram(         f,         ax,         cells[col],         bins=100,         breaks=bins.bins,         pal=palet.matplotlib.Viridis_5,         loc=\"lower left\",     )      return ax   # Let's plot the cells with the eccentricity metric plot_cells(tumor_cells, col=\"eccentricity\") Out[17]: <pre>&lt;Axes: &gt;</pre> <p>We can see that the high eccentricity cells can locate quite randomly in the tumor, although maybe a bit more to the inner border of the tissue. By computing the neighborhood average of the eccentricity values, we could see if the high eccentricity cells tend to locate near each other. This will be done next.</p> In\u00a0[18]: Copied! <pre>from cellseg_gsontools.character import local_character\n\nw = wcsp.context[0][\"roi_network\"]\ncells = wcsp.context[0][\"roi_cells\"].copy()\n\n# compute first the eccentricity for all the cells in the ROI\nmetrics = [\"eccentricity\"]\ncells = shape_metric(\n    cells,\n    metrics=metrics,\n    parallel=True,\n)\n\n# compute the mean eccentricity of each cell's neighborhood\ncells = local_character(\n    cells,\n    spatial_weights=w,\n    val_col=\"eccentricity\",\n    id_col=\"global_id\",\n    reductions=[\"mean\"],  # mean, median, sum,\n    weight_by_area=False,  # weight the values by the object areas\n    parallel=True,\n    rm_nhood_cols=False,\n)\n\ncols = [\"geometry\", \"class_name\", \"eccentricity\", \"nhood\", \"eccentricity_nhood_mean\"]\ncells[cols].head()\n</pre> from cellseg_gsontools.character import local_character  w = wcsp.context[0][\"roi_network\"] cells = wcsp.context[0][\"roi_cells\"].copy()  # compute first the eccentricity for all the cells in the ROI metrics = [\"eccentricity\"] cells = shape_metric(     cells,     metrics=metrics,     parallel=True, )  # compute the mean eccentricity of each cell's neighborhood cells = local_character(     cells,     spatial_weights=w,     val_col=\"eccentricity\",     id_col=\"global_id\",     reductions=[\"mean\"],  # mean, median, sum,     weight_by_area=False,  # weight the values by the object areas     parallel=True,     rm_nhood_cols=False, )  cols = [\"geometry\", \"class_name\", \"eccentricity\", \"nhood\", \"eccentricity_nhood_mean\"] cells[cols].head() Out[18]: geometry class_name eccentricity nhood eccentricity_nhood_mean global_id 9316 POLYGON ((7992.01191 49918.00298, 7992.01191 4... neoplastic 0.758648 [9316, 10508, 10516, 10528] 0.576694 9323 POLYGON ((7968.01182 50003.00490, 7968.01191 5... neoplastic 0.348132 [9323, 9329, 9689, 10528, 10551, 10561] 0.524408 9329 POLYGON ((7910.01182 50037.99510, 7911.00490 5... neoplastic 0.469570 [9329, 9323] 0.408851 9356 POLYGON ((7928.01188 50114.00360, 7928.01188 5... neoplastic 0.858783 [9356, 9357, 9372, 9690] 0.577453 9357 POLYGON ((7960.01182 50118.99510, 7962.82642 5... neoplastic 0.229062 [9357, 9356, 9372, 9689, 9690, 10594, 10601] 0.536294 In\u00a0[19]: Copied! <pre>plot_cells(cells, \"eccentricity_nhood_mean\")\n</pre> plot_cells(cells, \"eccentricity_nhood_mean\") Out[19]: <pre>&lt;Axes: &gt;</pre> <p>You can see from the plot that the high eccentricity cell neighborhoods locate quite near the the border of the tumor. This is a feature of the cervical tumor where less mature basal epithelial cells are more spindle like and tend to locate at the border of the tissue.</p> <p>Next, we\u2019ll compute how diverse the cell neighborhoods are in terms of eccentricity. This can be done by computing the shannon entropy of the eccentricity values of each cell neighborhood. The larger the shannon entropy is, the more diverse the cell neighborhood is in terms of the eccentricity.</p> In\u00a0[20]: Copied! <pre>from cellseg_gsontools.diversity import local_diversity\n\n# compute the heterogeneity of the neighborhood areas\ncells = local_diversity(\n    cells,\n    spatial_weights=w,\n    val_col=\"eccentricity\",\n    id_col=\"global_id\",\n    metrics=[\"shannon_index\"],\n)\n\ncols = cols = [\"geometry\", \"class_name\", \"eccentricity\", \"eccentricity_shannon_index\"]\ncells[cols].head()\n</pre> from cellseg_gsontools.diversity import local_diversity  # compute the heterogeneity of the neighborhood areas cells = local_diversity(     cells,     spatial_weights=w,     val_col=\"eccentricity\",     id_col=\"global_id\",     metrics=[\"shannon_index\"], )  cols = cols = [\"geometry\", \"class_name\", \"eccentricity\", \"eccentricity_shannon_index\"] cells[cols].head() Out[20]: geometry class_name eccentricity eccentricity_shannon_index global_id 9316 POLYGON ((7992.01191 49918.00298, 7992.01191 4... neoplastic 0.758648 0.693147 9323 POLYGON ((7968.01182 50003.00490, 7968.01191 5... neoplastic 0.348132 1.011404 9329 POLYGON ((7910.01182 50037.99510, 7911.00490 5... neoplastic 0.469570 0.000000 9356 POLYGON ((7928.01188 50114.00360, 7928.01188 5... neoplastic 0.858783 0.693147 9357 POLYGON ((7960.01182 50118.99510, 7962.82642 5... neoplastic 0.229062 0.955700 In\u00a0[21]: Copied! <pre>plot_cells(cells, \"eccentricity_shannon_index\")\n</pre> plot_cells(cells, \"eccentricity_shannon_index\") Out[21]: <pre>&lt;Axes: &gt;</pre> In\u00a0[\u00a0]: Copied! <pre>\n</pre>"},{"location":"user_guide/spatial_contexts/within_context/#within-context","title":"Within Context\u00b6","text":"<p>The <code>WithinContext</code> class is used to extract cells within a given tissue or tissues. Here we will use it to extract all the cancerous tissues and cells within them. The <code>WithinContext</code> extracts the cells from the input <code>cell_gdf</code> within the areas in the input <code>area_gdf</code>.</p> <p>After fitting the context, The <code>WithinContext.context</code> attribute will contain a nested dict where each value is a dict contain the following key-value pairs:</p> <ul> <li><code>roi_area</code> - the roi areas of type labels (<code>gpd.GeoDataFrame</code>)</li> <li><code>roi_cells</code> - the cells inside the roi areas. (<code>gpd.GeoDataFrame</code>)</li> <li><code>roi_grid</code> - the grids fitted on top of the roi areas of type labels. (<code>gpd.GeoDataFrame</code>)</li> <li><code>roi_network</code> - the network fitted on the roi_cells. (<code>libpysal.weights.W</code>)</li> </ul>"},{"location":"user_guide/spatial_contexts/within_context/#the-data","title":"The Data\u00b6","text":"<p>Let's look at the example data we will be using.</p>"},{"location":"user_guide/spatial_contexts/within_context/#fitting-the-context","title":"Fitting the Context\u00b6","text":""},{"location":"user_guide/spatial_contexts/within_context/#plotting-the-rois","title":"Plotting the ROIs\u00b6","text":"<p>Let's plot the extracted ROIs and cells from the WithinContext class.</p>"},{"location":"user_guide/spatial_contexts/within_context/#downstream-analysis","title":"Downstream Analysis\u00b6","text":"<p>Now that we've fitted the context, we can use the ROIs in the <code>context</code> class attribute to compute more features within the ROIs. Here, we will showcase some lightweight downstream analyses for the extracted ROIs.</p>"},{"location":"user_guide/spatial_contexts/within_context/#example-1-immune-cell-density","title":"Example 1: Immune Cell Density\u00b6","text":"<p>Now, if we wanted to compute the density of the inflammatory cells within one of the ROIs, we could use the <code>roi_grid</code> key of the context and compute the cell count of the inflammatory cells within the grid cells.</p>"},{"location":"user_guide/spatial_contexts/within_context/#example-2-cell-cell-interactions","title":"Example 2: Cell-Cell Interactions\u00b6","text":"<p>We can also compute the cell-cell interactions between the cells within the ROIs. We can do this by using the <code>roi_network</code> key of the context.</p>"},{"location":"user_guide/spatial_contexts/within_context/#example-3-computing-morphological-features-of-the-tumor-cells","title":"Example 3: Computing Morphological Features of the Tumor Cells\u00b6","text":"<p>Next, we will compute some basic morphological metrics for the tumor cell shapes.</p>"},{"location":"user_guide/spatial_contexts/within_context/#example-4-computing-neighborhood-statistics","title":"Example 4: Computing neighborhood statistics\u00b6","text":"<p>We will compute the neighborhood average of the eccentricity of the tumor cells. This can be done by using the <code>local_character</code> function.</p>"}]}